{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Testing with SDK v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml import command, Input\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import sys\n",
        "\n",
        "# Enter details of your AML workspace\n",
        "subscription_id = \"840b5c5c-3f4a-459a-94fc-6bad2a969f9d\"\n",
        "resource_group = \"ml\"\n",
        "workspace = \"ws02ent\"\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")\n",
        "\n",
        "sys.path.append(\"../\") # go to parent dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "from azure.ai.ml import  Input\n",
        "\n",
        "import ray\n",
        "\n",
        "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"ds11\" )\n",
        "#For use as client mode, uncomment these lines\n",
        "# head_ip = ray_on_aml.getRay(num_node=2,pip_packages=[\"torch==1.13.0\", \"azureml-mlflow\"])\n",
        "# client = ray.init(f\"ray://{head_ip}:10001\")\n",
        "#use CI as head node\n",
        "ray_on_aml.getRay(ci_is_head=True, num_node=2,pip_packages=[\"torch==1.13.0\", \"azureml-mlflow\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray.cluster_resources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.disconnect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Testing with SDK v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray_on_aml.shutdown(end_all_runs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Workspace\n",
        "import sys\n",
        "sys.path.append(\"../\") # go to parent dir\n",
        "import importlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "import ray\n",
        "ws = Workspace.from_config()\n",
        "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"ds11\",maxnode=2)\n",
        "ray_on_aml.getRay(num_node=2,pip_packages=[\"torch==1.13.0\", \"azureml-mlflow\"], ci_is_head=True)\n",
        "\n",
        "# head_ip = ray_on_aml.getRay(num_node=2,pip_packages=[\"torch==1.13.0\", \"azureml-mlflow\"], ci_is_head=True)\n",
        "\n",
        "# client = ray.init(f\"ray://{head_ip}:10001\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray.cluster_resources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray_on_aml.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ray\n",
        "\n",
        "# Load data.\n",
        "dataset = ray.data.read_csv(\"https://azuremlexamples.blob.core.windows.net/datasets/iris.csv\").repartition(4)\n",
        "\n",
        "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
        "\n",
        "# Create a test dataset by dropping the target column.\n",
        "test_dataset = valid_dataset.drop_columns(cols=[\"target\"])\n",
        "# Create a preprocessor to scale some columns.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from ray.data.preprocessors import Concatenator, Chain, StandardScaler\n",
        "\n",
        "# Create a preprocessor to scale some columns and concatenate the result.\n",
        "# preprocessor = Chain(\n",
        "#     StandardScaler(columns=[\"mean radius\", \"mean texture\"]),\n",
        "#     Concatenator(exclude=[\"target\"], dtype=np.float32),\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install pyarrow==6.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
        "\n",
        "from ray import train\n",
        "from ray.air import session\n",
        "from ray.air.config import ScalingConfig\n",
        "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
        "\n",
        "\n",
        "def create_model(input_features):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_features=input_features, out_features=16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "\n",
        "def train_loop_per_worker(config):\n",
        "    batch_size = config[\"batch_size\"]\n",
        "    lr = config[\"lr\"]\n",
        "    epochs = config[\"num_epochs\"]\n",
        "    num_features = config[\"num_features\"]\n",
        "\n",
        "    # Get the Ray Dataset shard for this data parallel worker,\n",
        "    # and convert it to a PyTorch Dataset.\n",
        "    train_data = train.get_dataset_shard(\"train\")\n",
        "    # Create model.\n",
        "    model = create_model(num_features)\n",
        "    model = train.torch.prepare_model(model)\n",
        "\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    for cur_epoch in range(epochs):\n",
        "        for batch in train_data.iter_torch_batches(\n",
        "            batch_size=batch_size, dtypes=torch.float32\n",
        "        ):\n",
        "            # \"concat_out\" is the output column of the Concatenator.\n",
        "            inputs, labels = batch[\"concat_out\"], batch[\"target\"]\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            train_loss = loss_fn(predictions, labels.unsqueeze(1))\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "        loss = train_loss.item()\n",
        "        session.report({\"loss\": loss}, checkpoint=TorchCheckpoint.from_model(model))\n",
        "\n",
        "\n",
        "num_features = len(train_dataset.schema().names) - 1\n",
        "\n",
        "trainer = TorchTrainer(\n",
        "    train_loop_per_worker=train_loop_per_worker,\n",
        "    train_loop_config={\n",
        "        \"batch_size\": 128,\n",
        "        \"num_epochs\": 20,\n",
        "        \"num_features\": num_features,\n",
        "        \"lr\": 0.001,\n",
        "    },\n",
        "    scaling_config=ScalingConfig(\n",
        "        num_workers=2,  # Number of workers to use for data parallelism.\n",
        "        use_gpu=False,\n",
        "        trainer_resources={\"CPU\": 1},  # so that the example works on Colab.\n",
        "    ),\n",
        "    datasets={\"train\": train_dataset},\n",
        "    preprocessor=preprocessor,\n",
        ")\n",
        "# Execute training.\n",
        "result = trainer.fit()\n",
        "print(f\"Last result: {result.metrics}\")\n",
        "# Last result: {'loss': 0.6559339960416158, ...}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install --upgrade ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray_on_aml.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ray\n",
        "client = ray.init(f\"ray://{head_ip}:10001\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.disconnect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('azureml_py310_sdkv2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
