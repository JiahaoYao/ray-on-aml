{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Testing with SDK v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml import command, Input\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import sys\n",
        "\n",
        "# Enter details of your AML workspace\n",
        "subscription_id = \"840b5c5c-3f4a-459a-94fc-6bad2a969f9d\"\n",
        "resource_group = \"ml\"\n",
        "workspace = \"ws02ent\"\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")\n",
        "\n",
        "sys.path.append(\"../\") # go to parent dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ray_on_aml._telemetry'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#X66sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mray_on_aml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m Ray_On_AML\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray_on_aml/core.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mzlib\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_telemetry\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_loggerfactory\u001b[39;00m \u001b[39mimport\u001b[39;00m _LoggerFactory\n\u001b[1;32m     14\u001b[0m \u001b[39m# from warnings import warn\u001b[39;00m\n\u001b[1;32m     16\u001b[0m __version__\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m0.2.3\u001b[39m\u001b[39m'\u001b[39m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray_on_aml._telemetry'"
          ]
        }
      ],
      "source": [
        "from ray_on_aml.core import Ray_On_AML\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  /anaconda/envs/azureml_py310_sdkv2/bin/python -m pip <command> [options]\n",
            "\n",
            "no such option: --force-reinstall\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install--upgrade git+https://github.com/microsoft/ray-on-aml.git@james-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: the provided asset name 'ray-on-aml-2580231983' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'ray-on-aml-2580231983' will not be used for anonymous registration\n",
            "\u001b[32mUploading .tmp (0.01 MBs): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6678/6678 [00:00<00:00, 151621.87it/s]\u001b[0m\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting cluster to start and return head node's ip\n",
            "...\n",
            " cluster is ready, head node ip  10.0.0.8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m /azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/ray/dashboard/agent.py:50: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m   aiogrpc.init_grpc_aio()\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m /azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/ray/dashboard/agent.py:468: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m   loop = asyncio.get_event_loop()\n"
          ]
        }
      ],
      "source": [
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "\n",
        "import logging\n",
        "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"d13\")\n",
        "#Note that if you need to customize the pip installation of the cluster, you also needs to support the ray package e.g. ray[data] which \n",
        "#match the version of the ray package(s) in your compute instance. If you don't specify pip_packages then ray[default] is inserted \n",
        "#automatically\n",
        "\n",
        "# For use as client mode, uncomment these lines\n",
        "ray = ray_on_aml.getRay(num_node=2,pip_packages=[\"ray[air]==2.1.0\",\"ray[data]==2.1.0\",\"torch==1.13.0\",\"fastparquet==2022.12.0\", \"azureml-mlflow==1.48.0\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs==2022.11.2\", \"fsspec==2022.11.0\"])\n",
        "client = ray.init(f\"ray://{ray_on_aml.headnode_private_ip}:10001\")\n",
        "\n",
        "#use CI as head node\n",
        "\n",
        "# ray = ray_on_aml.getRay(ci_is_head=True, num_node=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Example of using input and output for interactive job\n",
        "from azure.ai.ml import command, Input, Output\n",
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "import logging\n",
        "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"ds11\", verbosity=logging.INFO )\n",
        "\n",
        "inputs={\n",
        "\n",
        "    \"ISDWeather\": Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/adlsstore0001/paths/ISDWeather/year=2008\",\n",
        "    )\n",
        "}\n",
        "\n",
        "outputs={\n",
        "    \"output1\": Output(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/adlsstore0001/paths/dev\",\n",
        "    ),\n",
        "    \"output2\": Output(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/adlsstore0001/paths/dev\",\n",
        "    )\n",
        "}\n",
        "\n",
        "ray = ray_on_aml.getRay(inputs = inputs,outputs=outputs, num_node=2,pip_packages=[\"ray[data]\", \"fastparquet\", \"azureml-mlflow\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs\", \"fsspec\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "ray.cluster_resources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray_on_aml.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from adlfs import AzureBlobFileSystem\n",
        "#install dask, adlfs \n",
        "import dask.dataframe as dd\n",
        "from ray.util.dask import ray_dask_get, enable_dask_on_ray, disable_dask_on_ray\n",
        "enable_dask_on_ray()\n",
        "abfs = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
        "\n",
        "storage_options = {'account_name': 'azureopendatastorage'}\n",
        "ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
        "\n",
        "# data = ray.data.read_parquet(ray_on_aml.mount_points['ISDWeather'])\n",
        "\n",
        "data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs)\n",
        "print(data.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.disconnect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Testing with SDK v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Workspace\n",
        "import sys\n",
        "sys.path.append(\"../\") # go to parent dir\n",
        "import importlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "ws = Workspace.from_config()\n",
        "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"ds11\",maxnode=2)\n",
        "# ray_on_aml.getRay(num_node=2,pip_packages=[\"torch==1.13.0\", \"azureml-mlflow\"], ci_is_head=True)\n",
        "ray = ray_on_aml.getRay(num_node=2,pip_packages=[\"ray[data]==2.1.0\",\"fastparquet==2022.12.0\", \"azureml-mlflow==1.48.0\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs==2022.11.2\", \"fsspec==2022.11.0\"])\n",
        "\n",
        "client = ray.init(f\"ray://{ray_on_aml.headnode_private_ip}:10001\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray.cluster_resources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Load data.\n",
        "dataset = ray.data.read_csv(\"https://azuremlexamples.blob.core.windows.net/datasets/iris.csv\").repartition(4)\n",
        "\n",
        "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
        "\n",
        "# Create a test dataset by dropping the target column.\n",
        "# Create a preprocessor to scale some columns.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from ray.data.preprocessors import Concatenator, Chain, StandardScaler\n",
        "\n",
        "# Create a preprocessor to scale some columns and concatenate the result.\n",
        "# preprocessor = Chain(\n",
        "#     StandardScaler(columns=[\"mean radius\", \"mean texture\"]),\n",
        "#     Concatenator(exclude=[\"target\"], dtype=np.float32),\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray_on_aml.shutdown(end_all_runs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map_Batches:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | 0/2 [03:26<?, ?it/s]\n",
            "Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_map_block_nosplit()\u001b[39m (pid=521, ip=10.0.0.9)\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/ray/data/_internal/compute.py\", line 439, in _map_block_nosplit\n",
            "    for new_block in block_fn(block, *fn_args, **fn_kwargs):\n",
            "  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/dataset.py\", line 529, in transform\n",
            "  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/dataset.py\", line 649, in <lambda>\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/core/frame.py\", line 5396, in drop\n",
            "    return super().drop(\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/core/generic.py\", line 4505, in drop\n",
            "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/core/generic.py\", line 4546, in _drop_axis\n",
            "    new_axis = axis.drop(labels, errors=errors)\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 6977, in drop\n",
            "    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
            "KeyError: \"['target'] not found in axis\"\n",
            "Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): \u001b[36mray::_map_block_nosplit()\u001b[39m (pid=524, ip=10.0.0.9)\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/ray/data/_internal/compute.py\", line 439, in _map_block_nosplit\n",
            "    for new_block in block_fn(block, *fn_args, **fn_kwargs):\n",
            "  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/dataset.py\", line 529, in transform\n",
            "  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/dataset.py\", line 649, in <lambda>\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/core/frame.py\", line 5396, in drop\n",
            "    return super().drop(\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/util/_decorators.py\", line 331, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/core/generic.py\", line 4505, in drop\n",
            "    obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/core/generic.py\", line 4546, in _drop_axis\n",
            "    new_axis = axis.drop(labels, errors=errors)\n",
            "  File \"/azureml-envs/azureml_e6becbd955b6439d8f9fcc3781a8262b/lib/python3.10/site-packages/pandas/core/indexes/base.py\", line 6977, in drop\n",
            "    raise KeyError(f\"{list(labels[mask])} not found in axis\")\n",
            "KeyError: \"['target'] not found in axis\"\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/lib/../../nvidia/cublas/lib/libcublas.so.11: undefined symbol: cublasLtGetStatusString, version libcublasLt.so.11",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m consume_prefix_in_state_dict_if_present\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/__init__.py:191\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[39m# Easy way.  You want this most of the time, because it will prevent\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[39m# C++ symbols from libtorch clobbering C++ symbols from other\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[1;32m    189\u001b[0m     \u001b[39m# See Note [Global dependencies]\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     \u001b[39mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[0;32m--> 191\u001b[0m         _load_global_deps()\n\u001b[1;32m    192\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m  \u001b[39m# noqa: F403\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m# Appease the type checker; ordinarily this binding is inserted by the\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# torch._C module initialization code in C\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/__init__.py:153\u001b[0m, in \u001b[0;36m_load_global_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m here \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(\u001b[39m__file__\u001b[39m)\n\u001b[1;32m    151\u001b[0m lib_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(here), \u001b[39m'\u001b[39m\u001b[39mlib\u001b[39m\u001b[39m'\u001b[39m, lib_name)\n\u001b[0;32m--> 153\u001b[0m ctypes\u001b[39m.\u001b[39;49mCDLL(lib_path, mode\u001b[39m=\u001b[39;49mctypes\u001b[39m.\u001b[39;49mRTLD_GLOBAL)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_FuncPtr \u001b[39m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
            "\u001b[0;31mOSError\u001b[0m: /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/torch/lib/../../nvidia/cublas/lib/libcublas.so.11: undefined symbol: cublasLtGetStatusString, version libcublasLt.so.11"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Log channel is reconnecting. Logs produced while the connection was down can be found on the head node of the cluster in `ray_client_server_[port].out`\n",
            "2022-12-14 23:14:58,380\tWARNING dataclient.py:396 -- Encountered connection issues in the data channel. Attempting to reconnect.\n",
            "2022-12-14 23:15:28,589\tWARNING dataclient.py:403 -- Failed to reconnect the data channel\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
        "\n",
        "from ray import train\n",
        "from ray.air import session\n",
        "from ray.air.config import ScalingConfig\n",
        "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
        "\n",
        "\n",
        "def create_model(input_features):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_features=input_features, out_features=16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "\n",
        "def train_loop_per_worker(config):\n",
        "    batch_size = config[\"batch_size\"]\n",
        "    lr = config[\"lr\"]\n",
        "    epochs = config[\"num_epochs\"]\n",
        "    num_features = config[\"num_features\"]\n",
        "\n",
        "    # Get the Ray Dataset shard for this data parallel worker,\n",
        "    # and convert it to a PyTorch Dataset.\n",
        "    train_data = train.get_dataset_shard(\"train\")\n",
        "    # Create model.\n",
        "    model = create_model(num_features)\n",
        "    model = train.torch.prepare_model(model)\n",
        "\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    for cur_epoch in range(epochs):\n",
        "        for batch in train_data.iter_torch_batches(\n",
        "            batch_size=batch_size, dtypes=torch.float32\n",
        "        ):\n",
        "            # \"concat_out\" is the output column of the Concatenator.\n",
        "            inputs, labels = batch[\"concat_out\"], batch[\"target\"]\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            train_loss = loss_fn(predictions, labels.unsqueeze(1))\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "        loss = train_loss.item()\n",
        "        session.report({\"loss\": loss}, checkpoint=TorchCheckpoint.from_model(model))\n",
        "\n",
        "\n",
        "num_features = len(train_dataset.schema().names) - 1\n",
        "\n",
        "trainer = TorchTrainer(\n",
        "    train_loop_per_worker=train_loop_per_worker,\n",
        "    train_loop_config={\n",
        "        \"batch_size\": 128,\n",
        "        \"num_epochs\": 20,\n",
        "        \"num_features\": num_features,\n",
        "        \"lr\": 0.001,\n",
        "    },\n",
        "    scaling_config=ScalingConfig(\n",
        "        num_workers=2,  # Number of workers to use for data parallelism.\n",
        "        use_gpu=False,\n",
        "        trainer_resources={\"CPU\": 1},  # so that the example works on Colab.\n",
        "    ),\n",
        "    datasets={\"train\": train_dataset},\n",
        "    preprocessor=preprocessor,\n",
        ")\n",
        "# Execute training.\n",
        "result = trainer.fit()\n",
        "print(f\"Last result: {result.metrics}\")\n",
        "# Last result: {'loss': 0.6559339960416158, ...}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (1.13.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: typing-extensions in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: setuptools in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.0)\n",
            "Requirement already satisfied: wheel in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "azureml_py310_sdkv2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
