{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "\n",
        "# Load data.\n",
        "dataset = ray.data.read_csv(\"s3://anonymous@air-example-data/breast_cancer.csv\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-12-03 21:02:43,203\tINFO worker.py:1528 -- Started a local Ray instance.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#note: pip install -U \"pyarrow<7.0.0\" pip install -U pyarrow>=6.0.1\n",
        "#note: "
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
        "\n",
        "# Create a test dataset by dropping the target column.\n",
        "test_dataset = valid_dataset.drop_columns(cols=[\"target\"])\n",
        "# Create a preprocessor to scale some columns.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from ray.data.preprocessors import Concatenator, Chain, StandardScaler\n",
        "\n",
        "# Create a preprocessor to scale some columns and concatenate the result.\n",
        "preprocessor = Chain(\n",
        "    StandardScaler(columns=[\"mean radius\", \"mean texture\"]),\n",
        "    Concatenator(exclude=[\"target\"], dtype=np.float32),\n",
        ")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Map_Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 29.10it/s]\n"
        }
      ],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
        "\n",
        "from ray import train\n",
        "from ray.air import session\n",
        "from ray.air.config import ScalingConfig\n",
        "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
        "\n",
        "\n",
        "def create_model(input_features):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_features=input_features, out_features=16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "\n",
        "def train_loop_per_worker(config):\n",
        "    batch_size = config[\"batch_size\"]\n",
        "    lr = config[\"lr\"]\n",
        "    epochs = config[\"num_epochs\"]\n",
        "    num_features = config[\"num_features\"]\n",
        "\n",
        "    # Get the Ray Dataset shard for this data parallel worker,\n",
        "    # and convert it to a PyTorch Dataset.\n",
        "    train_data = train.get_dataset_shard(\"train\")\n",
        "    # Create model.\n",
        "    model = create_model(num_features)\n",
        "    model = train.torch.prepare_model(model)\n",
        "\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    for cur_epoch in range(epochs):\n",
        "        for batch in train_data.iter_torch_batches(\n",
        "            batch_size=batch_size, dtypes=torch.float32\n",
        "        ):\n",
        "            # \"concat_out\" is the output column of the Concatenator.\n",
        "            inputs, labels = batch[\"concat_out\"], batch[\"target\"]\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            train_loss = loss_fn(predictions, labels.unsqueeze(1))\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "        loss = train_loss.item()\n",
        "        session.report({\"loss\": loss}, checkpoint=TorchCheckpoint.from_model(model))\n",
        "\n",
        "\n",
        "num_features = len(train_dataset.schema().names) - 1\n",
        "\n",
        "trainer = TorchTrainer(\n",
        "    train_loop_per_worker=train_loop_per_worker,\n",
        "    train_loop_config={\n",
        "        \"batch_size\": 128,\n",
        "        \"num_epochs\": 20,\n",
        "        \"num_features\": num_features,\n",
        "        \"lr\": 0.001,\n",
        "    },\n",
        "    scaling_config=ScalingConfig(\n",
        "        num_workers=2,  # Number of workers to use for data parallelism.\n",
        "        use_gpu=False,\n",
        "        trainer_resources={\"CPU\": 0},  # so that the example works on Colab.\n",
        "    ),\n",
        "    datasets={\"train\": train_dataset},\n",
        "    preprocessor=preprocessor,\n",
        ")\n",
        "# Execute training.\n",
        "result = trainer.fit()\n",
        "print(f\"Last result: {result.metrics}\")\n",
        "# Last result: {'loss': 0.6559339960416158, ...}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/ray/train/base_trainer.py:354: UserWarning: Executing `.fit()` may leave less than 20% of CPUs in this cluster for Dataset execution, which can lead to resource contention or hangs. To avoid this, reserve at least 20% of node CPUs for Dataset execution by setting `_max_cpu_fraction_per_node = 0.8` in the Trainer scaling_config. See https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune for more info.\n  tuner = Tuner(trainable=trainable, run_config=self.run_config)\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "<div class=\"tuneStatus\">\n  <div style=\"display: flex;flex-direction: row\">\n    <div style=\"display: flex;flex-direction: column;\">\n      <h3>Tune Status</h3>\n      <table>\n<tbody>\n<tr><td>Current time:</td><td>2022-12-03 21:41:56</td></tr>\n<tr><td>Running for: </td><td>00:38:14.14        </td></tr>\n<tr><td>Memory:      </td><td>7.1/13.7 GiB       </td></tr>\n</tbody>\n</table>\n    </div>\n    <div class=\"vDivider\"></div>\n    <div class=\"systemInfo\">\n      <h3>System Info</h3>\n      Using FIFO scheduling algorithm.<br>Resources requested: 2.0/2 CPUs, 0/0 GPUs, 0.0/3.74 GiB heap, 0.0/1.87 GiB objects\n    </div>\n    \n  </div>\n  <div class=\"hDivider\"></div>\n  <div class=\"trialStatus\">\n    <h3>Trial Status</h3>\n    <table>\n<thead>\n<tr><th>Trial name              </th><th>status  </th><th>loc           </th></tr>\n</thead>\n<tbody>\n<tr><td>TorchTrainer_f7a7b_00000</td><td>RUNNING </td><td>10.0.0.4:55163</td></tr>\n</tbody>\n</table>\n  </div>\n</div>\n<style>\n.tuneStatus {\n  color: var(--jp-ui-font-color1);\n}\n.tuneStatus .systemInfo {\n  display: flex;\n  flex-direction: column;\n}\n.tuneStatus td {\n  white-space: nowrap;\n}\n.tuneStatus .trialStatus {\n  display: flex;\n  flex-direction: column;\n}\n.tuneStatus h3 {\n  font-weight: bold;\n}\n.tuneStatus .hDivider {\n  border-bottom-width: var(--jp-border-width);\n  border-bottom-color: var(--jp-border-color0);\n  border-bottom-style: solid;\n}\n.tuneStatus .vDivider {\n  border-left-width: var(--jp-border-width);\n  border-left-color: var(--jp-border-color0);\n  border-left-style: solid;\n  margin: 0.5em 1em 0.5em 1em;\n}\n</style>\n",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\u001b[2m\u001b[1m\u001b[36m(scheduler +1m17s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +1m17s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +1m52s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +2m27s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +3m2s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +3m37s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +4m13s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +4m48s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +5m23s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +5m58s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +6m33s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +7m8s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +7m43s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +8m18s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +8m53s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +9m28s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +10m3s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +10m38s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +11m13s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +11m48s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +12m23s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +12m58s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +13m33s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +14m8s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +14m44s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +15m19s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +15m54s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +16m29s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +17m4s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +17m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +18m14s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +18m49s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +19m24s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +19m59s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +20m34s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +21m9s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +21m44s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +22m19s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +22m54s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +23m29s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +24m4s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +24m39s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +25m14s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +25m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +26m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +27m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +27m35s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +28m10s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +28m45s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +29m20s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +29m55s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +30m30s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +31m5s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +31m40s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +32m15s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +32m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +33m25s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +34m0s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +34m35s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +35m10s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +35m45s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +36m21s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +36m56s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +37m31s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +38m6s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +38m41s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n\u001b[2m\u001b[1m\u001b[33m(scheduler +39m16s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2022-12-03 21:41:56,435\tWARNING tune.py:705 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n2022-12-03 21:41:56,670\tERROR tune.py:773 -- Trials did not complete: [TorchTrainer_f7a7b_00000]\n2022-12-03 21:41:56,674\tINFO tune.py:777 -- Total run time: 2294.38 seconds (2294.14 seconds for the tuning loop).\n2022-12-03 21:41:56,675\tWARNING tune.py:783 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Last result: {'trial_id': 'f7a7b_00000', 'experiment_id': 'fa3ed7b70b8547cfa4cee259c9be5bb3', 'date': '2022-12-03_21-03-46', 'timestamp': 1670101426, 'pid': 55163, 'hostname': 'ds11ci', 'node_ip': '10.0.0.4', 'config': {}}\n"
        }
      ],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "python_version = [\"python=3.10.1\"]\n",
        "base_conda_dep =['adlfs==2021.10.0','pip==21.3.1']\n",
        "additional_pip_packages = ['ray==2.1.0']\n",
        "additional_conda_packages =['pytorch']\n",
        "conda_packages = python_version+additional_conda_packages +base_conda_dep\n",
        "conda_dep = CondaDependencies()\n",
        "pip_packages = additional_pip_packages\n",
        "for conda_package in conda_packages:\n",
        "    conda_dep.add_conda_package(conda_package)\n",
        "\n",
        "for pip_package in pip_packages:\n",
        "    conda_dep.add_pip_package(pip_package)\n",
        "\n",
        "\n",
        "conda_dep.save(\"conda.yml\")\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "'conda.yml'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml import command, Input\n",
        "from azure.identity import DefaultAzureCredential\n",
        "# Enter details of your AML workspace\n",
        "subscription_id = \"840b5c5c-3f4a-459a-94fc-6bad2a969f9d\"\n",
        "resource_group = \"ml\"\n",
        "workspace = \"ws02ent\"\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# create the command\n",
        "job = command(\n",
        "    code=\"./job\",  # local path where the code is stored\n",
        "    command=\"python misc_job.py --diabetes-csv ${{inputs.diabetes}}\",\n",
        "    inputs={\n",
        "        \"diabetes\": Input(\n",
        "            type=\"uri_file\",\n",
        "            path=\"https://azuremlexamples.blob.core.windows.net/datasets/diabetes.csv\",\n",
        "        )\n",
        "    },\n",
        "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n",
        "    compute=\"ds11\",\n",
        "    display_name=\"sklearn-diabetes-example\",\n",
        "    # description,\n",
        "    # experiment_name\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "returned_job = ml_client.create_or_update(job)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot.this issue.\n\tManagedIdentityCredential: No token received.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\n"
        },
        {
          "output_type": "error",
          "ename": "ClientAuthenticationError",
          "evalue": "DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot.this issue.\n\tManagedIdentityCredential: No token received.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mClientAuthenticationError\u001b[0m                 Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m returned_job \u001b[39m=\u001b[39m ml_client\u001b[39m.\u001b[39;49mcreate_or_update(job)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/_ml_client.py:807\u001b[0m, in \u001b[0;36mMLClient.create_or_update\u001b[0;34m(self, entity, **kwargs)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_or_update\u001b[39m(\n\u001b[1;32m    786\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    787\u001b[0m     entity: T,\n\u001b[1;32m    788\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    789\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    790\u001b[0m     \u001b[39m\"\"\"Creates or updates an Azure ML resource.\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \n\u001b[1;32m    792\u001b[0m \u001b[39m    :param entity: The resource to create or update.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[39m        azure.ai.ml.entities.Datastore]\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 807\u001b[0m     \u001b[39mreturn\u001b[39;00m _create_or_update(entity, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_container\u001b[39m.\u001b[39;49mall_operations, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/functools.py:875\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    872\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfuncname\u001b[39m}\u001b[39;00m\u001b[39m requires at least \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    873\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39m1 positional argument\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m \u001b[39mreturn\u001b[39;00m dispatch(args[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/_ml_client.py:865\u001b[0m, in \u001b[0;36m_\u001b[0;34m(entity, operations, **kwargs)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[39m@_create_or_update\u001b[39m\u001b[39m.\u001b[39mregister(Job)\n\u001b[1;32m    863\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(entity: Job, operations, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    864\u001b[0m     module_logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mCreating or updating job\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 865\u001b[0m     \u001b[39mreturn\u001b[39;00m operations[AzureMLResourceType\u001b[39m.\u001b[39;49mJOB]\u001b[39m.\u001b[39;49mcreate_or_update(entity, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_job_operations.py:565\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m     log_and_raise_error(ex)\n\u001b[1;32m    564\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m     \u001b[39mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_job_operations.py:500\u001b[0m, in \u001b[0;36mJobOperations.create_or_update\u001b[0;34m(self, job, description, compute, tags, experiment_name, skip_validation, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate(job, raise_on_failure\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    499\u001b[0m \u001b[39m# Create all dependent resources\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_upload_dependencies(job)\n\u001b[1;32m    502\u001b[0m git_props \u001b[39m=\u001b[39m get_git_properties()\n\u001b[1;32m    503\u001b[0m \u001b[39m# Do not add git props if they already exist in job properties.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[39m# This is for update specifically-- if the user switches branches and tries to update\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[39m# their job, the request will fail since the git props will be repopulated.\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[39m# MFE does not allow existing properties to be updated, only for new props to be added\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_job_operations.py:843\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_upload_dependencies\u001b[0;34m(self, job)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_resolve_arm_id_or_upload_dependencies\u001b[39m(\u001b[39mself\u001b[39m, job: Job) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    834\u001b[0m     \u001b[39m\"\"\"This method converts name or name:version to ARM id. Or it\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[39m    registers/uploads nested dependencies.\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[39m    :rtype: Job\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 843\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_or_azureml_id(job, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_orchestrators\u001b[39m.\u001b[39;49mget_asset_arm_id)\n\u001b[1;32m    845\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, PipelineJob):\n\u001b[1;32m    846\u001b[0m         \u001b[39m# Resolve top-level inputs\u001b[39;00m\n\u001b[1;32m    847\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_pipeline_job_inputs(job, job\u001b[39m.\u001b[39m_base_path)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_job_operations.py:1047\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_or_azureml_id\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n\u001b[1;32m   1046\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, Command):\n\u001b[0;32m-> 1047\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_arm_id_for_command_job(job, resolver)\n\u001b[1;32m   1048\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(job, ImportJob):\n\u001b[1;32m   1049\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_arm_id_for_import_job(job, resolver)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_job_operations.py:1084\u001b[0m, in \u001b[0;36mJobOperations._resolve_arm_id_for_command_job\u001b[0;34m(self, job, resolver)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[39mraise\u001b[39;00m ValidationException(\n\u001b[1;32m   1076\u001b[0m         message\u001b[39m=\u001b[39mmsg\u001b[39m.\u001b[39mformat(job\u001b[39m.\u001b[39mcode),\n\u001b[1;32m   1077\u001b[0m         target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mJOB,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1080\u001b[0m         error_type\u001b[39m=\u001b[39mValidationErrorType\u001b[39m.\u001b[39mINVALID_VALUE,\n\u001b[1;32m   1081\u001b[0m     )\n\u001b[1;32m   1083\u001b[0m \u001b[39mif\u001b[39;00m job\u001b[39m.\u001b[39mcode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_ARM_id_for_resource(job\u001b[39m.\u001b[39mcode, AzureMLResourceType\u001b[39m.\u001b[39mCODE):\n\u001b[0;32m-> 1084\u001b[0m     job\u001b[39m.\u001b[39mcode \u001b[39m=\u001b[39m resolver(\n\u001b[1;32m   1085\u001b[0m         Code(base_path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49m_base_path, path\u001b[39m=\u001b[39;49mjob\u001b[39m.\u001b[39;49mcode),\n\u001b[1;32m   1086\u001b[0m         azureml_type\u001b[39m=\u001b[39;49mAzureMLResourceType\u001b[39m.\u001b[39;49mCODE,\n\u001b[1;32m   1087\u001b[0m     )\n\u001b[1;32m   1088\u001b[0m job\u001b[39m.\u001b[39menvironment \u001b[39m=\u001b[39m resolver(job\u001b[39m.\u001b[39menvironment, azureml_type\u001b[39m=\u001b[39mAzureMLResourceType\u001b[39m.\u001b[39mENVIRONMENT)\n\u001b[1;32m   1089\u001b[0m job\u001b[39m.\u001b[39mcompute \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resolve_compute_id(resolver, job\u001b[39m.\u001b[39mcompute)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_operation_orchestrator.py:214\u001b[0m, in \u001b[0;36mOperationOrchestrator.get_asset_arm_id\u001b[0;34m(self, asset, azureml_type, register_asset, sub_workspace_resource)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     \u001b[39m# TODO: once the asset redesign is finished, this logic can be replaced with unified API\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[39mif\u001b[39;00m azureml_type \u001b[39m==\u001b[39m AzureMLResourceType\u001b[39m.\u001b[39mCODE \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(asset, Code):\n\u001b[0;32m--> 214\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_code_asset_arm_id(asset, register_asset\u001b[39m=\u001b[39;49mregister_asset)\n\u001b[1;32m    215\u001b[0m     \u001b[39melif\u001b[39;00m azureml_type \u001b[39m==\u001b[39m AzureMLResourceType\u001b[39m.\u001b[39mENVIRONMENT \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(asset, Environment):\n\u001b[1;32m    216\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_environment_arm_id(asset, register_asset\u001b[39m=\u001b[39mregister_asset)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_operation_orchestrator.py:271\u001b[0m, in \u001b[0;36mOperationOrchestrator._get_code_asset_arm_id\u001b[0;34m(self, code_asset, register_asset)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[39mreturn\u001b[39;00m uploaded_code_asset\n\u001b[1;32m    270\u001b[0m \u001b[39mexcept\u001b[39;00m (MlException, HttpResponseError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 271\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    272\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    273\u001b[0m     \u001b[39mraise\u001b[39;00m AssetException(\n\u001b[1;32m    274\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError with code: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    275\u001b[0m         target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mASSET,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m         error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mSYSTEM_ERROR,\n\u001b[1;32m    279\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_operation_orchestrator.py:255\u001b[0m, in \u001b[0;36mOperationOrchestrator._get_code_asset_arm_id\u001b[0;34m(self, code_asset, register_asset)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_datastore_name(code_asset\u001b[39m.\u001b[39mpath)\n\u001b[1;32m    254\u001b[0m \u001b[39mif\u001b[39;00m register_asset:\n\u001b[0;32m--> 255\u001b[0m     code_asset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_code_assets\u001b[39m.\u001b[39;49mcreate_or_update(code_asset)\n\u001b[1;32m    256\u001b[0m     \u001b[39mreturn\u001b[39;00m code_asset\u001b[39m.\u001b[39mid\n\u001b[1;32m    257\u001b[0m uploaded_code_asset, _ \u001b[39m=\u001b[39m _check_and_upload_path(\n\u001b[1;32m    258\u001b[0m     artifact\u001b[39m=\u001b[39mcode_asset,\n\u001b[1;32m    259\u001b[0m     asset_operations\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_code_assets,\n\u001b[1;32m    260\u001b[0m     artifact_type\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mCODE,\n\u001b[1;32m    261\u001b[0m     show_progress\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_operation_config\u001b[39m.\u001b[39mshow_progress,\n\u001b[1;32m    262\u001b[0m )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_code_operations.py:141\u001b[0m, in \u001b[0;36mCodeOperations.create_or_update\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mstr\u001b[39m(ex) \u001b[39m==\u001b[39m ASSET_PATH_ERROR:\n\u001b[1;32m    135\u001b[0m         \u001b[39mraise\u001b[39;00m AssetPathException(\n\u001b[1;32m    136\u001b[0m             message\u001b[39m=\u001b[39mCHANGED_ASSET_PATH_MSG,\n\u001b[1;32m    137\u001b[0m             target\u001b[39m=\u001b[39mErrorTarget\u001b[39m.\u001b[39mCODE,\n\u001b[1;32m    138\u001b[0m             no_personal_data_message\u001b[39m=\u001b[39mCHANGED_ASSET_PATH_MSG_NO_PERSONAL_DATA,\n\u001b[1;32m    139\u001b[0m             error_category\u001b[39m=\u001b[39mErrorCategory\u001b[39m.\u001b[39mUSER_ERROR,\n\u001b[1;32m    140\u001b[0m         )\n\u001b[0;32m--> 141\u001b[0m \u001b[39mraise\u001b[39;00m ex\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_code_operations.py:94\u001b[0m, in \u001b[0;36mCodeOperations.create_or_update\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_registry_name:\n\u001b[1;32m     86\u001b[0m     sas_uri \u001b[39m=\u001b[39m get_sas_uri_for_registry_asset(\n\u001b[1;32m     87\u001b[0m         service_client\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_service_client,\n\u001b[1;32m     88\u001b[0m         name\u001b[39m=\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m         body\u001b[39m=\u001b[39mget_asset_body_for_registry_storage(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_registry_name, \u001b[39m\"\u001b[39m\u001b[39mcodes\u001b[39m\u001b[39m\"\u001b[39m, name, version),\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 94\u001b[0m code, _ \u001b[39m=\u001b[39m _check_and_upload_path(\n\u001b[1;32m     95\u001b[0m     artifact\u001b[39m=\u001b[39;49mcode, asset_operations\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, sas_uri\u001b[39m=\u001b[39;49msas_uri, artifact_type\u001b[39m=\u001b[39;49mErrorTarget\u001b[39m.\u001b[39;49mCODE\n\u001b[1;32m     96\u001b[0m )\n\u001b[1;32m     98\u001b[0m \u001b[39m# For anonymous code, if the code already exists in storage, we reuse the name,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39m# version stored in the storage metadata so the same anonymous code won't be created again.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39mif\u001b[39;00m code\u001b[39m.\u001b[39m_is_anonymous:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:399\u001b[0m, in \u001b[0;36m_check_and_upload_path\u001b[0;34m(artifact, asset_operations, artifact_type, datastore_name, sas_uri, show_progress)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m path\u001b[39m.\u001b[39mis_absolute():\n\u001b[1;32m    398\u001b[0m     path \u001b[39m=\u001b[39m Path(artifact\u001b[39m.\u001b[39mbase_path, path)\u001b[39m.\u001b[39mresolve()\n\u001b[0;32m--> 399\u001b[0m uploaded_artifact \u001b[39m=\u001b[39m _upload_to_datastore(\n\u001b[1;32m    400\u001b[0m     asset_operations\u001b[39m.\u001b[39;49m_operation_scope,\n\u001b[1;32m    401\u001b[0m     asset_operations\u001b[39m.\u001b[39;49m_datastore_operation,\n\u001b[1;32m    402\u001b[0m     path,\n\u001b[1;32m    403\u001b[0m     datastore_name\u001b[39m=\u001b[39;49mdatastore_name,\n\u001b[1;32m    404\u001b[0m     asset_name\u001b[39m=\u001b[39;49martifact\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    405\u001b[0m     asset_version\u001b[39m=\u001b[39;49m\u001b[39mstr\u001b[39;49m(artifact\u001b[39m.\u001b[39;49mversion),\n\u001b[1;32m    406\u001b[0m     asset_hash\u001b[39m=\u001b[39;49martifact\u001b[39m.\u001b[39;49m_upload_hash \u001b[39mif\u001b[39;49;00m \u001b[39mhasattr\u001b[39;49m(artifact, \u001b[39m\"\u001b[39;49m\u001b[39m_upload_hash\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    407\u001b[0m     sas_uri\u001b[39m=\u001b[39;49msas_uri,\n\u001b[1;32m    408\u001b[0m     artifact_type\u001b[39m=\u001b[39;49martifact_type,\n\u001b[1;32m    409\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m    410\u001b[0m )\n\u001b[1;32m    411\u001b[0m indicator_file \u001b[39m=\u001b[39m uploaded_artifact\u001b[39m.\u001b[39mindicator_file  \u001b[39m# reference to storage contents\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[39mif\u001b[39;00m artifact\u001b[39m.\u001b[39m_is_anonymous:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:297\u001b[0m, in \u001b[0;36m_upload_to_datastore\u001b[0;34m(operation_scope, datastore_operation, path, artifact_type, datastore_name, show_progress, asset_name, asset_version, asset_hash, ignore_file, sas_uri)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m asset_hash:\n\u001b[1;32m    296\u001b[0m     asset_hash \u001b[39m=\u001b[39m get_object_hash(path, ignore_file)\n\u001b[0;32m--> 297\u001b[0m artifact \u001b[39m=\u001b[39m upload_artifact(\n\u001b[1;32m    298\u001b[0m     \u001b[39mstr\u001b[39;49m(path),\n\u001b[1;32m    299\u001b[0m     datastore_operation,\n\u001b[1;32m    300\u001b[0m     operation_scope,\n\u001b[1;32m    301\u001b[0m     datastore_name,\n\u001b[1;32m    302\u001b[0m     show_progress\u001b[39m=\u001b[39;49mshow_progress,\n\u001b[1;32m    303\u001b[0m     asset_hash\u001b[39m=\u001b[39;49masset_hash,\n\u001b[1;32m    304\u001b[0m     asset_name\u001b[39m=\u001b[39;49masset_name,\n\u001b[1;32m    305\u001b[0m     asset_version\u001b[39m=\u001b[39;49masset_version,\n\u001b[1;32m    306\u001b[0m     ignore_file\u001b[39m=\u001b[39;49mignore_file,\n\u001b[1;32m    307\u001b[0m     sas_uri\u001b[39m=\u001b[39;49msas_uri,\n\u001b[1;32m    308\u001b[0m )\n\u001b[1;32m    309\u001b[0m \u001b[39mreturn\u001b[39;00m artifact\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:175\u001b[0m, in \u001b[0;36mupload_artifact\u001b[0;34m(local_path, datastore_operation, operation_scope, datastore_name, asset_hash, show_progress, asset_name, asset_version, ignore_file, sas_uri)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     datastore_name \u001b[39m=\u001b[39m _get_datastore_name(datastore_name\u001b[39m=\u001b[39mdatastore_name)\n\u001b[0;32m--> 175\u001b[0m     datastore_info \u001b[39m=\u001b[39m get_datastore_info(datastore_operation, datastore_name)\n\u001b[1;32m    176\u001b[0m     storage_client \u001b[39m=\u001b[39m get_storage_client(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdatastore_info)\n\u001b[1;32m    178\u001b[0m artifact_info \u001b[39m=\u001b[39m storage_client\u001b[39m.\u001b[39mupload(\n\u001b[1;32m    179\u001b[0m     local_path,\n\u001b[1;32m    180\u001b[0m     asset_hash\u001b[39m=\u001b[39masset_hash,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m     ignore_file\u001b[39m=\u001b[39mignore_file,\n\u001b[1;32m    185\u001b[0m )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/_artifacts/_artifact_utilities.py:68\u001b[0m, in \u001b[0;36mget_datastore_info\u001b[0;34m(operations, name)\u001b[0m\n\u001b[1;32m     66\u001b[0m datastore_info \u001b[39m=\u001b[39m {}\n\u001b[1;32m     67\u001b[0m \u001b[39mif\u001b[39;00m name:\n\u001b[0;32m---> 68\u001b[0m     datastore \u001b[39m=\u001b[39m operations\u001b[39m.\u001b[39;49mget(name, include_secrets\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     69\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     datastore \u001b[39m=\u001b[39m operations\u001b[39m.\u001b[39mget_default(include_secrets\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/operations/_datastore_operations.py:106\u001b[0m, in \u001b[0;36mDatastoreOperations.get\u001b[0;34m(self, name, include_secrets)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m\"\"\"Returns information about the datastore referenced by the given\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[39mname.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m:rtype: Datastore\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 106\u001b[0m     datastore_resource \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation\u001b[39m.\u001b[39;49mget(\n\u001b[1;32m    107\u001b[0m         name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    108\u001b[0m         resource_group_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_operation_scope\u001b[39m.\u001b[39;49mresource_group_name,\n\u001b[1;32m    109\u001b[0m         workspace_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_workspace_name,\n\u001b[1;32m    110\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_kwargs\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m include_secrets:\n\u001b[1;32m    113\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetch_and_populate_secret(datastore_resource)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/ai/ml/_restclient/v2022_05_01/operations/_datastores_operations.py:483\u001b[0m, in \u001b[0;36mDatastoresOperations.get\u001b[0;34m(self, resource_group_name, workspace_name, name, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m request \u001b[39m=\u001b[39m _convert_request(request)\n\u001b[1;32m    481\u001b[0m request\u001b[39m.\u001b[39murl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mformat_url(request\u001b[39m.\u001b[39murl)\n\u001b[0;32m--> 483\u001b[0m pipeline_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_pipeline\u001b[39m.\u001b[39;49mrun(request, stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    484\u001b[0m response \u001b[39m=\u001b[39m pipeline_response\u001b[39m.\u001b[39mhttp_response\n\u001b[1;32m    486\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m200\u001b[39m]:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/core/pipeline/_base.py:211\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m pipeline_request \u001b[39m=\u001b[39m PipelineRequest(\n\u001b[1;32m    204\u001b[0m     request, context\n\u001b[1;32m    205\u001b[0m )  \u001b[39m# type: PipelineRequest[HTTPRequestType]\u001b[39;00m\n\u001b[1;32m    206\u001b[0m first_node \u001b[39m=\u001b[39m (\n\u001b[1;32m    207\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies[\u001b[39m0\u001b[39m]\n\u001b[1;32m    208\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m _TransportRunner(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport)\n\u001b[1;32m    210\u001b[0m )\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m first_node\u001b[39m.\u001b[39;49msend(pipeline_request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/core/pipeline/_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     69\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/core/pipeline/_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     69\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
            "    \u001b[0;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 71 (2 times)]\u001b[0m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/core/pipeline/_base.py:71\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     69\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     70\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/mgmt/core/policies/_base.py:47\u001b[0m, in \u001b[0;36mARMAutoResourceProviderRegistrationPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend\u001b[39m(\u001b[39mself\u001b[39m, request):\n\u001b[1;32m     45\u001b[0m     \u001b[39m# type: (PipelineRequest[HTTPRequestType], Any) -> PipelineResponse[HTTPRequestType, HTTPResponseType]\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     http_request \u001b[39m=\u001b[39m request\u001b[39m.\u001b[39mhttp_request\n\u001b[0;32m---> 47\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mhttp_response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m409\u001b[39m:\n\u001b[1;32m     49\u001b[0m         rp_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_rp_not_registered_err(response)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/core/pipeline/policies/_redirect.py:153\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    151\u001b[0m redirect_settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfigure_redirects(request\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39moptions)\n\u001b[1;32m    152\u001b[0m \u001b[39mwhile\u001b[39;00m retryable:\n\u001b[0;32m--> 153\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m    154\u001b[0m     redirect_location \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_redirect_location(response)\n\u001b[1;32m    155\u001b[0m     \u001b[39mif\u001b[39;00m redirect_location \u001b[39mand\u001b[39;00m redirect_settings[\u001b[39m'\u001b[39m\u001b[39mallow\u001b[39m\u001b[39m'\u001b[39m]:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/core/pipeline/policies/_retry.py:445\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    443\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    444\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_timeout(request, absolute_timeout, is_response_error)\n\u001b[0;32m--> 445\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m    446\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_retry(retry_settings, response):\n\u001b[1;32m    447\u001b[0m     retry_active \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincrement(retry_settings, response\u001b[39m=\u001b[39mresponse)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/core/pipeline/policies/_authentication.py:111\u001b[0m, in \u001b[0;36mBearerTokenCredentialPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend\u001b[39m(\u001b[39mself\u001b[39m, request):\n\u001b[1;32m    105\u001b[0m     \u001b[39m# type: (PipelineRequest) -> PipelineResponse\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     \u001b[39m\"\"\"Authorize request with a bearer token and send it to the next policy\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[39m    :param request: The pipeline request object\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39m    :type request: ~azure.core.pipeline.PipelineRequest\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_request(request)\n\u001b[1;32m    112\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext\u001b[39m.\u001b[39msend(request)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/core/pipeline/policies/_authentication.py:88\u001b[0m, in \u001b[0;36mBearerTokenCredentialPolicy.on_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enforce_https(request)\n\u001b[1;32m     87\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_new_token:\n\u001b[0;32m---> 88\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_credential\u001b[39m.\u001b[39;49mget_token(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_scopes)\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_headers(request\u001b[39m.\u001b[39mhttp_request\u001b[39m.\u001b[39mheaders, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_token\u001b[39m.\u001b[39mtoken)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/identity/_credentials/default.py:172\u001b[0m, in \u001b[0;36mDefaultAzureCredential.get_token\u001b[0;34m(self, *scopes, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     _LOGGER\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    168\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m acquired a token from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_successful_credential\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    170\u001b[0m     \u001b[39mreturn\u001b[39;00m token\n\u001b[0;32m--> 172\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(DefaultAzureCredential, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mget_token(\u001b[39m*\u001b[39;49mscopes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/azure/identity/_credentials/chained.py:108\u001b[0m, in \u001b[0;36mChainedTokenCredential.get_token\u001b[0;34m(self, *scopes, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m message \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m failed to retrieve a token from the included credentials.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m attempts \\\n\u001b[1;32m    105\u001b[0m           \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTo mitigate this issue, please refer to the troubleshooting guidelines here at \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m    106\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mhttps://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m _LOGGER\u001b[39m.\u001b[39mwarning(message)\n\u001b[0;32m--> 108\u001b[0m \u001b[39mraise\u001b[39;00m ClientAuthenticationError(message\u001b[39m=\u001b[39mmessage)\n",
            "\u001b[0;31mClientAuthenticationError\u001b[0m: DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n\tEnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\nVisit https://aka.ms/azsdk/python/identity/environmentcredential/troubleshoot to troubleshoot.this issue.\n\tManagedIdentityCredential: No token received.\nTo mitigate this issue, please refer to the troubleshooting guidelines here at https://aka.ms/azsdk/python/identity/defaultazurecredential/troubleshoot."
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1670115536580
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "9169f1d4e16acc976bbb73e323b0dbdf23f1c55e833fb2befffc4fb50ac2de2f"
      }
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}