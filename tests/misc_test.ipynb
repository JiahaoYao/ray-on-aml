{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Testing with SDK v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml import command, Input\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import sys\n",
        "\n",
        "# Enter details of your AML workspace\n",
        "subscription_id = \"840b5c5c-3f4a-459a-94fc-6bad2a969f9d\"\n",
        "resource_group = \"ml\"\n",
        "workspace = \"ws02ent\"\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")\n",
        "\n",
        "sys.path.append(\"../\") # go to parent dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "\n",
        "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"ds11\" )\n",
        "#Note that if you need to customize the pip installation of the cluster, you also needs to support the ray package e.g. ray[data] which \n",
        "#match the version of the ray package(s) in your compute instance. If you don't specify pip_packages then ray[default] is inserted \n",
        "#automatically\n",
        "\n",
        "#For use as client mode, uncomment these lines\n",
        "# ray = ray_on_aml.getRay(num_node=2,pip_packages=[\"ray[data]\",\"fastparquet\", \"azureml-mlflow\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs\", \"fsspec\"])\n",
        "# client = ray.init(f\"ray://{ray_on_aml.headnode_private_ip}:10001\")\n",
        "\n",
        "#use CI as head node\n",
        "ray = ray_on_aml.getRay(ci_is_head=True, num_node=2,pip_packages=[\"ray[data]\", \"fastparquet\", \"azureml-mlflow\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs\", \"fsspec\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: the provided asset name 'ray-on-aml-2600608766' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'ray-on-aml-2600608766' will not be used for anonymous registration\n",
            "\u001b[32mUploading .tmp (0.0 MBs): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4211/4211 [00:00<00:00, 108466.94it/s]\u001b[0m\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting cluster to start and return head node's ip\n",
            ".....\n",
            " cluster is ready, head node ip  10.0.0.8\n"
          ]
        }
      ],
      "source": [
        "#Example of using input and output for interactive job\n",
        "from azure.ai.ml import command, Input, Output\n",
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "import logging\n",
        "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"ds11\", verbosity=logging.INFO )\n",
        "\n",
        "inputs={\n",
        "\n",
        "    \"ISDWeather\": Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/adlsstore0001/paths/ISDWeather/year=2008\",\n",
        "    )\n",
        "}\n",
        "\n",
        "outputs={\n",
        "    \"output1\": Output(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/adlsstore0001/paths/dev\",\n",
        "    ),\n",
        "    \"output2\": Output(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/adlsstore0001/paths/dev\",\n",
        "    )\n",
        "}\n",
        "\n",
        "ray = ray_on_aml.getRay(inputs = inputs,outputs=outputs, num_node=2,pip_packages=[\"ray[data]\", \"fastparquet\", \"azureml-mlflow\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs\", \"fsspec\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'object_store_memory': 4305602150.0,\n",
              " 'CPU': 2.0,\n",
              " 'node:10.0.0.8': 1.0,\n",
              " 'memory': 8611204302.0}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client = ray.init(f\"ray://{ray_on_aml.headnode_private_ip}:10001\")\n",
        "\n",
        "ray.cluster_resources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m /azureml-envs/azureml_118a0a3f1c505e56ae5dec61b113db5b/lib/python3.10/site-packages/ray/dashboard/agent.py:50: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m   aiogrpc.init_grpc_aio()\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m /azureml-envs/azureml_118a0a3f1c505e56ae5dec61b113db5b/lib/python3.10/site-packages/ray/dashboard/agent.py:468: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m   loop = asyncio.get_event_loop()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'master_ip': 'None',\n",
              " 'ISDWeather': '/mnt/azureml/cr/j/43c0b9ebce9445aaa0254793e4dc8e37/cap/data-capability/wd/INPUT_ISDWeather',\n",
              " 'output1': '/mnt/azureml/cr/j/43c0b9ebce9445aaa0254793e4dc8e37/cap/data-capability/wd/output1',\n",
              " 'output2': '/mnt/azureml/cr/j/43c0b9ebce9445aaa0254793e4dc8e37/cap/data-capability/wd/output2'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ray_on_aml.mount_points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(_get_read_tasks pid=274)\u001b[0m [dataset]: Run `pip install tqdm` to enable progress reporting.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m /azureml-envs/azureml_118a0a3f1c505e56ae5dec61b113db5b/lib/python3.10/site-packages/ray/dashboard/agent.py:50: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m   aiogrpc.init_grpc_aio()\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m /azureml-envs/azureml_118a0a3f1c505e56ae5dec61b113db5b/lib/python3.10/site-packages/ray/dashboard/agent.py:468: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m   loop = asyncio.get_event_loop()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97581959\n"
          ]
        }
      ],
      "source": [
        "# from adlfs import AzureBlobFileSystem\n",
        "# import dask.dataframe as dd\n",
        "# from ray.util.dask import ray_dask_get, enable_dask_on_ray, disable_dask_on_ray\n",
        "# enable_dask_on_ray()\n",
        "# abfs = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
        "\n",
        "# storage_options = {'account_name': 'azureopendatastorage'}\n",
        "# ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
        "\n",
        "data = ray.data.read_parquet(ray_on_aml.mount_points['ISDWeather'])\n",
        "\n",
        "# data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs)\n",
        "print(data.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.disconnect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Testing with SDK v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray_on_aml.shutdown(end_all_runs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Workspace\n",
        "import sys\n",
        "sys.path.append(\"../\") # go to parent dir\n",
        "import importlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "import ray\n",
        "ws = Workspace.from_config()\n",
        "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"ds11\",maxnode=2)\n",
        "ray_on_aml.getRay(num_node=2,pip_packages=[\"torch==1.13.0\", \"azureml-mlflow\"], ci_is_head=True)\n",
        "\n",
        "# head_ip = ray_on_aml.getRay(num_node=2,pip_packages=[\"torch==1.13.0\", \"azureml-mlflow\"], ci_is_head=True)\n",
        "\n",
        "# client = ray.init(f\"ray://{head_ip}:10001\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray.cluster_resources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray_on_aml.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ray\n",
        "\n",
        "# Load data.\n",
        "dataset = ray.data.read_csv(\"https://azuremlexamples.blob.core.windows.net/datasets/iris.csv\").repartition(4)\n",
        "\n",
        "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
        "\n",
        "# Create a test dataset by dropping the target column.\n",
        "test_dataset = valid_dataset.drop_columns(cols=[\"target\"])\n",
        "# Create a preprocessor to scale some columns.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from ray.data.preprocessors import Concatenator, Chain, StandardScaler\n",
        "\n",
        "# Create a preprocessor to scale some columns and concatenate the result.\n",
        "# preprocessor = Chain(\n",
        "#     StandardScaler(columns=[\"mean radius\", \"mean texture\"]),\n",
        "#     Concatenator(exclude=[\"target\"], dtype=np.float32),\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install pyarrow==6.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
        "\n",
        "from ray import train\n",
        "from ray.air import session\n",
        "from ray.air.config import ScalingConfig\n",
        "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
        "\n",
        "\n",
        "def create_model(input_features):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_features=input_features, out_features=16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "\n",
        "def train_loop_per_worker(config):\n",
        "    batch_size = config[\"batch_size\"]\n",
        "    lr = config[\"lr\"]\n",
        "    epochs = config[\"num_epochs\"]\n",
        "    num_features = config[\"num_features\"]\n",
        "\n",
        "    # Get the Ray Dataset shard for this data parallel worker,\n",
        "    # and convert it to a PyTorch Dataset.\n",
        "    train_data = train.get_dataset_shard(\"train\")\n",
        "    # Create model.\n",
        "    model = create_model(num_features)\n",
        "    model = train.torch.prepare_model(model)\n",
        "\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    for cur_epoch in range(epochs):\n",
        "        for batch in train_data.iter_torch_batches(\n",
        "            batch_size=batch_size, dtypes=torch.float32\n",
        "        ):\n",
        "            # \"concat_out\" is the output column of the Concatenator.\n",
        "            inputs, labels = batch[\"concat_out\"], batch[\"target\"]\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            train_loss = loss_fn(predictions, labels.unsqueeze(1))\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "        loss = train_loss.item()\n",
        "        session.report({\"loss\": loss}, checkpoint=TorchCheckpoint.from_model(model))\n",
        "\n",
        "\n",
        "num_features = len(train_dataset.schema().names) - 1\n",
        "\n",
        "trainer = TorchTrainer(\n",
        "    train_loop_per_worker=train_loop_per_worker,\n",
        "    train_loop_config={\n",
        "        \"batch_size\": 128,\n",
        "        \"num_epochs\": 20,\n",
        "        \"num_features\": num_features,\n",
        "        \"lr\": 0.001,\n",
        "    },\n",
        "    scaling_config=ScalingConfig(\n",
        "        num_workers=2,  # Number of workers to use for data parallelism.\n",
        "        use_gpu=False,\n",
        "        trainer_resources={\"CPU\": 1},  # so that the example works on Colab.\n",
        "    ),\n",
        "    datasets={\"train\": train_dataset},\n",
        "    preprocessor=preprocessor,\n",
        ")\n",
        "# Execute training.\n",
        "result = trainer.fit()\n",
        "print(f\"Last result: {result.metrics}\")\n",
        "# Last result: {'loss': 0.6559339960416158, ...}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install --upgrade ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray_on_aml.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ray\n",
        "client = ray.init(f\"ray://{head_ip}:10001\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.disconnect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('azureml_py310_sdkv2')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
