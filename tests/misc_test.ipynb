{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Testing with SDK v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml import command, Input\n",
        "from azure.identity import DefaultAzureCredential\n",
        "import sys\n",
        "\n",
        "# Enter details of your AML workspace\n",
        "subscription_id = \"840b5c5c-3f4a-459a-94fc-6bad2a969f9d\"\n",
        "resource_group = \"ml\"\n",
        "workspace = \"ws02ent\"\n",
        "# get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")\n",
        "\n",
        "sys.path.append(\"../\") # go to parent dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/anaconda/envs/azureml_py38/bin//ray\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 2588, in main\n",
            "    return cli()\n",
            "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/click/core.py\", line 1130, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/click/core.py\", line 1055, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/click/core.py\", line 1657, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/click/core.py\", line 1404, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/click/core.py\", line 760, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/cli_logger.py\", line 852, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/scripts/scripts.py\", line 739, in start\n",
            "    raise ConnectionError(\n",
            "ConnectionError: Ray is trying to start at 10.0.0.4:6379, but is already running at 10.0.0.4:6379. Please specify a different port using the `--port` flag of `ray start` command.\n",
            "Warning: the provided asset name 'ray-on-aml-2600608766' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'ray-on-aml-2600608766' will not be used for anonymous registration\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for cluster to start\n",
            "..."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.6)\u001b[0m /azureml-envs/azureml_118a0a3f1c505e56ae5dec61b113db5b/lib/python3.10/site-packages/ray/dashboard/agent.py:50: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.6)\u001b[0m   aiogrpc.init_grpc_aio()\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.6)\u001b[0m /azureml-envs/azureml_118a0a3f1c505e56ae5dec61b113db5b/lib/python3.10/site-packages/ray/dashboard/agent.py:468: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.6)\u001b[0m   loop = asyncio.get_event_loop()\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.10)\u001b[0m /azureml-envs/azureml_118a0a3f1c505e56ae5dec61b113db5b/lib/python3.10/site-packages/ray/dashboard/agent.py:50: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.10)\u001b[0m   aiogrpc.init_grpc_aio()\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.10)\u001b[0m /azureml-envs/azureml_118a0a3f1c505e56ae5dec61b113db5b/lib/python3.10/site-packages/ray/dashboard/agent.py:468: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.10)\u001b[0m   loop = asyncio.get_event_loop()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Cluster started successfully\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'Ray_On_AML' object has no attribute 'headnode_private_ip'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#Note that if you need to customize the pip installation of the cluster, you also needs to support the ray package e.g. ray[data] which \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#match the version of the ray package(s) in your compute instance. If you don't specify pip_packages then ray[default] is inserted \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#automatically\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# For use as client mode, uncomment these lines\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m ray \u001b[39m=\u001b[39m ray_on_aml\u001b[39m.\u001b[39mgetRay(ci_is_head\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_node\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,pip_packages\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mray[data]\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mfastparquet\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mazureml-mlflow\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpyarrow==6.0.1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdask==2022.2.0\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39madlfs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfsspec\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m client \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39minit(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mray://\u001b[39m\u001b[39m{\u001b[39;00mray_on_aml\u001b[39m.\u001b[39mheadnode_private_ip\u001b[39m}\u001b[39;00m\u001b[39m:10001\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Ray_On_AML' object has no attribute 'headnode_private_ip'"
          ]
        }
      ],
      "source": [
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "\n",
        "import logging\n",
        "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"ds11\")\n",
        "#Note that if you need to customize the pip installation of the cluster, you also needs to support the ray package e.g. ray[data] which \n",
        "#match the version of the ray package(s) in your compute instance. If you don't specify pip_packages then ray[default] is inserted \n",
        "#automatically\n",
        "\n",
        "# For use as client mode, uncomment these lines\n",
        "ray = ray_on_aml.getRay(ci_is_head=True, num_node=2,pip_packages=[\"ray[data]\",\"fastparquet\", \"azureml-mlflow\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs\", \"fsspec\"])\n",
        "# client = ray.init(f\"ray://{ray_on_aml.headnode_private_ip}:10001\")\n",
        "\n",
        "#use CI as head node\n",
        "\n",
        "# ray = ray_on_aml.getRay(ci_is_head=True, num_node=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: the provided asset name 'ray-on-aml-2600608766' will not be used for anonymous registration\n",
            "Warning: the provided asset name 'ray-on-aml-2600608766' will not be used for anonymous registration\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting cluster to start and return head node's ip\n",
            "..."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 19:54:36,690\tWARNING worker.py:1839 -- The node with node id: d44347aed336b31268cbba5b0ee97a4a65d77d417baf581b77133e7c and address: 10.0.0.8 and node name: 10.0.0.8 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, preempted node, etc.) \n",
            "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "."
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 19:54:40,690\tWARNING worker.py:1839 -- The node with node id: ed0005dbb2d47b243d5f1118cc8e9beffbc364746d336f3830aa2a28 and address: 10.0.0.9 and node name: 10.0.0.9 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, preempted node, etc.) \n",
            "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".........\n",
            " cluster is ready, head node ip  10.0.0.8\n"
          ]
        }
      ],
      "source": [
        "#Example of using input and output for interactive job\n",
        "from azure.ai.ml import command, Input, Output\n",
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "import logging\n",
        "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"ds11\", verbosity=logging.INFO )\n",
        "\n",
        "inputs={\n",
        "\n",
        "    \"ISDWeather\": Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/adlsstore0001/paths/ISDWeather/year=2008\",\n",
        "    )\n",
        "}\n",
        "\n",
        "outputs={\n",
        "    \"output1\": Output(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/adlsstore0001/paths/dev\",\n",
        "    ),\n",
        "    \"output2\": Output(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml://datastores/adlsstore0001/paths/dev\",\n",
        "    )\n",
        "}\n",
        "\n",
        "ray = ray_on_aml.getRay(inputs = inputs,outputs=outputs, num_node=2,pip_packages=[\"ray[data]\", \"fastparquet\", \"azureml-mlflow\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs\", \"fsspec\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'object_store_memory': 10938155827.0,\n",
              " 'node:10.0.0.4': 1.0,\n",
              " 'CPU': 6.0,\n",
              " 'memory': 24778350183.0,\n",
              " 'node:10.0.0.6': 1.0,\n",
              " 'node:10.0.0.10': 1.0}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "ray.cluster_resources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Log channel is reconnecting. Logs produced while the connection was down can be found on the head node of the cluster in `ray_client_server_[port].out`\n",
            "2022-12-14 22:17:01,329\tWARNING dataclient.py:396 -- Encountered connection issues in the data channel. Attempting to reconnect.\n",
            "2022-12-14 22:17:31,533\tWARNING dataclient.py:403 -- Failed to reconnect the data channel\n"
          ]
        }
      ],
      "source": [
        "ray_on_aml.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(_get_read_tasks pid=274)\u001b[0m [dataset]: Run `pip install tqdm` to enable progress reporting.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m /azureml-envs/azureml_118a0a3f1c505e56ae5dec61b113db5b/lib/python3.10/site-packages/ray/dashboard/agent.py:50: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m   aiogrpc.init_grpc_aio()\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m /azureml-envs/azureml_118a0a3f1c505e56ae5dec61b113db5b/lib/python3.10/site-packages/ray/dashboard/agent.py:468: DeprecationWarning: There is no current event loop\n",
            "\u001b[2m\u001b[33m(raylet, ip=10.0.0.9)\u001b[0m   loop = asyncio.get_event_loop()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97581959\n"
          ]
        }
      ],
      "source": [
        "# from adlfs import AzureBlobFileSystem\n",
        "# import dask.dataframe as dd\n",
        "# from ray.util.dask import ray_dask_get, enable_dask_on_ray, disable_dask_on_ray\n",
        "# enable_dask_on_ray()\n",
        "# abfs = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
        "\n",
        "# storage_options = {'account_name': 'azureopendatastorage'}\n",
        "# ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
        "\n",
        "data = ray.data.read_parquet(ray_on_aml.mount_points['ISDWeather'])\n",
        "\n",
        "# data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs)\n",
        "print(data.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.disconnect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Testing with SDK v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Workspace\n",
        "import sys\n",
        "sys.path.append(\"../\") # go to parent dir\n",
        "import importlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting cluster to start and return head node ip\n",
            ".."
          ]
        }
      ],
      "source": [
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "import ray\n",
        "ws = Workspace.from_config()\n",
        "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"ds11\",maxnode=2)\n",
        "# ray_on_aml.getRay(num_node=2,pip_packages=[\"torch==1.13.0\", \"azureml-mlflow\"], ci_is_head=True)\n",
        "ray = ray_on_aml.getRay(num_node=2,pip_packages=[\"ray[data]==2.1.0\",\"fastparquet==2022.12.0\", \"azureml-mlflow==1.48.0\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs==2022.11.2\", \"fsspec==2022.11.0\"])\n",
        "\n",
        "client = ray.init(f\"ray://{ray_on_aml.headnode_private_ip}:10001\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'object_store_memory': 10911909886.0,\n",
              " 'node:10.0.0.4': 1.0,\n",
              " 'CPU': 6.0,\n",
              " 'memory': 24723150441.0,\n",
              " 'node:10.0.0.6': 1.0,\n",
              " 'node:10.0.0.10': 1.0}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ray.cluster_resources()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "RayTaskError(ImportError)",
          "evalue": "\u001b[36mray::_get_read_tasks()\u001b[39m (pid=212508, ip=10.0.0.4)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/read_api.py\", line 1380, in _get_read_tasks\n    reader = ds.create_reader(**kwargs)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/datasource/file_based_datasource.py\", line 219, in create_reader\n    return _FileBasedDatasourceReader(self, **kwargs)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/datasource/file_based_datasource.py\", line 378, in __init__\n    paths, self._filesystem = _resolve_paths_and_filesystem(paths, filesystem)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/datasource/file_based_datasource.py\", line 666, in _resolve_paths_and_filesystem\n    raise ImportError(\nImportError: Please install fsspec to read files from HTTP.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRayTaskError(ImportError)\u001b[0m                 Traceback (most recent call last)",
            "\u001b[1;32m/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load data.\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m dataset \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://azuremlexamples.blob.core.windows.net/datasets/iris.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mrepartition(\u001b[39m4\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m train_dataset, valid_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mtrain_test_split(test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f38343062356335632d336634612d343539612d393466632d3662616432613936396639642f7265736f7572636547726f7570732f6d6c2f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f77733032656e742f636f6d70757465732f647331316369/home/azureuser/cloudfiles/code/Users/janguy/ray-on-aml/tests/misc_test.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Create a test dataset by dropping the target column.\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/read_api.py:744\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(paths, filesystem, parallelism, ray_remote_args, arrow_open_stream_args, meta_provider, partition_filter, partitioning, **arrow_csv_args)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[39m@PublicAPI\u001b[39m\n\u001b[1;32m    658\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_csv\u001b[39m(\n\u001b[1;32m    659\u001b[0m     paths: Union[\u001b[39mstr\u001b[39m, List[\u001b[39mstr\u001b[39m]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39marrow_csv_args,\n\u001b[1;32m    669\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dataset[ArrowRow]:\n\u001b[1;32m    670\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Create an Arrow dataset from csv files.\u001b[39;00m\n\u001b[1;32m    671\u001b[0m \n\u001b[1;32m    672\u001b[0m \u001b[39m    Examples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[39m        Dataset holding Arrow records read from the specified paths.\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[0;32m--> 744\u001b[0m     \u001b[39mreturn\u001b[39;00m read_datasource(\n\u001b[1;32m    745\u001b[0m         CSVDatasource(),\n\u001b[1;32m    746\u001b[0m         parallelism\u001b[39m=\u001b[39;49mparallelism,\n\u001b[1;32m    747\u001b[0m         paths\u001b[39m=\u001b[39;49mpaths,\n\u001b[1;32m    748\u001b[0m         filesystem\u001b[39m=\u001b[39;49mfilesystem,\n\u001b[1;32m    749\u001b[0m         ray_remote_args\u001b[39m=\u001b[39;49mray_remote_args,\n\u001b[1;32m    750\u001b[0m         open_stream_args\u001b[39m=\u001b[39;49marrow_open_stream_args,\n\u001b[1;32m    751\u001b[0m         meta_provider\u001b[39m=\u001b[39;49mmeta_provider,\n\u001b[1;32m    752\u001b[0m         partition_filter\u001b[39m=\u001b[39;49mpartition_filter,\n\u001b[1;32m    753\u001b[0m         partitioning\u001b[39m=\u001b[39;49mpartitioning,\n\u001b[1;32m    754\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49marrow_csv_args,\n\u001b[1;32m    755\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/read_api.py:273\u001b[0m, in \u001b[0;36mread_datasource\u001b[0;34m(datasource, parallelism, ray_remote_args, **read_args)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[39m# Prepare read in a remote task so that in Ray client mode, we aren't\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[39m# attempting metadata resolution from the client machine.\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     get_read_tasks \u001b[39m=\u001b[39m cached_remote_fn(\n\u001b[1;32m    270\u001b[0m         _get_read_tasks, retry_exceptions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_cpus\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    271\u001b[0m     )\n\u001b[0;32m--> 273\u001b[0m     requested_parallelism, min_safe_parallelism, read_tasks \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mget(\n\u001b[1;32m    274\u001b[0m         get_read_tasks\u001b[39m.\u001b[39;49mremote(\n\u001b[1;32m    275\u001b[0m             datasource,\n\u001b[1;32m    276\u001b[0m             ctx,\n\u001b[1;32m    277\u001b[0m             cur_pg,\n\u001b[1;32m    278\u001b[0m             parallelism,\n\u001b[1;32m    279\u001b[0m             _wrap_and_register_arrow_serialization_workaround(read_args),\n\u001b[1;32m    280\u001b[0m         )\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m read_tasks \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(read_tasks) \u001b[39m<\u001b[39m min_safe_parallelism \u001b[39m*\u001b[39m \u001b[39m0.7\u001b[39m:\n\u001b[1;32m    284\u001b[0m     perc \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mround\u001b[39m((min_safe_parallelism \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(read_tasks)) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(read_tasks), \u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/_private/worker.py:2289\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2287\u001b[0m     worker\u001b[39m.\u001b[39mcore_worker\u001b[39m.\u001b[39mdump_object_store_memory_usage()\n\u001b[1;32m   2288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayTaskError):\n\u001b[0;32m-> 2289\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m   2290\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2291\u001b[0m     \u001b[39mraise\u001b[39;00m value\n",
            "\u001b[0;31mRayTaskError(ImportError)\u001b[0m: \u001b[36mray::_get_read_tasks()\u001b[39m (pid=212508, ip=10.0.0.4)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/read_api.py\", line 1380, in _get_read_tasks\n    reader = ds.create_reader(**kwargs)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/datasource/file_based_datasource.py\", line 219, in create_reader\n    return _FileBasedDatasourceReader(self, **kwargs)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/datasource/file_based_datasource.py\", line 378, in __init__\n    paths, self._filesystem = _resolve_paths_and_filesystem(paths, filesystem)\n  File \"/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/ray/data/datasource/file_based_datasource.py\", line 666, in _resolve_paths_and_filesystem\n    raise ImportError(\nImportError: Please install fsspec to read files from HTTP."
          ]
        }
      ],
      "source": [
        "\n",
        "# Load data.\n",
        "dataset = ray.data.read_csv(\"https://azuremlexamples.blob.core.windows.net/datasets/iris.csv\").repartition(4)\n",
        "\n",
        "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
        "\n",
        "# Create a test dataset by dropping the target column.\n",
        "test_dataset = valid_dataset.drop_columns(cols=[\"target\"])\n",
        "# Create a preprocessor to scale some columns.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from ray.data.preprocessors import Concatenator, Chain, StandardScaler\n",
        "\n",
        "# Create a preprocessor to scale some columns and concatenate the result.\n",
        "# preprocessor = Chain(\n",
        "#     StandardScaler(columns=[\"mean radius\", \"mean texture\"]),\n",
        "#     Concatenator(exclude=[\"target\"], dtype=np.float32),\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'node:10.0.0.4': 1.0,\n",
              " 'memory': 4464080487.0,\n",
              " 'CPU': 2.0,\n",
              " 'object_store_memory': 2232040243.0}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ray_on_aml.shutdown(end_all_runs=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
        "\n",
        "from ray import train\n",
        "from ray.air import session\n",
        "from ray.air.config import ScalingConfig\n",
        "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
        "\n",
        "\n",
        "def create_model(input_features):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_features=input_features, out_features=16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 1),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "\n",
        "def train_loop_per_worker(config):\n",
        "    batch_size = config[\"batch_size\"]\n",
        "    lr = config[\"lr\"]\n",
        "    epochs = config[\"num_epochs\"]\n",
        "    num_features = config[\"num_features\"]\n",
        "\n",
        "    # Get the Ray Dataset shard for this data parallel worker,\n",
        "    # and convert it to a PyTorch Dataset.\n",
        "    train_data = train.get_dataset_shard(\"train\")\n",
        "    # Create model.\n",
        "    model = create_model(num_features)\n",
        "    model = train.torch.prepare_model(model)\n",
        "\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    for cur_epoch in range(epochs):\n",
        "        for batch in train_data.iter_torch_batches(\n",
        "            batch_size=batch_size, dtypes=torch.float32\n",
        "        ):\n",
        "            # \"concat_out\" is the output column of the Concatenator.\n",
        "            inputs, labels = batch[\"concat_out\"], batch[\"target\"]\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            train_loss = loss_fn(predictions, labels.unsqueeze(1))\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "        loss = train_loss.item()\n",
        "        session.report({\"loss\": loss}, checkpoint=TorchCheckpoint.from_model(model))\n",
        "\n",
        "\n",
        "num_features = len(train_dataset.schema().names) - 1\n",
        "\n",
        "trainer = TorchTrainer(\n",
        "    train_loop_per_worker=train_loop_per_worker,\n",
        "    train_loop_config={\n",
        "        \"batch_size\": 128,\n",
        "        \"num_epochs\": 20,\n",
        "        \"num_features\": num_features,\n",
        "        \"lr\": 0.001,\n",
        "    },\n",
        "    scaling_config=ScalingConfig(\n",
        "        num_workers=2,  # Number of workers to use for data parallelism.\n",
        "        use_gpu=False,\n",
        "        trainer_resources={\"CPU\": 1},  # so that the example works on Colab.\n",
        "    ),\n",
        "    datasets={\"train\": train_dataset},\n",
        "    preprocessor=preprocessor,\n",
        ")\n",
        "# Execute training.\n",
        "result = trainer.fit()\n",
        "print(f\"Last result: {result.metrics}\")\n",
        "# Last result: {'loss': 0.6559339960416158, ...}"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "azureml_py38",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
