{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Interactive use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1639464905474
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8 is detected.\n",
      "1.9.0 is detected\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ray\n",
    "\n",
    "if not (sys.version_info.major == 3 and sys.version_info.minor == 8):\n",
    "    print(\"Python 3.8 or higher is required.\")\n",
    "    print(\"Change kerner to azureml_py38\")\n",
    "    print(\"                 ^^^^^^^^^^^\")\n",
    "else:\n",
    "    print(f\"{sys.version_info.major}.{sys.version_info.minor} is detected.\")\n",
    "\n",
    "if not ray.__version__.startswith('1.9'):\n",
    "    print(\"User Ray is not 1.9\")\n",
    "    print(\"pip install ray==1.9.0\")\n",
    "    print(\"           ^^^^^^^^^^^\")\n",
    "else:\n",
    "    print(f\"{ray.__version__} is detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1639464907468
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "# from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import platform\n",
    "# from ray_on_azureml.ray_on_aml import getRay\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancel active AML runs if any\n",
      "Canceling active run  ray_on_aml_1640884059_5f98e280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log channel is reconnecting. Logs produced while the connection was down can be found on the head node of the cluster in `ray_client_server_[port].out`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down ray if any\n"
     ]
    }
   ],
   "source": [
    "# ray_on_aml.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "gather": {
     "logged": 1639464931994
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancel active AML runs if any\n",
      "Canceling active run  ray_on_aml_1640886640_42784325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Log channel is reconnecting. Logs produced while the connection was down can be found on the head node of the cluster in `ray_client_server_[port].out`\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down ray if any\n",
      "Found existing cluster worker-cpu-v3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting cluster to start and return head node ip\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    }
   ],
   "source": [
    "from src.ray_on_aml.core import Ray_On_AML\n",
    "ws = Workspace.from_config()\n",
    "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"worker-cpu-v3\", additional_pip_packages=['torch', 'torchvision'])\n",
    "ray = ray_on_aml.getRay(ci_is_head=False)\n",
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "gather": {
     "logged": 1639464969085
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': 48164491266.0,\n",
       " 'object_store_memory': 21248431717.0,\n",
       " 'CPU': 20.0,\n",
       " 'node:10.0.0.19': 1.0,\n",
       " 'node:10.0.0.21': 1.0,\n",
       " 'node:10.0.0.22': 1.0,\n",
       " 'node:10.0.0.17': 1.0,\n",
       " 'node:10.0.0.18': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Dask on Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1639105974201
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7008.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9959</th>\n",
       "      <td>2312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>9460.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>5067.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>4671.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>9987.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade\n",
       "age         \n",
       "6     1101.0\n",
       "11    2967.0\n",
       "22    7928.0\n",
       "31    7008.0\n",
       "32      37.0\n",
       "...      ...\n",
       "9959  2312.0\n",
       "9975  9460.0\n",
       "9982  5067.0\n",
       "9988  4671.0\n",
       "9992  9987.0\n",
       "\n",
       "[985 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ray\n",
    "# ray.init()\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dask.config.set(scheduler=ray_dask_get)\n",
    "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
    "\n",
    "# The Dask scheduler submits the underlying task graph to Ray.\n",
    "d_arr.mean().compute(scheduler=ray_dask_get)\n",
    "\n",
    "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
    "# specify it on each compute call.\n",
    "\n",
    "df = dd.from_pandas(\n",
    "    pd.DataFrame(\n",
    "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
    "    npartitions=2)\n",
    "df.groupby([\"age\"]).mean().compute()\n",
    "\n",
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1639104458150
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:('dataframe-count-chunk-c779cbec183eaab06c239b02895358aa', 0, 2, 0) pid=189, ip=10.0.0.22)\u001b[0m \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vendorID                3297967\n",
       "lpepPickupDatetime      3297967\n",
       "lpepDropoffDatetime     3297967\n",
       "passengerCount          3297967\n",
       "tripDistance            3297967\n",
       "puLocationId            3297967\n",
       "doLocationId            3297967\n",
       "pickupLongitude               0\n",
       "pickupLatitude                0\n",
       "dropoffLongitude              0\n",
       "dropoffLatitude               0\n",
       "rateCodeID              3297967\n",
       "storeAndFwdFlag         3297967\n",
       "paymentType             3297967\n",
       "fareAmount              3297967\n",
       "extra                   3297967\n",
       "mtaTax                  3297967\n",
       "improvementSurcharge    3297967\n",
       "tipAmount               3297967\n",
       "tollsAmount             3297967\n",
       "ehailFee                      0\n",
       "totalAmount             3297967\n",
       "tripType                3297967\n",
       "puMonth                 3297967\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "storage_options = {'account_name': 'azureopendatastorage'}\n",
    "ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
    "ddf.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1639106144831
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata Fetch Progress: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:06<00:00,  2.62it/s]\n",
      "Metadata Fetch Progress: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98904376"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dask\n",
    "\n",
    "# import ray\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Model\n",
    "from adlfs import AzureBlobFileSystem\n",
    "account_key = ws.get_default_keyvault().get_secret(\"adls7-account-key\")\n",
    "account_name=\"adlsgen7\"\n",
    "abfs = AzureBlobFileSystem(account_name=\"adlsgen7\",account_key=account_key,  container_name=\"mltraining\")\n",
    "abfs2 = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
    "\n",
    "\n",
    "storage_options={'account_name': account_name, 'account_key': account_key}\n",
    "\n",
    "# ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year2008', storage_options=storage_options)\n",
    "\n",
    "data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs2)\n",
    "data2 = ray.data.read_parquet(\"az://mltraining/ISDWeatherDelta/year2008\", filesystem=abfs)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.29it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24461/567395666.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"az://isdweatherdatacontainer/ISDWeather/year=2012/\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabfs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"az://isdweatherdatacontainer/ISDWeather/year=2015/\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabfs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"az://isdweatherdatacontainer/ISDWeather/year=2010/\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabfs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mdata3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"az://isdweatherdatacontainer/ISDWeather/year=2009/\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabfs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/data/read_api.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(paths, filesystem, columns, parallelism, ray_remote_args, _tensor_column_schema, **arrow_parquet_args)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0marrow_parquet_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_block_udf\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_block_udf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     return read_datasource(\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mParquetDatasource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mparallelism\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallelism\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/data/read_api.py\u001b[0m in \u001b[0;36mread_datasource\u001b[0;34m(datasource, parallelism, ray_remote_args, _spread_resource_prefix, **read_args)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \"\"\"\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mread_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallelism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mread_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py\u001b[0m in \u001b[0;36mprepare_read\u001b[0;34m(self, parallelism, paths, filesystem, columns, schema, _block_udf, **reader_args)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0minferred_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mread_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mserialized_pieces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpq_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpieces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpq_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpieces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mPARALLELIZE_META_FETCH_THRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_metadata_remotely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_pieces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0minferred_schema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mread_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mserialized_pieces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpq_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpieces\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpq_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpieces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mPARALLELIZE_META_FETCH_THRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_metadata_remotely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserialized_pieces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"recursion\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.ParquetFileFragment.__reduce__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.ParquetFileFragment.row_groups.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.ParquetFileFragment.metadata.__get__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.ParquetFileFragment.ensure_complete_metadata\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/_fs.pyx\u001b[0m in \u001b[0;36mpyarrow._fs._cb_open_input_file\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/fs.py\u001b[0m in \u001b[0;36mopen_input_file\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPythonFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_output_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, block_size, cache_options, **kwargs)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"autocommit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intrans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             f = self._open(\n\u001b[0m\u001b[1;32m   1007\u001b[0m                 \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/adlfs/spec.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, block_size, autocommit, cache_options, cache_type, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1695\u001b[0m         \"\"\"\n\u001b[1;32m   1696\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"_open:  {path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m         return AzureBlobFile(\n\u001b[0m\u001b[1;32m   1698\u001b[0m             \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/adlfs/spec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fs, path, mode, block_size, autocommit, cache_type, cache_options, metadata, **kwargs)\u001b[0m\n\u001b[1;32m   1818\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mcache_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             )\n\u001b[0;32m-> 1820\u001b[0;31m             self.metadata = sync(\n\u001b[0m\u001b[1;32m   1821\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_blob_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m             )\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# this loops allows thread to get interrupted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Model\n",
    "from adlfs import AzureBlobFileSystem\n",
    "account_key = ws.get_default_keyvault().get_secret(\"adls7-account-key\")\n",
    "account_name=\"adlsgen7\"\n",
    "# abfs = AzureBlobFileSystem(account_name=\"adlsgen7\",account_key=account_key,  container_name=\"mltraining\")\n",
    "abfs2 = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
    "\n",
    "\n",
    "storage_options={'account_name': account_name, 'account_key': account_key}\n",
    "\n",
    "# ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year2008', storage_options=storage_options)\n",
    "\n",
    "data = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2012/\"], filesystem=abfs2)\n",
    "data1 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2015/\"], filesystem=abfs2)\n",
    "data2 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2010/\"], filesystem=abfs2)\n",
    "data3 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2009/\"], filesystem=abfs2)\n",
    "data4 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2011/\"], filesystem=abfs2)\n",
    "data5 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2013/\"], filesystem=abfs2)\n",
    "data6 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2014/\"], filesystem=abfs2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Ray Tune for distributed ML tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639106657384
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "# import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # In this example, we don't change the model architecture\n",
    "        # due to simplicity.\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "# Change these values if you want the training to run quicker or slower.\n",
    "EPOCH_SIZE = 512\n",
    "TEST_SIZE = 256\n",
    "\n",
    "def train(model, optimizer, train_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # We set this just for the example to run quickly.\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "            return\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # We set this just for the example to run quickly.\n",
    "            if batch_idx * len(data) > TEST_SIZE:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "def train_mnist(config):\n",
    "    # Data Setup\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = ConvNet()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "    for i in range(10):\n",
    "        train(model, optimizer, train_loader)\n",
    "        acc = test(model, test_loader)\n",
    "\n",
    "        # Send the current training result back to Tune\n",
    "        tune.report(mean_accuracy=acc)\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            # This saves the model to the trial directory\n",
    "            torch.save(model.state_dict(), \"./model.pth\")\n",
    "search_space = {\n",
    "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
    "    \"momentum\": tune.uniform(0.01, 0.09)\n",
    "}\n",
    "\n",
    "# Uncomment this to enable distributed execution\n",
    "# ray.shutdown()\n",
    "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
    "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
    "# Download the dataset first\n",
    "datasets.MNIST(\"~/data\", train=True, download=True)\n",
    "\n",
    "analysis = tune.run(train_mnist, config=search_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639106681808
    }
   },
   "outputs": [],
   "source": [
    " import sklearn.datasets\n",
    " import sklearn.metrics\n",
    " from sklearn.model_selection import train_test_split\n",
    " import xgboost as xgb\n",
    "\n",
    " from ray import tune\n",
    "\n",
    "\n",
    " def train_breast_cancer(config):\n",
    "     # Load dataset\n",
    "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "     # Split into train and test set\n",
    "     train_x, test_x, train_y, test_y = train_test_split(\n",
    "         data, labels, test_size=0.25)\n",
    "     # Build input matrices for XGBoost\n",
    "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
    "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
    "     # Train the classifier\n",
    "     results = {}\n",
    "     xgb.train(\n",
    "         config,\n",
    "         train_set,\n",
    "         evals=[(test_set, \"eval\")],\n",
    "         evals_result=results,\n",
    "         verbose_eval=False)\n",
    "     # Return prediction accuracy\n",
    "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
    "     tune.report(mean_accuracy=accuracy, done=True)\n",
    "\n",
    "\n",
    " config = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"eval_metric\": [\"logloss\", \"error\"],\n",
    "     \"max_depth\": tune.randint(1, 9),\n",
    "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
    "     \"subsample\": tune.uniform(0.5, 1.0),\n",
    "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
    " }\n",
    " analysis = tune.run(\n",
    "     train_breast_cancer,\n",
    "     resources_per_trial={\"cpu\": 1},\n",
    "     config=config,\n",
    "     num_samples=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Spark on Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:48:42,187\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2021-12-06 19:48:45,043 WARN Utils [Thread-1]: Your hostname, nc6v0 resolves to a loopback address: 127.0.0.1; using 10.0.0.11 instead (on interface eth0)\n",
      "2021-12-06 19:48:45,046 WARN Utils [Thread-1]: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "2021-12-06 19:48:45,240 WARN NativeCodeLoader [Thread-1]: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:48:45,321 INFO SecurityManager [Thread-1]: Changing view acls to: azureuser\n",
      "2021-12-06 19:48:45,321 INFO SecurityManager [Thread-1]: Changing modify acls to: azureuser\n",
      "2021-12-06 19:48:45,322 INFO SecurityManager [Thread-1]: Changing view acls groups to: \n",
      "2021-12-06 19:48:45,322 INFO SecurityManager [Thread-1]: Changing modify acls groups to: \n",
      "2021-12-06 19:48:45,323 INFO SecurityManager [Thread-1]: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(azureuser); groups with view permissions: Set(); users  with modify permissions: Set(azureuser); groups with modify permissions: Set()\n",
      "2021-12-06 19:48:45,591 INFO Utils [Thread-1]: Successfully started service 'RAY_RPC_ENV' on port 44621.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/jars/ray_dist.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:48:48,798 INFO RayAppMaster$RayAppMasterEndpoint [dispatcher-event-loop-1]: Registering app example\n",
      "2021-12-06 19:48:48,802 INFO RayAppMaster$RayAppMasterEndpoint [dispatcher-event-loop-1]: Registered app example with ID app-20211206194848-0000\n",
      "0    1\n",
      "1    4\n",
      "2    9\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|multiply_func(x, x)|\n",
      "+-------------------+\n",
      "|                  1|\n",
      "|                  4|\n",
      "|                  9|\n",
      "+-------------------+\n",
      "\n",
      "2021-12-06 19:48:59,086 INFO RayAppMaster [Thread-1]: Stopping RayAppMaster\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import raydp\n",
    "import os\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/anaconda/envs/azureml_py38/bin/python3\"\n",
    "\n",
    "# ray.init(address ='ray://10.0.0.11:6379')\n",
    "spark = raydp.init_spark(\n",
    "  app_name = \"example\",\n",
    "  num_executors = 2,\n",
    "  executor_cores = 1,\n",
    "  executor_memory = \"1gb\"\n",
    ")\n",
    "\n",
    "# data =spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://ojsales-simulatedcontainer@azureopendatastorage.blob.core.windows.net/oj_sales_data/Store10*.csv\")\n",
    "\n",
    "\n",
    "# # normal data processesing with Spark\n",
    "# df = spark.createDataFrame([('look',), ('spark',), ('tutorial',), ('spark',), ('look', ), ('python', )], ['word'])\n",
    "# df.show()\n",
    "# word_count = df.groupBy('word').count()\n",
    "# word_count.show()\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "# Declare the function and create the UDF\n",
    "def multiply_func(a: pd.Series, b: pd.Series) -> pd.Series:\n",
    "    return a * b\n",
    "\n",
    "multiply = pandas_udf(multiply_func, returnType=LongType())\n",
    "\n",
    "# The function for a pandas_udf should be able to execute with local Pandas data\n",
    "x = pd.Series([1, 2, 3])\n",
    "print(multiply_func(x, x))\n",
    "# 0    1\n",
    "# 1    4\n",
    "# 2    9\n",
    "# dtype: int64\n",
    "\n",
    "# Create a Spark DataFrame, 'spark' is an existing SparkSession\n",
    "df = spark.createDataFrame(pd.DataFrame(x, columns=[\"x\"]))\n",
    "\n",
    "# Execute function as a Spark vectorized UDF\n",
    "df.select(multiply(col(\"x\"), col(\"x\"))).show()\n",
    "# +-------------------+\n",
    "# |multiply_func(x, x)|\n",
    "# +-------------------+\n",
    "# |                  1|\n",
    "# |                  4|\n",
    "# |                  9|\n",
    "# +-------------------+\n",
    "\n",
    "\n",
    "# stop the spark cluster\n",
    "raydp.stop_spark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raydp.stop_spark()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Ray on Job Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "#     pyarrow >=6.0.1\n",
    "# dask >=2021.11.2\n",
    "# adlfs >=2021.10.0\n",
    "# fsspec==2021.10.1\n",
    "# ray[default]==1.9.0\n",
    "ws = Workspace.from_config()\n",
    "base_conda_dep =['adlfs==2021.10.0','pip']\n",
    "base_pip_dep = ['ray[tune]==1.9.1', 'xgboost_ray==0.1.5', 'dask==2021.12.0','pyarrow >= 5.0.0','fsspec==2021.10.1', 'torch','torchvision==0.8.1']\n",
    "\n",
    "compute_cluster = 'worker-cpu-v3'\n",
    "maxnode =5\n",
    "vm_size='STANDARD_DS3_V2'\n",
    "vnet='rayvnet'\n",
    "subnet='default'\n",
    "exp ='ray_on_aml_job'\n",
    "ws_detail = ws.get_details()\n",
    "ws_rg = ws_detail['id'].split(\"/\")[4]\n",
    "vnet_rg=None\n",
    "try:\n",
    "    ray_cluster = ComputeTarget(workspace=ws, name=compute_cluster)\n",
    "\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    if vnet_rg is None:\n",
    "        vnet_rg = ws_rg\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                        min_nodes=0, max_nodes=maxnode,\n",
    "                                                        vnet_resourcegroup_name=vnet_rg,\n",
    "                                                        vnet_name=vnet,\n",
    "                                                        subnet_name=subnet)\n",
    "    ray_cluster = ComputeTarget.create(ws, compute_cluster, compute_config)\n",
    "\n",
    "    ray_cluster.wait_for_completion(show_output=True)\n",
    "\n",
    "\n",
    "python_version = [\"python=\"+platform.python_version()]\n",
    "\n",
    "\n",
    "\n",
    "conda_packages = python_version+base_conda_dep\n",
    "pip_packages = base_pip_dep \n",
    "\n",
    "conda_dep = CondaDependencies()\n",
    "\n",
    "rayEnv = Environment(name=\"rayEnv\")\n",
    "# rayEnv = Environment.get(ws, \"rayEnv\", version=16)\n",
    "for conda_package in conda_packages:\n",
    "    conda_dep.add_conda_package(conda_package)\n",
    "\n",
    "for pip_package in pip_packages:\n",
    "    conda_dep.add_pip_package(pip_package)\n",
    "\n",
    "# # Adds dependencies to PythonSection of myenv\n",
    "rayEnv.python.conda_dependencies=conda_dep\n",
    "\n",
    "src = ScriptRunConfig(source_directory='job',\n",
    "                script='aml_job.py',\n",
    "                environment=rayEnv,\n",
    "                compute_target=ray_cluster,\n",
    "                distributed_job_config=PyTorchConfiguration(node_count=maxnode),\n",
    "                    # arguments = [\"--master_ip\",master_ip]\n",
    "                )\n",
    "run = Experiment(ws, exp).submit(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440001f1cc284fabb748b2ab6e756859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/ray_on_aml_job_1640888890_1cb24381?wsid=/subscriptions/0e9bace8-7a81-4922-83b5-d995ff706507/resourcegroups/azureml/workspaces/ws01ent&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\", \"run_id\": \"ray_on_aml_job_1640888890_1cb24381\", \"run_properties\": {\"run_id\": \"ray_on_aml_job_1640888890_1cb24381\", \"created_utc\": \"2021-12-30T18:28:11.175346Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"ec031de0-fde6-40f1-aaf4-029a38beda5b\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\", \"azureml.git.repository_uri\": \"https://github.com/james-tn/ray-on-aml.git\", \"mlflow.source.git.repoURL\": \"https://github.com/james-tn/ray-on-aml.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"15eb1c529e90b84e363749dcd59fbbfcc116788c\", \"mlflow.source.git.commit\": \"15eb1c529e90b84e363749dcd59fbbfcc116788c\", \"azureml.git.dirty\": \"True\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":5,\\\"CurrentNodeCount\\\":10}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-12-30T18:31:49.7507Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_3125fc93c3a5aed2c45377d4b5d0b65f80ca24f2c77bc3348e6cba2967e696ca_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/55_azureml-execution-tvmps_3125fc93c3a5aed2c45377d4b5d0b65f80ca24f2c77bc3348e6cba2967e696ca_d.txt?sv=2019-07-07&sr=b&sig=4FBXiFOpAr99HkWimW6Efz%2FIN84GOogW3m0oAmilD2M%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_3da956945f0100ed1942c31600a2112ac70dc2b0d7c4be95028fac93353750cb_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/55_azureml-execution-tvmps_3da956945f0100ed1942c31600a2112ac70dc2b0d7c4be95028fac93353750cb_d.txt?sv=2019-07-07&sr=b&sig=DFkqFNCVLxG3hmBf2nCVQjk3PPVEFgXnhYIEwOOQIS8%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_a18a43613e1f7dbd178e48dce461d549005bf218e297546939cb75c8c4ee346e_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/55_azureml-execution-tvmps_a18a43613e1f7dbd178e48dce461d549005bf218e297546939cb75c8c4ee346e_d.txt?sv=2019-07-07&sr=b&sig=kmCC5AMvZIV4lfR7MsVB7DpzfEsbeiqBol25V1nQRxw%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_a5d963c9eb484574f81458d5d2b6e3f6c07b897792ffc01724ea26500646ce6d_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/55_azureml-execution-tvmps_a5d963c9eb484574f81458d5d2b6e3f6c07b897792ffc01724ea26500646ce6d_d.txt?sv=2019-07-07&sr=b&sig=o1mIC9wx6MYVuUmoj2avaOUxSHGdH%2BpVXeuTDXdYvD4%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_bbdafebc41013ae341074b9cd2a8560a38dc63ea213daacd6fa9d8df87e9a98d_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/55_azureml-execution-tvmps_bbdafebc41013ae341074b9cd2a8560a38dc63ea213daacd6fa9d8df87e9a98d_d.txt?sv=2019-07-07&sr=b&sig=ECGxN%2FTFA%2Fa4YrQHvbSfkBElpzxAXX0IGdXm2VUhutk%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_3125fc93c3a5aed2c45377d4b5d0b65f80ca24f2c77bc3348e6cba2967e696ca_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/65_job_prep-tvmps_3125fc93c3a5aed2c45377d4b5d0b65f80ca24f2c77bc3348e6cba2967e696ca_d.txt?sv=2019-07-07&sr=b&sig=o8xoYyq%2B0Bj7mIptosOy8MoKuaiMDQSG5jGvxoBIfj4%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_3da956945f0100ed1942c31600a2112ac70dc2b0d7c4be95028fac93353750cb_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/65_job_prep-tvmps_3da956945f0100ed1942c31600a2112ac70dc2b0d7c4be95028fac93353750cb_d.txt?sv=2019-07-07&sr=b&sig=uSIG4LFW6zyuDV68VYc%2BpmLDRH2YXhb01bxScA2KWEY%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_a18a43613e1f7dbd178e48dce461d549005bf218e297546939cb75c8c4ee346e_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/65_job_prep-tvmps_a18a43613e1f7dbd178e48dce461d549005bf218e297546939cb75c8c4ee346e_d.txt?sv=2019-07-07&sr=b&sig=GyBnRTSWGmGTSswJp1oVjU7ezFARmFvMTi1tI%2BHtweE%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_a5d963c9eb484574f81458d5d2b6e3f6c07b897792ffc01724ea26500646ce6d_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/65_job_prep-tvmps_a5d963c9eb484574f81458d5d2b6e3f6c07b897792ffc01724ea26500646ce6d_d.txt?sv=2019-07-07&sr=b&sig=0XcHQQFJa2AOnsakPng2xkpiAh1np3nvZ%2BBntZDy6ks%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_bbdafebc41013ae341074b9cd2a8560a38dc63ea213daacd6fa9d8df87e9a98d_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/65_job_prep-tvmps_bbdafebc41013ae341074b9cd2a8560a38dc63ea213daacd6fa9d8df87e9a98d_d.txt?sv=2019-07-07&sr=b&sig=qJ1w4IuQG5floHrK3nqwp8uWSGsnn55WNCciWr0O1j0%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/70_driver_log_0.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/70_driver_log_0.txt?sv=2019-07-07&sr=b&sig=qUD%2FBwj862HwSy4yKFhbPaALAZFJ9Pmw4GvnMCUM1T0%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/70_driver_log_1.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/70_driver_log_1.txt?sv=2019-07-07&sr=b&sig=11oXqOjoW%2BotqvH6Q2Yjugyv%2F5LY0qLOWNAid5eEETU%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/70_driver_log_2.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/70_driver_log_2.txt?sv=2019-07-07&sr=b&sig=OEr2v5pTUOR1WeKzUuwyjiEZwyLVDTtIhEw7mobGKlw%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/70_driver_log_3.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/70_driver_log_3.txt?sv=2019-07-07&sr=b&sig=T3TZpCzhWLJNQY7%2B47f1%2BgQzOF35rR%2Fpb%2FEN%2BaSYQwI%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/70_driver_log_4.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/70_driver_log_4.txt?sv=2019-07-07&sr=b&sig=mNtn0ZjpCmZQagrdXfSWktgTmrZCbNKtdhKcgIPyZus%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/75_job_post-tvmps_3125fc93c3a5aed2c45377d4b5d0b65f80ca24f2c77bc3348e6cba2967e696ca_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/75_job_post-tvmps_3125fc93c3a5aed2c45377d4b5d0b65f80ca24f2c77bc3348e6cba2967e696ca_d.txt?sv=2019-07-07&sr=b&sig=1AfHzOO4pZhsYqtoGdKulEAkzuvYO3D1t16bGH%2By%2FKU%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/75_job_post-tvmps_3da956945f0100ed1942c31600a2112ac70dc2b0d7c4be95028fac93353750cb_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/75_job_post-tvmps_3da956945f0100ed1942c31600a2112ac70dc2b0d7c4be95028fac93353750cb_d.txt?sv=2019-07-07&sr=b&sig=JiOLVUIGte60DINrWkoHiwmFtsax2GTcwRtkCmy%2Bd8Q%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/75_job_post-tvmps_a18a43613e1f7dbd178e48dce461d549005bf218e297546939cb75c8c4ee346e_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/75_job_post-tvmps_a18a43613e1f7dbd178e48dce461d549005bf218e297546939cb75c8c4ee346e_d.txt?sv=2019-07-07&sr=b&sig=9D3CRzNaP8wM9PucxZVYHAOoi0nqbMAsp0UFT51N4VA%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/75_job_post-tvmps_a5d963c9eb484574f81458d5d2b6e3f6c07b897792ffc01724ea26500646ce6d_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/75_job_post-tvmps_a5d963c9eb484574f81458d5d2b6e3f6c07b897792ffc01724ea26500646ce6d_d.txt?sv=2019-07-07&sr=b&sig=fQzIdDqiDu5EvnF3Rq68o8PbzwML5aYAEPgbaN71zj8%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/75_job_post-tvmps_bbdafebc41013ae341074b9cd2a8560a38dc63ea213daacd6fa9d8df87e9a98d_d.txt\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/75_job_post-tvmps_bbdafebc41013ae341074b9cd2a8560a38dc63ea213daacd6fa9d8df87e9a98d_d.txt?sv=2019-07-07&sr=b&sig=9kd06kUg6tNB23h4qvxHnjq2L6I4otVH8AKd6SIZOw0%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/process_info.json\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=V358eFfyyRKKeqLNPcBMdZEmYIjOt8WMBCbxlG5slvE%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"azureml-logs/process_status.json\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=V%2FypDQlXN46SdaqD9vl0XNKi31mVibMAGFJM4zX5pbI%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T16%3A34%3A19Z&ske=2022-01-01T00%3A44%3A19Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"logs/azureml/0_143_azureml.log\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/logs/azureml/0_143_azureml.log?sv=2019-07-07&sr=b&sig=k9D2R59YnbitXysZtjN%2BRKDnfZ63pZEFiP3kZFpm8u4%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T23%3A09%3A35Z&ske=2022-01-01T07%3A19%3A35Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"logs/azureml/1_121_azureml.log\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/logs/azureml/1_121_azureml.log?sv=2019-07-07&sr=b&sig=JbhrCJcFutZL1GiTxQCfc1ksShKB4ymXUJb1t2euFRM%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T23%3A09%3A35Z&ske=2022-01-01T07%3A19%3A35Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"logs/azureml/2_119_azureml.log\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/logs/azureml/2_119_azureml.log?sv=2019-07-07&sr=b&sig=MTOzsju2Yojgc0TTkPeqzCDQKqAyIlo6n%2F%2FKXJbYkuI%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T23%3A09%3A35Z&ske=2022-01-01T07%3A19%3A35Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"logs/azureml/3_118_azureml.log\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/logs/azureml/3_118_azureml.log?sv=2019-07-07&sr=b&sig=4NxDfVipEO1tQwKbAouzas3lSSssEEUFmmbP0%2BUPvKs%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T23%3A09%3A35Z&ske=2022-01-01T07%3A19%3A35Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"logs/azureml/4_121_azureml.log\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/logs/azureml/4_121_azureml.log?sv=2019-07-07&sr=b&sig=L%2FQ%2FMJ0W4MGBciKxwR8FDdHy6yCOtzUXDmMTuTQditg%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T23%3A09%3A35Z&ske=2022-01-01T07%3A19%3A35Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=efLNae8CpLCEL2UKEelKBmXoeGEOZY8ZiwEWQLWj6xA%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T23%3A09%3A35Z&ske=2022-01-01T07%3A19%3A35Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://ws01ent3218162019.blob.core.windows.net/azureml/ExperimentRun/dcid.ray_on_aml_job_1640888890_1cb24381/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=dMiIrsTZRPqwX47O7TvPpJxrQ30jgBFc0K%2FIxZw%2FAjE%3D&skoid=77bedd4a-092b-43e6-861b-6568aa9dd518&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-12-30T23%3A09%3A35Z&ske=2022-01-01T07%3A19%3A35Z&sks=b&skv=2019-07-07&st=2021-12-30T23%3A22%3A13Z&se=2021-12-31T07%3A32%3A13Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"logs/azureml/0_143_azureml.log\"], [\"logs/azureml/1_121_azureml.log\"], [\"logs/azureml/2_119_azureml.log\"], [\"logs/azureml/3_118_azureml.log\"], [\"logs/azureml/4_121_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_3da956945f0100ed1942c31600a2112ac70dc2b0d7c4be95028fac93353750cb_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_a5d963c9eb484574f81458d5d2b6e3f6c07b897792ffc01724ea26500646ce6d_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_a18a43613e1f7dbd178e48dce461d549005bf218e297546939cb75c8c4ee346e_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_3125fc93c3a5aed2c45377d4b5d0b65f80ca24f2c77bc3348e6cba2967e696ca_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_bbdafebc41013ae341074b9cd2a8560a38dc63ea213daacd6fa9d8df87e9a98d_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_3da956945f0100ed1942c31600a2112ac70dc2b0d7c4be95028fac93353750cb_d.txt\", \"azureml-logs/65_job_prep-tvmps_a5d963c9eb484574f81458d5d2b6e3f6c07b897792ffc01724ea26500646ce6d_d.txt\", \"azureml-logs/65_job_prep-tvmps_a18a43613e1f7dbd178e48dce461d549005bf218e297546939cb75c8c4ee346e_d.txt\", \"azureml-logs/65_job_prep-tvmps_3125fc93c3a5aed2c45377d4b5d0b65f80ca24f2c77bc3348e6cba2967e696ca_d.txt\", \"azureml-logs/65_job_prep-tvmps_bbdafebc41013ae341074b9cd2a8560a38dc63ea213daacd6fa9d8df87e9a98d_d.txt\"], [\"azureml-logs/70_driver_log_0.txt\", \"azureml-logs/70_driver_log_1.txt\", \"azureml-logs/70_driver_log_2.txt\", \"azureml-logs/70_driver_log_3.txt\", \"azureml-logs/70_driver_log_4.txt\"], [\"azureml-logs/75_job_post-tvmps_3da956945f0100ed1942c31600a2112ac70dc2b0d7c4be95028fac93353750cb_d.txt\", \"azureml-logs/75_job_post-tvmps_a5d963c9eb484574f81458d5d2b6e3f6c07b897792ffc01724ea26500646ce6d_d.txt\", \"azureml-logs/75_job_post-tvmps_a18a43613e1f7dbd178e48dce461d549005bf218e297546939cb75c8c4ee346e_d.txt\", \"azureml-logs/75_job_post-tvmps_3125fc93c3a5aed2c45377d4b5d0b65f80ca24f2c77bc3348e6cba2967e696ca_d.txt\", \"azureml-logs/75_job_post-tvmps_bbdafebc41013ae341074b9cd2a8560a38dc63ea213daacd6fa9d8df87e9a98d_d.txt\"]], \"run_duration\": \"0:03:38\", \"run_number\": \"36\", \"run_queued_details\": {\"status\": \"Completed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"[2021-12-30T18:31:31.574915] Entering job release\\r\\n[2021-12-30T18:31:32.591969] job release stage : copy_batchai_cached_logs starting...\\r\\n[2021-12-30T18:31:32.592017] job release stage : copy_batchai_cached_logs completed...\\r\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.34.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class SynapseCompute: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
