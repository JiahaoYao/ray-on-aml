{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Interactive use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1639168219519
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "# from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import platform\n",
    "# from ray_on_azureml.ray_on_aml import getRay\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CPU': 26.0,\n",
       " 'node:10.0.0.35': 1.0,\n",
       " 'memory': 77997084266.0,\n",
       " 'object_store_memory': 35463301936.0,\n",
       " 'node:10.0.0.18': 1.0,\n",
       " 'GPU': 1.0,\n",
       " 'node:10.0.0.11': 1.0,\n",
       " 'accelerator_type:K80': 1.0,\n",
       " 'node:10.0.0.33': 1.0,\n",
       " 'node:10.0.0.12': 1.0,\n",
       " 'node:10.0.0.34': 1.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1639167793538
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get active run  ray_on_aml_1639356958_5ef4cfc6\n",
      "Run does not exisit, finding active runs to cancel\n",
      "Cannot shutdown ray\n",
      "rank returned is  None\n",
      "rank returned is  None\n",
      "azureml_py38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:00:37,210\tERROR import_thread.py:89 -- ImportThread: Connection closed by server.\n",
      "2021-12-13 01:00:37,219\tERROR worker.py:1247 -- listen_error_messages_raylet: Connection closed by server.\n",
      "2021-12-13 01:00:37,220\tERROR worker.py:478 -- print_logs: Connection closed by server.\n",
      "2021-12-13 01:00:43,075\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:00:59,045\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 10.0.0.11:6379\n",
      "2021-12-13 01:00:59,172\tWARNING worker.py:1219 -- The autoscaler failed with the following error:\n",
      "Terminated with signal 15\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 543, in <module>\n",
      "    monitor.run()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 439, in run\n",
      "    self._run()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 346, in _run\n",
      "    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'object_store_memory': 14251860787.0,\n",
       " 'accelerator_type:K80': 1.0,\n",
       " 'GPU': 1.0,\n",
       " 'CPU': 6.0,\n",
       " 'node:10.0.0.11': 1.0,\n",
       " 'memory': 28503721575.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.ray_on_aml.core import Ray_On_AML\n",
    "ws = Workspace.from_config()\n",
    "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"worker-cpu-v3\",additional_pip_packages=['azureml-mlflow', 'torch', 'torchvision','sklearn'])\n",
    "ray_on_aml.shutdown(end_all_runs=True)\n",
    "#clear up all active run\n",
    "_, ray = ray_on_aml.getRay()\n",
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "gather": {
     "logged": 1639106683762
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get active run  ray_on_aml_1639357246_fafdc42a\n"
     ]
    }
   ],
   "source": [
    "ray_on_aml.shutdown()\n",
    "# import ray\n",
    "# ray.shutdown()\n",
    "# ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Dask on Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1639105974201
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>6826.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9938</th>\n",
       "      <td>9412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9954</th>\n",
       "      <td>3235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>1304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>2001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>982 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade\n",
       "age         \n",
       "7      188.0\n",
       "20    2956.0\n",
       "22    7300.0\n",
       "38    9611.0\n",
       "67    3711.0\n",
       "...      ...\n",
       "9881  6826.0\n",
       "9938  9412.0\n",
       "9954  3235.0\n",
       "9976  1304.0\n",
       "9991  2001.0\n",
       "\n",
       "[982 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ray\n",
    "# ray.init()\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dask.config.set(scheduler=ray_dask_get)\n",
    "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
    "\n",
    "# The Dask scheduler submits the underlying task graph to Ray.\n",
    "d_arr.mean().compute(scheduler=ray_dask_get)\n",
    "\n",
    "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
    "# specify it on each compute call.\n",
    "\n",
    "df = dd.from_pandas(\n",
    "    pd.DataFrame(\n",
    "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
    "    npartitions=2)\n",
    "df.groupby([\"age\"]).mean().compute()\n",
    "\n",
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1639104458150
    }
   },
   "outputs": [
    {
     "ename": "RayTaskError(NameError)",
     "evalue": "\u001b[36mray::dask:('dataframe-count-agg-c779cbec183eaab06c239b02895358aa', 0)\u001b[39m (pid=247, ip=10.0.0.33)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RayTaskError: \u001b[36mray::dask:('dataframe-count-chunk-c779cbec183eaab06c239b02895358aa', 0, 6, 0)\u001b[39m (pid=191, ip=10.0.0.33)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RayTaskError: \u001b[36mray::dask:('read-parquet-80717453fe38c42d32a261b8d065b376', 6)\u001b[39m (pid=192, ip=10.0.0.33)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\", line 350, in dask_task_wrapper\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/optimization.py\", line 969, in __call__\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/core.py\", line 149, in get\n    result = _execute_task(task, cache)\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/core.py\", line 119, in _execute_task\n    return func(*(_execute_task(a, cache) for a in args))\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 87, in __call__\n    return read_parquet_part(\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 422, in read_parquet_part\n    dfs = [\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 423, in <listcomp>\n    func(fs, rg, columns.copy(), index, **toolz.merge(kwargs, kw))\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/dataframe/io/parquet/fastparquet.py\", line 953, in read_partition\n    parquet_file = ParquetFile(\nNameError: name 'ParquetFile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(NameError)\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73189/1282347489.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'account_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'azureopendatastorage'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mddf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'az://nyctlc/green/puYear=2019/puMonth=*/*.parquet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mddf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\u001b[0m in \u001b[0;36mray_dask_get\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0menable_progress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mpb_actor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_dask_on_ray_pb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray_get_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_actor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpb_actor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mray_finish_cbs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mray_finish_cbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\u001b[0m in \u001b[0;36mray_get_unpack\u001b[0;34m(object_refs, progress_bar_actor)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;31m# completes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_object_refs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mcomputed_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(object_refs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprogress_bar_actor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mrender_progress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar_actor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1711\u001b[0m                     \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_object_store_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayTaskError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError(NameError)\u001b[0m: \u001b[36mray::dask:('dataframe-count-agg-c779cbec183eaab06c239b02895358aa', 0)\u001b[39m (pid=247, ip=10.0.0.33)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RayTaskError: \u001b[36mray::dask:('dataframe-count-chunk-c779cbec183eaab06c239b02895358aa', 0, 6, 0)\u001b[39m (pid=191, ip=10.0.0.33)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RayTaskError: \u001b[36mray::dask:('read-parquet-80717453fe38c42d32a261b8d065b376', 6)\u001b[39m (pid=192, ip=10.0.0.33)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\", line 350, in dask_task_wrapper\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/optimization.py\", line 969, in __call__\n    return core.get(self.dsk, self.outkey, dict(zip(self.inkeys, args)))\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/core.py\", line 149, in get\n    result = _execute_task(task, cache)\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/core.py\", line 119, in _execute_task\n    return func(*(_execute_task(a, cache) for a in args))\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 87, in __call__\n    return read_parquet_part(\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 422, in read_parquet_part\n    dfs = [\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\", line 423, in <listcomp>\n    func(fs, rg, columns.copy(), index, **toolz.merge(kwargs, kw))\n  File \"/azureml-envs/azureml_d28debf0c131ba759185828baf634c78/lib/python3.8/site-packages/dask/dataframe/io/parquet/fastparquet.py\", line 953, in read_partition\n    parquet_file = ParquetFile(\nNameError: name 'ParquetFile' is not defined"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "storage_options = {'account_name': 'azureopendatastorage'}\n",
    "ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
    "ddf.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "gather": {
     "logged": 1639106144831
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.32it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.62it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.47it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.39it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.39it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "780032264"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dask\n",
    "\n",
    "# import ray\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Model\n",
    "from adlfs import AzureBlobFileSystem\n",
    "account_key = ws.get_default_keyvault().get_secret(\"adls7-account-key\")\n",
    "account_name=\"adlsgen7\"\n",
    "abfs = AzureBlobFileSystem(account_name=\"adlsgen7\",account_key=account_key,  container_name=\"mltraining\")\n",
    "abfs2 = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
    "\n",
    "\n",
    "storage_options={'account_name': account_name, 'account_key': account_key}\n",
    "\n",
    "# ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year2008', storage_options=storage_options)\n",
    "\n",
    "\n",
    "data = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2012/\"], filesystem=abfs2)\n",
    "data1 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2010/\"], filesystem=abfs2)\n",
    "data3 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2009/\"], filesystem=abfs2)\n",
    "data4 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2011/\"], filesystem=abfs2)\n",
    "data5 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2013/\"], filesystem=abfs2)\n",
    "data6 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2014/\"], filesystem=abfs2)\n",
    "\n",
    "all_data =data.union(data1).union(data2).union(data3).union(data4).union(data5).union(data6)\n",
    "all_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sort Sample:  98%|█████████▊| 613/627 [03:04<00:16,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_sample_block pid=7388, ip=10.0.0.12)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sort Sample: 100%|██████████| 627/627 [03:32<00:00,  2.95it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_73189/3382282944.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stationName\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/data/grouped_dataset.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0mgroupby\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mkey\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0momitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAggregateOnTs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/data/grouped_dataset.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, *aggs)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mboundaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             boundaries = sort.sample_boundaries(\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ascending\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 if isinstance(self._key, str) else self._key, num_reducers)\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/data/impl/sort.py\u001b[0m in \u001b[0;36msample_boundaries\u001b[0;34m(blocks, key, num_reducers)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_reducers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0msample_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0msample_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     ret = [\n\u001b[1;32m     62\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "all_data.groupby(\"stationName\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_dask = all_data.to_dask().describe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_dask.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Ray Tune for distributed ML tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "gather": {
     "logged": 1639106657384
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:24:59,030\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
      "2021-12-13 01:24:59,036\tWARNING tune.py:570 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-13 01:24:59 (running for 00:00:00.12)<br>Memory usage on this node: 12.6/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/72.64 GiB heap, 0.0/33.03 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-13_01-24-58<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_7ca0b_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000164303</td><td style=\"text-align: right;\">      0.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=88813)\u001b[0m /anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=88813)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_mnist_7ca0b_00000:\n",
      "  date: 2021-12-13_01-25-01\n",
      "  done: false\n",
      "  experiment_id: c7e07e291ce54faab67cbcae24560f7e\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.115625\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 88813\n",
      "  time_since_restore: 0.2597367763519287\n",
      "  time_this_iter_s: 0.2597367763519287\n",
      "  time_total_s: 0.2597367763519287\n",
      "  timestamp: 1639358701\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 7ca0b_00000\n",
      "  \n",
      "Result for train_mnist_7ca0b_00000:\n",
      "  date: 2021-12-13_01-25-03\n",
      "  done: true\n",
      "  experiment_id: c7e07e291ce54faab67cbcae24560f7e\n",
      "  experiment_tag: 0_lr=0.0001643,momentum=0.07\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 10\n",
      "  mean_accuracy: 0.125\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 88813\n",
      "  time_since_restore: 2.1971499919891357\n",
      "  time_this_iter_s: 0.21480560302734375\n",
      "  time_total_s: 2.1971499919891357\n",
      "  timestamp: 1639358703\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: 7ca0b_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-13 01:25:03 (running for 00:00:04.03)<br>Memory usage on this node: 12.8/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/72.64 GiB heap, 0.0/33.03 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-13_01-24-58<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">  acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_7ca0b_00000</td><td>TERMINATED</td><td>10.0.0.11:88813</td><td style=\"text-align: right;\">0.000164303</td><td style=\"text-align: right;\">      0.07</td><td style=\"text-align: right;\">0.125</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.19715</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:25:03,182\tINFO tune.py:626 -- Total run time: 4.22 seconds (4.03 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "# import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # In this example, we don't change the model architecture\n",
    "        # due to simplicity.\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "# Change these values if you want the training to run quicker or slower.\n",
    "EPOCH_SIZE = 512\n",
    "TEST_SIZE = 256\n",
    "\n",
    "def train(model, optimizer, train_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # We set this just for the example to run quickly.\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "            return\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # We set this just for the example to run quickly.\n",
    "            if batch_idx * len(data) > TEST_SIZE:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "def train_mnist(config):\n",
    "    # Data Setup\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = ConvNet()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "    for i in range(10):\n",
    "        train(model, optimizer, train_loader)\n",
    "        acc = test(model, test_loader)\n",
    "\n",
    "        # Send the current training result back to Tune\n",
    "        tune.report(mean_accuracy=acc)\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            # This saves the model to the trial directory\n",
    "            torch.save(model.state_dict(), \"./model.pth\")\n",
    "search_space = {\n",
    "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
    "    \"momentum\": tune.choice([0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09, 0.01])\n",
    "}\n",
    "\n",
    "# Uncomment this to enable distributed execution\n",
    "# ray.shutdown()\n",
    "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
    "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
    "# Download the dataset first\n",
    "datasets.MNIST(\"~/data\", train=True, download=True)\n",
    "\n",
    "analysis = tune.run(train_mnist, config=search_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1639106681808
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 01:26:24,973\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
      "2021-12-13 01:26:24,978\tWARNING tune.py:570 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-13 01:26:25 (running for 00:00:00.24)<br>Memory usage on this node: 12.8/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/72.64 GiB heap, 0.0/33.03 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-13_01-26-24<br>Number of trials: 28/1200 (28 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_breast_cancer_afdd3_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">7.21882e-06</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">   0.991635</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0896394  </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">   0.454755</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">2.57277e-05</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">   0.140229</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">1.97735e-06</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">   0.403903</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.020118   </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.59187 </td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">3.74366e-05</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">   0.24934 </td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">2.09181e-05</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">   0.488391</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">1.71127e-06</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">   0.214962</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00117104 </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.905878</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">2.69995e-05</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.751093</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00010</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00223921 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.389914</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00011</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0413016  </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">   0.125355</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00012</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00752405 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.657031</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00013</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">6.03963e-06</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.696009</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00014</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0587166  </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">   0.824876</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00015</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000281124</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">   0.987052</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00016</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0442456  </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.651834</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00017</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000134132</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 7</td><td style=\"text-align: right;\">   0.676895</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00018</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0165246  </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">   0.543462</td></tr>\n",
       "<tr><td>train_breast_cancer_afdd3_00019</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.021204   </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">   0.376925</td></tr>\n",
       "</tbody>\n",
       "</table><br>... 8 more trials not shown (8 PENDING)<br><br>"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1639464907468
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.ray_on_aml.core import Ray_On_AML\n",
        "ws = Workspace.from_config()\n",
        "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"worker-cpu-v3\")\n",
        "_, ray = ray_on_aml.getRay()\n",
        "ray.cluster_resources()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "rank returned is  None\nrank returned is  None\nazureml_py38\nFound existing cluster, use it.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-14 06:55:17,517\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n2021-12-14 06:55:32,057\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 10.1.0.5:6379\n2021-12-14 06:55:32,208\tWARNING worker.py:1219 -- The autoscaler failed with the following error:\nTerminated with signal 15\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 543, in <module>\n    monitor.run()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 439, in run\n    self._run()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 346, in _run\n    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "{'node:10.1.0.5': 1.0,\n 'CPU': 4.0,\n 'object_store_memory': 3305130393.0,\n 'memory': 6610260788.0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1639464931994
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ray.cluster_resources()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "{'object_store_memory': 24512124516.0,\n 'node:10.1.0.5': 1.0,\n 'memory': 56093247081.0,\n 'CPU': 24.0,\n 'node:10.1.0.4': 1.0,\n 'node:10.1.0.9': 1.0,\n 'node:10.1.0.8': 1.0,\n 'node:10.1.0.7': 1.0,\n 'node:10.1.0.11': 1.0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639464969085
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ray_on_aml.run)\n",
        "# ray_on_aml.shutdown()\n",
        "# import ray\n",
        "# ray.shutdown()\n",
        "# ray.init()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run(Experiment: ray_on_aml,\nId: ray_on_aml_1639464919_93c6f227,\nType: azureml.scriptrun,\nStatus: Queued)\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-14 07:00:28,670\tWARNING worker.py:1245 -- The node with node id: 359ec449b46156a3fbfb8080f2cec158cbba5cccfacff1f07dd43189 and ip: 10.1.0.7 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a raylet crashes unexpectedly or has lagging heartbeats.\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1639464971727
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing with Dask on Ray"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import ray\n",
        "# ray.init()\n",
        "from ray.util.dask import ray_dask_get\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "dask.config.set(scheduler=ray_dask_get)\n",
        "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
        "\n",
        "# The Dask scheduler submits the underlying task graph to Ray.\n",
        "d_arr.mean().compute(scheduler=ray_dask_get)\n",
        "\n",
        "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
        "# specify it on each compute call.\n",
        "\n",
        "df = dd.from_pandas(\n",
        "    pd.DataFrame(\n",
        "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
        "    npartitions=2)\n",
        "df.groupby([\"age\"]).mean().compute()\n",
        "\n",
        "# ray.shutdown()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>grade</th>\n    </tr>\n    <tr>\n      <th>age</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>35</th>\n      <td>1325.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>388.0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>865.0</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>9141.0</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>311.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9880</th>\n      <td>9171.0</td>\n    </tr>\n    <tr>\n      <th>9889</th>\n      <td>2188.0</td>\n    </tr>\n    <tr>\n      <th>9902</th>\n      <td>2798.0</td>\n    </tr>\n    <tr>\n      <th>9939</th>\n      <td>9432.0</td>\n    </tr>\n    <tr>\n      <th>9988</th>\n      <td>2724.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>981 rows × 1 columns</p>\n</div>",
            "text/plain": "       grade\nage         \n35    1325.0\n37     388.0\n48     865.0\n66    9141.0\n102    311.0\n...      ...\n9880  9171.0\n9889  2188.0\n9902  2798.0\n9939  9432.0\n9988  2724.0\n\n[981 rows x 1 columns]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1639105974201
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "\n",
        "storage_options = {'account_name': 'azureopendatastorage'}\n",
        "ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
        "ddf.count().compute()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "vendorID                3297967\nlpepPickupDatetime      3297967\nlpepDropoffDatetime     3297967\npassengerCount          3297967\ntripDistance            3297967\npuLocationId            3297967\ndoLocationId            3297967\npickupLongitude               0\npickupLatitude                0\ndropoffLongitude              0\ndropoffLatitude               0\nrateCodeID              3297967\nstoreAndFwdFlag         3297967\npaymentType             3297967\nfareAmount              3297967\nextra                   3297967\nmtaTax                  3297967\nimprovementSurcharge    3297967\ntipAmount               3297967\ntollsAmount             3297967\nehailFee                      0\ntotalAmount             3297967\ntripType                3297967\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1639104458150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dask\n",
        "\n",
        "# import ray\n",
        "from ray.util.dask import ray_dask_get\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dask\n",
        "import dask.dataframe as dd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from azureml.core import Workspace, Dataset, Model\n",
        "from adlfs import AzureBlobFileSystem\n",
        "account_key = ws.get_default_keyvault().get_secret(\"adls7-account-key\")\n",
        "account_name=\"adlsgen7\"\n",
        "abfs = AzureBlobFileSystem(account_name=\"adlsgen7\",account_key=account_key,  container_name=\"mltraining\")\n",
        "abfs2 = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
        "\n",
        "\n",
        "storage_options={'account_name': account_name, 'account_key': account_key}\n",
        "\n",
        "# ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year2008', storage_options=storage_options)\n",
        "\n",
        "data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs2)\n",
        "data2 = ray.data.read_parquet(\"az://mltraining/ISDWeatherDelta/year2008\", filesystem=abfs)\n",
        "data.count()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'EntryPoint' object has no attribute 'AbstractFileSystem'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ab52310d138e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year2008', storage_options=storage_options)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"az://isdweatherdatacontainer/ISDWeather/year=2009\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabfs2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mdata2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"az://mltraining/ISDWeatherDelta/year2008\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ray/data/read_api.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(paths, filesystem, columns, parallelism, ray_remote_args, _tensor_column_schema, **arrow_parquet_args)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mray_remote_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mray_remote_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         **arrow_parquet_args)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ray/data/read_api.py\u001b[0m in \u001b[0;36mread_datasource\u001b[0;34m(datasource, parallelism, ray_remote_args, _spread_resource_prefix, **read_args)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \"\"\"\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mread_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallelism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mread_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ray/data/datasource/parquet_datasource.py\u001b[0m in \u001b[0;36mprepare_read\u001b[0;34m(self, parallelism, paths, filesystem, columns, schema, _block_udf, **reader_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_resolve_paths_and_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ray/data/datasource/file_based_datasource.py\u001b[0m in \u001b[0;36m_resolve_paths_and_filesystem\u001b[0;34m(paths, filesystem)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# an fsspec filesystem, so we raise a TypeError.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfsspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAbstractFileSystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'EntryPoint' object has no attribute 'AbstractFileSystem'"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1639106144831
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Ray Tune for distributed ML tunning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "# import ray\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # In this example, we don't change the model architecture\n",
        "        # due to simplicity.\n",
        "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
        "        self.fc = nn.Linear(192, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
        "        x = x.view(-1, 192)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "# Change these values if you want the training to run quicker or slower.\n",
        "EPOCH_SIZE = 512\n",
        "TEST_SIZE = 256\n",
        "\n",
        "def train(model, optimizer, train_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # We set this just for the example to run quickly.\n",
        "        if batch_idx * len(data) > EPOCH_SIZE:\n",
        "            return\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test(model, data_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            # We set this just for the example to run quickly.\n",
        "            if batch_idx * len(data) > TEST_SIZE:\n",
        "                break\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    return correct / total\n",
        "def train_mnist(config):\n",
        "    # Data Setup\n",
        "    mnist_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
        "        batch_size=64,\n",
        "        shuffle=True)\n",
        "    test_loader = DataLoader(\n",
        "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
        "        batch_size=64,\n",
        "        shuffle=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ConvNet()\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
        "    for i in range(10):\n",
        "        train(model, optimizer, train_loader)\n",
        "        acc = test(model, test_loader)\n",
        "\n",
        "        # Send the current training result back to Tune\n",
        "        tune.report(mean_accuracy=acc)\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            # This saves the model to the trial directory\n",
        "            torch.save(model.state_dict(), \"./model.pth\")\n",
        "search_space = {\n",
        "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
        "    \"momentum\": tune.uniform(0.01, 0.09)\n",
        "}\n",
        "\n",
        "# Uncomment this to enable distributed execution\n",
        "# ray.shutdown()\n",
        "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
        "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
        "# Download the dataset first\n",
        "datasets.MNIST(\"~/data\", train=True, download=True)\n",
        "\n",
        "analysis = tune.run(train_mnist, config=search_space)\n"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1639106657384
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import sklearn.datasets\n",
        " import sklearn.metrics\n",
        " from sklearn.model_selection import train_test_split\n",
        " import xgboost as xgb\n",
        "\n",
        " from ray import tune\n",
        "\n",
        "\n",
        " def train_breast_cancer(config):\n",
        "     # Load dataset\n",
        "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "     # Split into train and test set\n",
        "     train_x, test_x, train_y, test_y = train_test_split(\n",
        "         data, labels, test_size=0.25)\n",
        "     # Build input matrices for XGBoost\n",
        "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
        "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
        "     # Train the classifier\n",
        "     results = {}\n",
        "     xgb.train(\n",
        "         config,\n",
        "         train_set,\n",
        "         evals=[(test_set, \"eval\")],\n",
        "         evals_result=results,\n",
        "         verbose_eval=False)\n",
        "     # Return prediction accuracy\n",
        "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
        "     tune.report(mean_accuracy=accuracy, done=True)\n",
        "\n",
        "\n",
        " config = {\n",
        "     \"objective\": \"binary:logistic\",\n",
        "     \"eval_metric\": [\"logloss\", \"error\"],\n",
        "     \"max_depth\": tune.randint(1, 9),\n",
        "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
        "     \"subsample\": tune.uniform(0.5, 1.0),\n",
        "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
        " }\n",
        " analysis = tune.run(\n",
        "     train_breast_cancer,\n",
        "     resources_per_trial={\"cpu\": 1},\n",
        "     config=config,\n",
        "     num_samples=10)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-10 03:24:19,734\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "== Status ==<br>Current time: 2021-12-10 03:24:20 (running for 00:00:01.00)<br>Memory usage on this node: 7.5/94.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/48 CPUs, 0/0 GPUs, 0.0/54.28 GiB heap, 0.0/27.14 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-10_03-24-19<br>Number of trials: 10/10 (9 PENDING, 1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_a9876_00000</td><td>RUNNING </td><td>10.0.0.5:24461</td><td style=\"text-align: right;\">0.00378889 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.802378</td></tr>\n<tr><td>train_breast_cancer_a9876_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000491363</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.888983</td></tr>\n<tr><td>train_breast_cancer_a9876_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00230636 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.908011</td></tr>\n<tr><td>train_breast_cancer_a9876_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00456041 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.909479</td></tr>\n<tr><td>train_breast_cancer_a9876_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000478117</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.735239</td></tr>\n<tr><td>train_breast_cancer_a9876_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00181548 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.897581</td></tr>\n<tr><td>train_breast_cancer_a9876_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000361135</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.543242</td></tr>\n<tr><td>train_breast_cancer_a9876_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00273367 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.975624</td></tr>\n<tr><td>train_breast_cancer_a9876_00008</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.0416131  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.95536 </td></tr>\n<tr><td>train_breast_cancer_a9876_00009</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00919299 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.797331</td></tr>\n</tbody>\n</table><br><br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "== Status ==<br>Current time: 2021-12-10 03:24:25 (running for 00:00:06.03)<br>Memory usage on this node: 7.9/94.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10.0/48 CPUs, 0/0 GPUs, 0.0/54.28 GiB heap, 0.0/27.14 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-10_03-24-19<br>Number of trials: 10/10 (10 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_a9876_00000</td><td>RUNNING </td><td>10.0.0.5:24461</td><td style=\"text-align: right;\">0.00378889 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.802378</td></tr>\n<tr><td>train_breast_cancer_a9876_00001</td><td>RUNNING </td><td>10.0.0.5:24462</td><td style=\"text-align: right;\">0.000491363</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.888983</td></tr>\n<tr><td>train_breast_cancer_a9876_00002</td><td>RUNNING </td><td>10.0.0.5:24479</td><td style=\"text-align: right;\">0.00230636 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.908011</td></tr>\n<tr><td>train_breast_cancer_a9876_00003</td><td>RUNNING </td><td>10.0.0.5:24466</td><td style=\"text-align: right;\">0.00456041 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.909479</td></tr>\n<tr><td>train_breast_cancer_a9876_00004</td><td>RUNNING </td><td>10.0.0.5:24469</td><td style=\"text-align: right;\">0.000478117</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.735239</td></tr>\n<tr><td>train_breast_cancer_a9876_00005</td><td>RUNNING </td><td>10.0.0.5:24471</td><td style=\"text-align: right;\">0.00181548 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.897581</td></tr>\n<tr><td>train_breast_cancer_a9876_00006</td><td>RUNNING </td><td>10.0.0.5:24407</td><td style=\"text-align: right;\">0.000361135</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.543242</td></tr>\n<tr><td>train_breast_cancer_a9876_00007</td><td>RUNNING </td><td>10.0.0.5:24470</td><td style=\"text-align: right;\">0.00273367 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.975624</td></tr>\n<tr><td>train_breast_cancer_a9876_00008</td><td>RUNNING </td><td>10.0.0.5:24463</td><td style=\"text-align: right;\">0.0416131  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.95536 </td></tr>\n<tr><td>train_breast_cancer_a9876_00009</td><td>RUNNING </td><td>10.0.0.5:24472</td><td style=\"text-align: right;\">0.00919299 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.797331</td></tr>\n</tbody>\n</table><br><br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Result for train_breast_cancer_a9876_00000:\n  date: 2021-12-10_03-24-28\n  done: true\n  experiment_id: 4b8c5fcd6681461fa96c1bef98240f5b\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.888112\n  node_ip: 10.0.0.5\n  pid: 24461\n  time_since_restore: 7.398552179336548\n  time_this_iter_s: 7.398552179336548\n  time_total_s: 7.398552179336548\n  timestamp: 1639106668\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a9876_00000\n  \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "== Status ==<br>Current time: 2021-12-10 03:24:31 (running for 00:00:11.46)<br>Memory usage on this node: 7.7/94.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 9.0/48 CPUs, 0/0 GPUs, 0.0/54.28 GiB heap, 0.0/27.14 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-10_03-24-19<br>Number of trials: 10/10 (9 RUNNING, 1 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_a9876_00001</td><td>RUNNING   </td><td>10.0.0.5:24462</td><td style=\"text-align: right;\">0.000491363</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.888983</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00002</td><td>RUNNING   </td><td>10.0.0.5:24479</td><td style=\"text-align: right;\">0.00230636 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.908011</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00003</td><td>RUNNING   </td><td>10.0.0.5:24466</td><td style=\"text-align: right;\">0.00456041 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.909479</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00004</td><td>RUNNING   </td><td>10.0.0.5:24469</td><td style=\"text-align: right;\">0.000478117</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.735239</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00005</td><td>RUNNING   </td><td>10.0.0.5:24471</td><td style=\"text-align: right;\">0.00181548 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.897581</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00006</td><td>RUNNING   </td><td>10.0.0.5:24407</td><td style=\"text-align: right;\">0.000361135</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.543242</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00007</td><td>RUNNING   </td><td>10.0.0.5:24470</td><td style=\"text-align: right;\">0.00273367 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.975624</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00008</td><td>RUNNING   </td><td>10.0.0.5:24463</td><td style=\"text-align: right;\">0.0416131  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.95536 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00009</td><td>RUNNING   </td><td>10.0.0.5:24472</td><td style=\"text-align: right;\">0.00919299 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.797331</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00000</td><td>TERMINATED</td><td>10.0.0.5:24461</td><td style=\"text-align: right;\">0.00378889 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.802378</td><td style=\"text-align: right;\">0.888112</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.39855</td></tr>\n</tbody>\n</table><br><br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Result for train_breast_cancer_a9876_00001:\n  date: 2021-12-10_03-24-32\n  done: true\n  experiment_id: 71c40e70593f42dab1e1fde7e39e5f40\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.86014\n  node_ip: 10.0.0.5\n  pid: 24462\n  time_since_restore: 11.064076662063599\n  time_this_iter_s: 11.064076662063599\n  time_total_s: 11.064076662063599\n  timestamp: 1639106672\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a9876_00001\n  \nResult for train_breast_cancer_a9876_00002:\n  date: 2021-12-10_03-24-32\n  done: true\n  experiment_id: 16a03d4b623e418996df96241c8b2388\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.895105\n  node_ip: 10.0.0.5\n  pid: 24479\n  time_since_restore: 11.145933628082275\n  time_this_iter_s: 11.145933628082275\n  time_total_s: 11.145933628082275\n  timestamp: 1639106672\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a9876_00002\n  \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "== Status ==<br>Current time: 2021-12-10 03:24:36 (running for 00:00:17.21)<br>Memory usage on this node: 7.3/94.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 7.0/48 CPUs, 0/0 GPUs, 0.0/54.28 GiB heap, 0.0/27.14 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-10_03-24-19<br>Number of trials: 10/10 (7 RUNNING, 3 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_a9876_00003</td><td>RUNNING   </td><td>10.0.0.5:24466</td><td style=\"text-align: right;\">0.00456041 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.909479</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00004</td><td>RUNNING   </td><td>10.0.0.5:24469</td><td style=\"text-align: right;\">0.000478117</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.735239</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00005</td><td>RUNNING   </td><td>10.0.0.5:24471</td><td style=\"text-align: right;\">0.00181548 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.897581</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00006</td><td>RUNNING   </td><td>10.0.0.5:24407</td><td style=\"text-align: right;\">0.000361135</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.543242</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00007</td><td>RUNNING   </td><td>10.0.0.5:24470</td><td style=\"text-align: right;\">0.00273367 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.975624</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00008</td><td>RUNNING   </td><td>10.0.0.5:24463</td><td style=\"text-align: right;\">0.0416131  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.95536 </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00009</td><td>RUNNING   </td><td>10.0.0.5:24472</td><td style=\"text-align: right;\">0.00919299 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.797331</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00000</td><td>TERMINATED</td><td>10.0.0.5:24461</td><td style=\"text-align: right;\">0.00378889 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.802378</td><td style=\"text-align: right;\">0.888112</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.39855</td></tr>\n<tr><td>train_breast_cancer_a9876_00001</td><td>TERMINATED</td><td>10.0.0.5:24462</td><td style=\"text-align: right;\">0.000491363</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.888983</td><td style=\"text-align: right;\">0.86014 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.0641 </td></tr>\n<tr><td>train_breast_cancer_a9876_00002</td><td>TERMINATED</td><td>10.0.0.5:24479</td><td style=\"text-align: right;\">0.00230636 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.908011</td><td style=\"text-align: right;\">0.895105</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.1459 </td></tr>\n</tbody>\n</table><br><br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Result for train_breast_cancer_a9876_00006:\n  date: 2021-12-10_03-24-38\n  done: true\n  experiment_id: 71e3908bad894d6489608e9104300e3b\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.93007\n  node_ip: 10.0.0.5\n  pid: 24407\n  time_since_restore: 17.26025152206421\n  time_this_iter_s: 17.26025152206421\n  time_total_s: 17.26025152206421\n  timestamp: 1639106678\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a9876_00006\n  \nResult for train_breast_cancer_a9876_00009:\n  date: 2021-12-10_03-24-39\n  done: true\n  experiment_id: 7a7618e5041f409692686cd22eea7b3d\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.923077\n  node_ip: 10.0.0.5\n  pid: 24472\n  time_since_restore: 17.459272861480713\n  time_this_iter_s: 17.459272861480713\n  time_total_s: 17.459272861480713\n  timestamp: 1639106679\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a9876_00009\n  \nResult for train_breast_cancer_a9876_00004:\n  date: 2021-12-10_03-24-40\n  done: true\n  experiment_id: e18db97b3f414dfb8bd4ab9ab6d7173f\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.958042\n  node_ip: 10.0.0.5\n  pid: 24469\n  time_since_restore: 19.217035055160522\n  time_this_iter_s: 19.217035055160522\n  time_total_s: 19.217035055160522\n  timestamp: 1639106680\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a9876_00004\n  \nResult for train_breast_cancer_a9876_00008:\n  date: 2021-12-10_03-24-41\n  done: true\n  experiment_id: 948e3c626b5e4e1683d19aabf71deabc\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.923077\n  node_ip: 10.0.0.5\n  pid: 24463\n  time_since_restore: 19.712729692459106\n  time_this_iter_s: 19.712729692459106\n  time_total_s: 19.712729692459106\n  timestamp: 1639106681\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a9876_00008\n  \nResult for train_breast_cancer_a9876_00005:\n  date: 2021-12-10_03-24-41\n  done: true\n  experiment_id: 7da6b61c5f8140c897c8c3d953841c73\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.916084\n  node_ip: 10.0.0.5\n  pid: 24471\n  time_since_restore: 20.038052082061768\n  time_this_iter_s: 20.038052082061768\n  time_total_s: 20.038052082061768\n  timestamp: 1639106681\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a9876_00005\n  \nResult for train_breast_cancer_a9876_00007:\n  date: 2021-12-10_03-24-42\n  done: true\n  experiment_id: e6fad8cf9daa4ce28d48df228815f102\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.958042\n  node_ip: 10.0.0.5\n  pid: 24470\n  time_since_restore: 20.27607297897339\n  time_this_iter_s: 20.27607297897339\n  time_total_s: 20.27607297897339\n  timestamp: 1639106682\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a9876_00007\n  \nResult for train_breast_cancer_a9876_00003:\n  date: 2021-12-10_03-24-42\n  done: true\n  experiment_id: 0ef300f575a84ae2a44540d2bacbc11a\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.944056\n  node_ip: 10.0.0.5\n  pid: 24466\n  time_since_restore: 20.275203466415405\n  time_this_iter_s: 20.275203466415405\n  time_total_s: 20.275203466415405\n  timestamp: 1639106682\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a9876_00003\n  \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "== Status ==<br>Current time: 2021-12-10 03:24:42 (running for 00:00:22.30)<br>Memory usage on this node: 6.2/94.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/48 CPUs, 0/0 GPUs, 0.0/54.28 GiB heap, 0.0/27.14 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-10_03-24-19<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_a9876_00000</td><td>TERMINATED</td><td>10.0.0.5:24461</td><td style=\"text-align: right;\">0.00378889 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.802378</td><td style=\"text-align: right;\">0.888112</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.39855</td></tr>\n<tr><td>train_breast_cancer_a9876_00001</td><td>TERMINATED</td><td>10.0.0.5:24462</td><td style=\"text-align: right;\">0.000491363</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.888983</td><td style=\"text-align: right;\">0.86014 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.0641 </td></tr>\n<tr><td>train_breast_cancer_a9876_00002</td><td>TERMINATED</td><td>10.0.0.5:24479</td><td style=\"text-align: right;\">0.00230636 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.908011</td><td style=\"text-align: right;\">0.895105</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.1459 </td></tr>\n<tr><td>train_breast_cancer_a9876_00003</td><td>TERMINATED</td><td>10.0.0.5:24466</td><td style=\"text-align: right;\">0.00456041 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.909479</td><td style=\"text-align: right;\">0.944056</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        20.2752 </td></tr>\n<tr><td>train_breast_cancer_a9876_00004</td><td>TERMINATED</td><td>10.0.0.5:24469</td><td style=\"text-align: right;\">0.000478117</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.735239</td><td style=\"text-align: right;\">0.958042</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        19.217  </td></tr>\n<tr><td>train_breast_cancer_a9876_00005</td><td>TERMINATED</td><td>10.0.0.5:24471</td><td style=\"text-align: right;\">0.00181548 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.897581</td><td style=\"text-align: right;\">0.916084</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        20.0381 </td></tr>\n<tr><td>train_breast_cancer_a9876_00006</td><td>TERMINATED</td><td>10.0.0.5:24407</td><td style=\"text-align: right;\">0.000361135</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.543242</td><td style=\"text-align: right;\">0.93007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        17.2603 </td></tr>\n<tr><td>train_breast_cancer_a9876_00007</td><td>TERMINATED</td><td>10.0.0.5:24470</td><td style=\"text-align: right;\">0.00273367 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.975624</td><td style=\"text-align: right;\">0.958042</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        20.2761 </td></tr>\n<tr><td>train_breast_cancer_a9876_00008</td><td>TERMINATED</td><td>10.0.0.5:24463</td><td style=\"text-align: right;\">0.0416131  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.95536 </td><td style=\"text-align: right;\">0.923077</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        19.7127 </td></tr>\n<tr><td>train_breast_cancer_a9876_00009</td><td>TERMINATED</td><td>10.0.0.5:24472</td><td style=\"text-align: right;\">0.00919299 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.797331</td><td style=\"text-align: right;\">0.923077</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        17.4593 </td></tr>\n</tbody>\n</table><br><br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "== Status ==<br>Current time: 2021-12-10 03:24:42 (running for 00:00:22.27)<br>Memory usage on this node: 6.5/94.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/48 CPUs, 0/0 GPUs, 0.0/54.28 GiB heap, 0.0/27.14 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-10_03-24-19<br>Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_a9876_00003</td><td>RUNNING   </td><td>10.0.0.5:24466</td><td style=\"text-align: right;\">0.00456041 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.909479</td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n<tr><td>train_breast_cancer_a9876_00000</td><td>TERMINATED</td><td>10.0.0.5:24461</td><td style=\"text-align: right;\">0.00378889 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.802378</td><td style=\"text-align: right;\">0.888112</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         7.39855</td></tr>\n<tr><td>train_breast_cancer_a9876_00001</td><td>TERMINATED</td><td>10.0.0.5:24462</td><td style=\"text-align: right;\">0.000491363</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.888983</td><td style=\"text-align: right;\">0.86014 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.0641 </td></tr>\n<tr><td>train_breast_cancer_a9876_00002</td><td>TERMINATED</td><td>10.0.0.5:24479</td><td style=\"text-align: right;\">0.00230636 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.908011</td><td style=\"text-align: right;\">0.895105</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        11.1459 </td></tr>\n<tr><td>train_breast_cancer_a9876_00004</td><td>TERMINATED</td><td>10.0.0.5:24469</td><td style=\"text-align: right;\">0.000478117</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.735239</td><td style=\"text-align: right;\">0.958042</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        19.217  </td></tr>\n<tr><td>train_breast_cancer_a9876_00005</td><td>TERMINATED</td><td>10.0.0.5:24471</td><td style=\"text-align: right;\">0.00181548 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.897581</td><td style=\"text-align: right;\">0.916084</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        20.0381 </td></tr>\n<tr><td>train_breast_cancer_a9876_00006</td><td>TERMINATED</td><td>10.0.0.5:24407</td><td style=\"text-align: right;\">0.000361135</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.543242</td><td style=\"text-align: right;\">0.93007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        17.2603 </td></tr>\n<tr><td>train_breast_cancer_a9876_00007</td><td>TERMINATED</td><td>10.0.0.5:24470</td><td style=\"text-align: right;\">0.00273367 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.975624</td><td style=\"text-align: right;\">0.958042</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        20.2761 </td></tr>\n<tr><td>train_breast_cancer_a9876_00008</td><td>TERMINATED</td><td>10.0.0.5:24463</td><td style=\"text-align: right;\">0.0416131  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.95536 </td><td style=\"text-align: right;\">0.923077</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        19.7127 </td></tr>\n<tr><td>train_breast_cancer_a9876_00009</td><td>TERMINATED</td><td>10.0.0.5:24472</td><td style=\"text-align: right;\">0.00919299 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.797331</td><td style=\"text-align: right;\">0.923077</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        17.4593 </td></tr>\n</tbody>\n</table><br><br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-10 03:24:42,146\tINFO tune.py:626 -- Total run time: 22.42 seconds (22.29 seconds for the tuning loop).\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1639106681808
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Spark on Ray"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "import raydp\n",
        "import os\n",
        "ray.shutdown()\n",
        "ray.init()\n",
        "os.environ[\"PYSPARK_PYTHON\"]=\"/anaconda/envs/azureml_py38/bin/python3\"\n",
        "\n",
        "# ray.init(address ='ray://10.0.0.11:6379')\n",
        "spark = raydp.init_spark(\n",
        "  app_name = \"example\",\n",
        "  num_executors = 2,\n",
        "  executor_cores = 1,\n",
        "  executor_memory = \"1gb\"\n",
        ")\n",
        "\n",
        "# data =spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://ojsales-simulatedcontainer@azureopendatastorage.blob.core.windows.net/oj_sales_data/Store10*.csv\")\n",
        "\n",
        "\n",
        "# # normal data processesing with Spark\n",
        "# df = spark.createDataFrame([('look',), ('spark',), ('tutorial',), ('spark',), ('look', ), ('python', )], ['word'])\n",
        "# df.show()\n",
        "# word_count = df.groupBy('word').count()\n",
        "# word_count.show()\n",
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql.functions import col, pandas_udf\n",
        "from pyspark.sql.types import LongType\n",
        "\n",
        "# Declare the function and create the UDF\n",
        "def multiply_func(a: pd.Series, b: pd.Series) -> pd.Series:\n",
        "    return a * b\n",
        "\n",
        "multiply = pandas_udf(multiply_func, returnType=LongType())\n",
        "\n",
        "# The function for a pandas_udf should be able to execute with local Pandas data\n",
        "x = pd.Series([1, 2, 3])\n",
        "print(multiply_func(x, x))\n",
        "# 0    1\n",
        "# 1    4\n",
        "# 2    9\n",
        "# dtype: int64\n",
        "\n",
        "# Create a Spark DataFrame, 'spark' is an existing SparkSession\n",
        "df = spark.createDataFrame(pd.DataFrame(x, columns=[\"x\"]))\n",
        "\n",
        "# Execute function as a Spark vectorized UDF\n",
        "df.select(multiply(col(\"x\"), col(\"x\"))).show()\n",
        "# +-------------------+\n",
        "# |multiply_func(x, x)|\n",
        "# +-------------------+\n",
        "# |                  1|\n",
        "# |                  4|\n",
        "# |                  9|\n",
        "# +-------------------+\n",
        "\n",
        "\n",
        "# stop the spark cluster\n",
        "raydp.stop_spark()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-06 19:48:42,187\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n2021-12-06 19:48:45,043 WARN Utils [Thread-1]: Your hostname, nc6v0 resolves to a loopback address: 127.0.0.1; using 10.0.0.11 instead (on interface eth0)\n2021-12-06 19:48:45,046 WARN Utils [Thread-1]: Set SPARK_LOCAL_IP if you need to bind to another address\n2021-12-06 19:48:45,240 WARN NativeCodeLoader [Thread-1]: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING: An illegal reflective access operation has occurred\nWARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2021-12-06 19:48:45,321 INFO SecurityManager [Thread-1]: Changing view acls to: azureuser\n2021-12-06 19:48:45,321 INFO SecurityManager [Thread-1]: Changing modify acls to: azureuser\n2021-12-06 19:48:45,322 INFO SecurityManager [Thread-1]: Changing view acls groups to: \n2021-12-06 19:48:45,322 INFO SecurityManager [Thread-1]: Changing modify acls groups to: \n2021-12-06 19:48:45,323 INFO SecurityManager [Thread-1]: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(azureuser); groups with view permissions: Set(); users  with modify permissions: Set(azureuser); groups with modify permissions: Set()\n2021-12-06 19:48:45,591 INFO Utils [Thread-1]: Successfully started service 'RAY_RPC_ENV' on port 44621.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/jars/ray_dist.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING: An illegal reflective access operation has occurred\nWARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2021-12-06 19:48:48,798 INFO RayAppMaster$RayAppMasterEndpoint [dispatcher-event-loop-1]: Registering app example\n2021-12-06 19:48:48,802 INFO RayAppMaster$RayAppMasterEndpoint [dispatcher-event-loop-1]: Registered app example with ID app-20211206194848-0000\n0    1\n1    4\n2    9\ndtype: int64\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n                                                                                \r"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+-------------------+\n|multiply_func(x, x)|\n+-------------------+\n|                  1|\n|                  4|\n|                  9|\n+-------------------+\n\n2021-12-06 19:48:59,086 INFO RayAppMaster [Thread-1]: Stopping RayAppMaster\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "raydp.stop_spark()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Ray on Job Cluster"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#     pyarrow >=6.0.1\n",
        "# dask >=2021.11.2\n",
        "# adlfs >=2021.10.0\n",
        "# fsspec==2021.10.1\n",
        "# ray[default]==1.9.0\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# base_conda_dep =['adlfs>=2021.10.0','pytorch','matplotlib','torchvision','pip']\n",
        "# base_pip_dep = ['sklearn','xgboost','lightgbm','ray[default]==1.9.0', 'xgboost_ray', 'dask','pyarrow>=6.0.1', 'azureml-mlflow']\n",
        "compute_cluster = 'worker-cpu-v3'\n",
        "maxnode =5\n",
        "vm_size='STANDARD_DS3_V2'\n",
        "vnet='rayvnet'\n",
        "subnet='default'\n",
        "exp ='ray_on_aml_job'\n",
        "ws_detail = ws.get_details()\n",
        "ws_rg = ws_detail['id'].split(\"/\")[4]\n",
        "vnet_rg=None\n",
        "try:\n",
        "    ray_cluster = ComputeTarget(workspace=ws, name=compute_cluster)\n",
        "\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    if vnet_rg is None:\n",
        "        vnet_rg = ws_rg\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
        "                                                        min_nodes=0, max_nodes=maxnode,\n",
        "                                                        vnet_resourcegroup_name=vnet_rg,\n",
        "                                                        vnet_name=vnet,\n",
        "                                                        subnet_name=subnet)\n",
        "    ray_cluster = ComputeTarget.create(ws, compute_cluster, compute_config)\n",
        "\n",
        "    ray_cluster.wait_for_completion(show_output=True)\n",
        "\n",
        "\n",
        "# python_version = [\"python=\"+platform.python_version()]\n",
        "\n",
        "\n",
        "\n",
        "# conda_packages = python_version+base_conda_dep\n",
        "# pip_packages = base_pip_dep \n",
        "\n",
        "# conda_dep = CondaDependencies()\n",
        "\n",
        "# rayEnv = Environment(name=\"rayEnv\")\n",
        "rayEnv = Environment.get(ws, \"rayEnv\", version=16)\n",
        "# for conda_package in conda_packages:\n",
        "#     conda_dep.add_conda_package(conda_package)\n",
        "\n",
        "# for pip_package in pip_packages:\n",
        "#     conda_dep.add_pip_package(pip_package)\n",
        "\n",
        "# # Adds dependencies to PythonSection of myenv\n",
        "# rayEnv.python.conda_dependencies=conda_dep\n",
        "\n",
        "src = ScriptRunConfig(source_directory='job',\n",
        "                script='aml_job.py',\n",
        "                environment=rayEnv,\n",
        "                compute_target=ray_cluster,\n",
        "                distributed_job_config=PyTorchConfiguration(node_count=maxnode),\n",
        "                    # arguments = [\"--master_ip\",master_ip]\n",
        "                )\n",
        "run = Experiment(ws, exp).submit(src)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Found existing cluster, use it.\n"
        }
      ],
      "execution_count": 15,
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "cac4749ce6e64bfd07fafd5bf9c175e86cc05b1d81ce0d05824a22ecc489c963"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}