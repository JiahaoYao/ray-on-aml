{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "# from ray_on_azureml.ray_on_aml import getRay\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "import importlib\n",
    "from src.ray_on_azureml.ray_on_aml import Ray_On_AML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"worker-cpu-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_on_aml.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_py38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 17:54:08,788\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 17:54:24,358\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 10.0.0.11:6379\n",
      "2021-12-05 17:54:24,492\tWARNING worker.py:1219 -- The autoscaler failed with the following error:\n",
      "Terminated with signal 15\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 543, in <module>\n",
      "    monitor.run()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 439, in run\n",
      "    self._run()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 346, in _run\n",
      "    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run, ray = ray_on_aml.getRay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node:10.0.0.29': 1.0,\n",
       " 'object_store_memory': 38201283377.0,\n",
       " 'CPU': 26.0,\n",
       " 'memory': 83487628905.0,\n",
       " 'node:10.0.0.20': 1.0,\n",
       " 'node:10.0.0.25': 1.0,\n",
       " 'node:10.0.0.27': 1.0,\n",
       " 'node:10.0.0.11': 1.0,\n",
       " 'accelerator_type:K80': 1.0,\n",
       " 'GPU': 1.0,\n",
       " 'node:10.0.0.17': 1.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ray\n",
    "# ray.init(dashboard_host=\"0.0.0.0\")\n",
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3524.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5590.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9930</th>\n",
       "      <td>933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9944</th>\n",
       "      <td>9450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>2110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9968</th>\n",
       "      <td>9633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>9113.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>977 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade\n",
       "age         \n",
       "12    3524.5\n",
       "14     693.0\n",
       "24    8510.0\n",
       "51    6913.0\n",
       "53    5590.0\n",
       "...      ...\n",
       "9930   933.0\n",
       "9944  9450.0\n",
       "9952  2110.0\n",
       "9968  9633.0\n",
       "9975  9113.0\n",
       "\n",
       "[977 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ray\n",
    "# ray.init()\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# ray.shutdown()\n",
    "# client = ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True  )\n",
    "# with client:\n",
    "# Start Ray.\n",
    "# Tip: If connecting to an existing cluster, use ray.init(address=\"auto\").\n",
    "# ray.init(address ='ray://10.0.0.14:10001',ignore_reinit_error=True)\n",
    "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
    "\n",
    "# The Dask scheduler submits the underlying task graph to Ray.\n",
    "d_arr.mean().compute(scheduler=ray_dask_get)\n",
    "\n",
    "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
    "# specify it on each compute call.\n",
    "dask.config.set(scheduler=ray_dask_get)\n",
    "\n",
    "df = dd.from_pandas(\n",
    "    pd.DataFrame(\n",
    "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
    "    npartitions=2)\n",
    "df.groupby([\"age\"]).mean().compute()\n",
    "\n",
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 04:57:52,298\tWARNING function_runner.py:561 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "2021-12-05 04:57:52,311\tINFO logger.py:605 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2021-12-05 04:57:52,311\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
      "2021-12-05 04:57:52,330\tWARNING tune.py:570 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-05 04:57:52 (running for 00:00:00.11)<br>Memory usage on this node: 3.3/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/77.75 GiB heap, 0.0/35.58 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-05_04-57-52<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_e6d1f_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">1.69244e-07</td><td style=\"text-align: right;\"> 0.0674072</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=21852)\u001b[0m /anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=21852)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_mnist_e6d1f_00000:\n",
      "  date: 2021-12-05_04-57-53\n",
      "  done: false\n",
      "  experiment_id: dc6cebb9cdd14cd4aa515c02c9d89af4\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.11875\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 21852\n",
      "  time_since_restore: 0.25304245948791504\n",
      "  time_this_iter_s: 0.25304245948791504\n",
      "  time_total_s: 0.25304245948791504\n",
      "  timestamp: 1638680273\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: e6d1f_00000\n",
      "  \n",
      "Result for train_mnist_e6d1f_00000:\n",
      "  date: 2021-12-05_04-57-55\n",
      "  done: true\n",
      "  experiment_id: dc6cebb9cdd14cd4aa515c02c9d89af4\n",
      "  experiment_tag: 0_lr=1.6924e-07,momentum=0.067407\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 10\n",
      "  mean_accuracy: 0.090625\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 21852\n",
      "  time_since_restore: 2.0839645862579346\n",
      "  time_this_iter_s: 0.20478534698486328\n",
      "  time_total_s: 2.0839645862579346\n",
      "  timestamp: 1638680275\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: e6d1f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-05 04:57:55 (running for 00:00:03.26)<br>Memory usage on this node: 3.4/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/77.75 GiB heap, 0.0/35.58 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-05_04-57-52<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_e6d1f_00000</td><td>TERMINATED</td><td>10.0.0.11:21852</td><td style=\"text-align: right;\">1.69244e-07</td><td style=\"text-align: right;\"> 0.0674072</td><td style=\"text-align: right;\">0.090625</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.08396</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 04:57:55,697\tINFO tune.py:626 -- Total run time: 3.40 seconds (3.25 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "# import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # In this example, we don't change the model architecture\n",
    "        # due to simplicity.\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "# Change these values if you want the training to run quicker or slower.\n",
    "EPOCH_SIZE = 512\n",
    "TEST_SIZE = 256\n",
    "\n",
    "def train(model, optimizer, train_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # We set this just for the example to run quickly.\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "            return\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # We set this just for the example to run quickly.\n",
    "            if batch_idx * len(data) > TEST_SIZE:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "def train_mnist(config):\n",
    "    # Data Setup\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = ConvNet()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "    for i in range(10):\n",
    "        train(model, optimizer, train_loader)\n",
    "        acc = test(model, test_loader)\n",
    "\n",
    "        # Send the current training result back to Tune\n",
    "        tune.report(mean_accuracy=acc)\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            # This saves the model to the trial directory\n",
    "            torch.save(model.state_dict(), \"./model.pth\")\n",
    "search_space = {\n",
    "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
    "    \"momentum\": tune.uniform(0.01, 0.09)\n",
    "}\n",
    "\n",
    "# Uncomment this to enable distributed execution\n",
    "# ray.shutdown()\n",
    "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
    "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
    "# Download the dataset first\n",
    "datasets.MNIST(\"~/data\", train=True, download=True)\n",
    "\n",
    "analysis = tune.run(train_mnist, config=search_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 05:35:20,237\tWARNING function_runner.py:561 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "2021-12-05 05:35:20,242\tINFO logger.py:605 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2021-12-05 05:35:20,242\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
      "2021-12-05 05:35:20,259\tWARNING tune.py:570 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-05 05:35:20 (running for 00:00:00.18)<br>Memory usage on this node: 3.2/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/77.75 GiB heap, 0.0/35.58 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-05_05-35-20<br>Number of trials: 10/10 (10 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_breast_cancer_22b10_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000115884</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.820534</td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000159302</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.800876</td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0925686  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.576718</td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000185896</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.610289</td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00243399 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.554835</td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00398388 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.651541</td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0628726  </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.920078</td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000289861</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.689321</td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000293346</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.997516</td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000158485</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.500692</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_breast_cancer_22b10_00000:\n",
      "  date: 2021-12-05_05-35-21\n",
      "  done: true\n",
      "  experiment_id: 286b920c722a4779ab42009884ed4c3e\n",
      "  hostname: 71bb804dc8084a5e8ad9b06b8cb81bbb000001\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.951049\n",
      "  node_ip: 10.0.0.17\n",
      "  pid: 227\n",
      "  time_since_restore: 0.08456587791442871\n",
      "  time_this_iter_s: 0.08456587791442871\n",
      "  time_total_s: 0.08456587791442871\n",
      "  timestamp: 1638682521\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 22b10_00000\n",
      "  \n",
      "Result for train_breast_cancer_22b10_00003:\n",
      "  date: 2021-12-05_05-35-22\n",
      "  done: true\n",
      "  experiment_id: cb7bfb305c8a4595a065a1ab188e5d20\n",
      "  hostname: 71bb804dc8084a5e8ad9b06b8cb81bbb00000I\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.965035\n",
      "  node_ip: 10.0.0.27\n",
      "  pid: 216\n",
      "  time_since_restore: 0.11986041069030762\n",
      "  time_this_iter_s: 0.11986041069030762\n",
      "  time_total_s: 0.11986041069030762\n",
      "  timestamp: 1638682522\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 22b10_00003\n",
      "  \n",
      "Result for train_breast_cancer_22b10_00001:\n",
      "  date: 2021-12-05_05-35-22\n",
      "  done: true\n",
      "  experiment_id: 17ff739ab2954020a766434fcb0adae0\n",
      "  hostname: 71bb804dc8084a5e8ad9b06b8cb81bbb00000K\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.923077\n",
      "  node_ip: 10.0.0.29\n",
      "  pid: 233\n",
      "  time_since_restore: 0.38966917991638184\n",
      "  time_this_iter_s: 0.38966917991638184\n",
      "  time_total_s: 0.38966917991638184\n",
      "  timestamp: 1638682522\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 22b10_00001\n",
      "  \n",
      "Result for train_breast_cancer_22b10_00008:\n",
      "  date: 2021-12-05_05-35-22\n",
      "  done: true\n",
      "  experiment_id: 2028befb5bfd44408182c743978e164e\n",
      "  hostname: 71bb804dc8084a5e8ad9b06b8cb81bbb00000K\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.951049\n",
      "  node_ip: 10.0.0.29\n",
      "  pid: 234\n",
      "  time_since_restore: 0.3355069160461426\n",
      "  time_this_iter_s: 0.3355069160461426\n",
      "  time_total_s: 0.3355069160461426\n",
      "  timestamp: 1638682522\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 22b10_00008\n",
      "  \n",
      "Result for train_breast_cancer_22b10_00005:\n",
      "  date: 2021-12-05_05-35-22\n",
      "  done: true\n",
      "  experiment_id: 74ff2c9d354949848e3e4950299d3585\n",
      "  hostname: 71bb804dc8084a5e8ad9b06b8cb81bbb00000C\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.944056\n",
      "  node_ip: 10.0.0.25\n",
      "  pid: 257\n",
      "  time_since_restore: 0.10262274742126465\n",
      "  time_this_iter_s: 0.10262274742126465\n",
      "  time_total_s: 0.10262274742126465\n",
      "  timestamp: 1638682522\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 22b10_00005\n",
      "  \n",
      "Result for train_breast_cancer_22b10_00002:\n",
      "  date: 2021-12-05_05-35-22\n",
      "  done: true\n",
      "  experiment_id: c2390c71c6d14153a26e98aa4ab799c2\n",
      "  hostname: 71bb804dc8084a5e8ad9b06b8cb81bbb000004\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.93007\n",
      "  node_ip: 10.0.0.20\n",
      "  pid: 231\n",
      "  time_since_restore: 0.5008883476257324\n",
      "  time_this_iter_s: 0.5008883476257324\n",
      "  time_total_s: 0.5008883476257324\n",
      "  timestamp: 1638682522\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 22b10_00002\n",
      "  \n",
      "Result for train_breast_cancer_22b10_00006:\n",
      "  date: 2021-12-05_05-35-22\n",
      "  done: true\n",
      "  experiment_id: 1c3be36b21ae428fbe0126ac7d292ef8\n",
      "  hostname: 71bb804dc8084a5e8ad9b06b8cb81bbb000004\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.958042\n",
      "  node_ip: 10.0.0.20\n",
      "  pid: 230\n",
      "  time_since_restore: 0.41339993476867676\n",
      "  time_this_iter_s: 0.41339993476867676\n",
      "  time_total_s: 0.41339993476867676\n",
      "  timestamp: 1638682522\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 22b10_00006\n",
      "  \n",
      "Result for train_breast_cancer_22b10_00007:\n",
      "  date: 2021-12-05_05-35-23\n",
      "  done: true\n",
      "  experiment_id: e66cd0dc4b49478d9b9844bca20dbea7\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.951049\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 29483\n",
      "  time_since_restore: 1.2531559467315674\n",
      "  time_this_iter_s: 1.2531559467315674\n",
      "  time_total_s: 1.2531559467315674\n",
      "  timestamp: 1638682523\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 22b10_00007\n",
      "  \n",
      "Result for train_breast_cancer_22b10_00004:\n",
      "  date: 2021-12-05_05-35-23\n",
      "  done: true\n",
      "  experiment_id: 7b08be8193b946b6987e46bcbe7c9f29\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.944056\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 29482\n",
      "  time_since_restore: 1.3312878608703613\n",
      "  time_this_iter_s: 1.3312878608703613\n",
      "  time_total_s: 1.3312878608703613\n",
      "  timestamp: 1638682523\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 22b10_00004\n",
      "  \n",
      "Result for train_breast_cancer_22b10_00009:\n",
      "  date: 2021-12-05_05-35-23\n",
      "  done: true\n",
      "  experiment_id: 858f245554eb4d06b3f12867b20f6d9c\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.965035\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 29481\n",
      "  time_since_restore: 1.3548097610473633\n",
      "  time_this_iter_s: 1.3548097610473633\n",
      "  time_total_s: 1.3548097610473633\n",
      "  timestamp: 1638682523\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 22b10_00009\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-05 05:35:24 (running for 00:00:03.76)<br>Memory usage on this node: 3.2/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/77.75 GiB heap, 0.0/35.58 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-05_05-35-20<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_breast_cancer_22b10_00000</td><td>TERMINATED</td><td>10.0.0.17:227  </td><td style=\"text-align: right;\">0.000115884</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.820534</td><td style=\"text-align: right;\">0.951049</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0845659</td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00001</td><td>TERMINATED</td><td>10.0.0.29:233  </td><td style=\"text-align: right;\">0.000159302</td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.800876</td><td style=\"text-align: right;\">0.923077</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.389669 </td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00002</td><td>TERMINATED</td><td>10.0.0.20:231  </td><td style=\"text-align: right;\">0.0925686  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.576718</td><td style=\"text-align: right;\">0.93007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.500888 </td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00003</td><td>TERMINATED</td><td>10.0.0.27:216  </td><td style=\"text-align: right;\">0.000185896</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.610289</td><td style=\"text-align: right;\">0.965035</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.11986  </td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00004</td><td>TERMINATED</td><td>10.0.0.11:29482</td><td style=\"text-align: right;\">0.00243399 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.554835</td><td style=\"text-align: right;\">0.944056</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       1.33129  </td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00005</td><td>TERMINATED</td><td>10.0.0.25:257  </td><td style=\"text-align: right;\">0.00398388 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.651541</td><td style=\"text-align: right;\">0.944056</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.102623 </td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00006</td><td>TERMINATED</td><td>10.0.0.20:230  </td><td style=\"text-align: right;\">0.0628726  </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.920078</td><td style=\"text-align: right;\">0.958042</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.4134   </td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00007</td><td>TERMINATED</td><td>10.0.0.11:29483</td><td style=\"text-align: right;\">0.000289861</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.689321</td><td style=\"text-align: right;\">0.951049</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       1.25316  </td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00008</td><td>TERMINATED</td><td>10.0.0.29:234  </td><td style=\"text-align: right;\">0.000293346</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.997516</td><td style=\"text-align: right;\">0.951049</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.335507 </td></tr>\n",
       "<tr><td>train_breast_cancer_22b10_00009</td><td>TERMINATED</td><td>10.0.0.11:29481</td><td style=\"text-align: right;\">0.000158485</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.500692</td><td style=\"text-align: right;\">0.965035</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       1.35481  </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 05:35:24,128\tINFO tune.py:626 -- Total run time: 3.89 seconds (3.74 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    " import sklearn.datasets\n",
    " import sklearn.metrics\n",
    " from sklearn.model_selection import train_test_split\n",
    " import xgboost as xgb\n",
    "\n",
    " from ray import tune\n",
    "\n",
    "\n",
    " def train_breast_cancer(config):\n",
    "     # Load dataset\n",
    "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "     # Split into train and test set\n",
    "     train_x, test_x, train_y, test_y = train_test_split(\n",
    "         data, labels, test_size=0.25)\n",
    "     # Build input matrices for XGBoost\n",
    "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
    "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
    "     # Train the classifier\n",
    "     results = {}\n",
    "     xgb.train(\n",
    "         config,\n",
    "         train_set,\n",
    "         evals=[(test_set, \"eval\")],\n",
    "         evals_result=results,\n",
    "         verbose_eval=False)\n",
    "     # Return prediction accuracy\n",
    "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
    "     tune.report(mean_accuracy=accuracy, done=True)\n",
    "\n",
    "\n",
    " config = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"eval_metric\": [\"logloss\", \"error\"],\n",
    "     \"max_depth\": tune.randint(1, 9),\n",
    "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
    "     \"subsample\": tune.uniform(0.5, 1.0),\n",
    "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
    " }\n",
    " analysis = tune.run(\n",
    "     train_breast_cancer,\n",
    "     resources_per_trial={\"cpu\": 1},\n",
    "     config=config,\n",
    "     num_samples=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask\n",
    "\n",
    "# import ray\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import glob\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Model\n",
    "data_url = 'https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29073/2095843755.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'account_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'azureopendatastorage'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mddf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'az://isdweatherdatacontainer/ISDWeather/year=2019/month=2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, filters, categories, index, storage_options, engine, gather_statistics, ignore_metadata_file, split_row_groups, read_from_paths, chunksize, aggregate_files, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mgather_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     read_metadata_result = engine.read_metadata(\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/io/parquet/fastparquet.py\u001b[0m in \u001b[0;36mread_metadata\u001b[0;34m(cls, fs, paths, categories, index, gather_statistics, filters, split_row_groups, chunksize, aggregate_files, ignore_metadata_file, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;31m# then each part will correspond to a file.  Otherwise, each part will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;31m# correspond to a row group (populated below).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         parts, pf, gather_statistics, base_path = _determine_pf_parts(\n\u001b[0m\u001b[1;32m    759\u001b[0m             \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/io/parquet/fastparquet.py\u001b[0m in \u001b[0;36m_determine_pf_parts\u001b[0;34m(fs, paths, gather_statistics, ignore_metadata_file, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;31m# There is only one file to read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         pf = ParquetFile(\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fastparquet/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, verify, open_with, root, sep, fs, pandas_nulls)\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mfn2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fastparquet/api.py\u001b[0m in \u001b[0;36m_parse_header\u001b[0;34m(self, f, verify)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb'PAR1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0mhead_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mseek\u001b[0;34m(self, loc, whence)\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0mnloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mwhence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m             \u001b[0mnloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid whence (%s, should be 0, 1 or 2)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "storage_options = {'account_name': 'azureopendatastorage'}\n",
    "ddf = dd.read_parquet('az://isdweatherdatacontainer/ISDWeather/year=2019/month=2', storage_options=storage_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adlfs import AzureBlobFileSystem,AzureDatalakeFileSystem\n",
    "sas_token='sp=rle&st=2021-11-27T19:26:49Z&se=2022-04-22T02:26:49Z&spr=https&sv=2020-08-04&sr=c&sig=gpYJ3LofkkjkeWkrMDTY1Ge6NsOCghbUR9CQs65HCvU%3D'\n",
    "account_key='ak7nSgU/iRc5XCvXjaM2UwX18ybS9WO1BsE4Vm42XLmiZvBm1kCyZQD3USeCCOiwusWkDaq0jcRF1JpPHiAMhw=='\n",
    "account_name=\"adlsgen7\"\n",
    "abfs = AzureBlobFileSystem(account_name=\"adlsgen7\",account_key=account_key,  container_name=\"mltraining\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "\n",
    "# storage_options={'account_name': account_name, 'account_key': account_key}\n",
    "\n",
    "# # ddf = dd.read_csv('abfs://{CONTAINER}/{FOLDER}/*.csv', storage_options=storage_options)\n",
    "# ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year=2008/month=1/*.parquet', storage_options=storage_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "mltraining/ISDWeatherDelta/year2008/month",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29073/2169028898.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"az://mltraining/ISDWeatherDelta/year2008/month\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesystem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mabfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/data/read_api.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(paths, filesystem, columns, parallelism, ray_remote_args, _tensor_column_schema, **arrow_parquet_args)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0marrow_parquet_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_block_udf\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_block_udf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     return read_datasource(\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mParquetDatasource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mparallelism\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallelism\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/data/read_api.py\u001b[0m in \u001b[0;36mread_datasource\u001b[0;34m(datasource, parallelism, ray_remote_args, _spread_resource_prefix, **read_args)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \"\"\"\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mread_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallelism\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mread_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/data/datasource/parquet_datasource.py\u001b[0m in \u001b[0;36mprepare_read\u001b[0;34m(self, parallelism, paths, filesystem, columns, schema, _block_udf, **reader_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mdataset_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset_kwargs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         pq_ds = pq.ParquetDataset(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mdataset_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, path_or_paths, filesystem, schema, metadata, split_row_groups, validate_schema, filters, metadata_nthreads, read_dictionary, memory_map, buffer_size, partitioning, use_legacy_dataset)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_legacy_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             return _ParquetDatasetV2(path_or_paths, filesystem=filesystem,\n\u001b[0m\u001b[1;32m   1230\u001b[0m                                      \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                                      \u001b[0mpartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, **kwargs)\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 infer_dictionary=True)\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m         self._dataset = ds.dataset(path_or_paths, filesystem=filesystem,\n\u001b[0m\u001b[1;32m   1559\u001b[0m                                    \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparquet_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m                                    \u001b[0mpartitioning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_filesystem_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_is_path_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mselector_ignore_prefixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselector_ignore_prefixes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     )\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0mfactory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileSystemDatasetFactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths_or_selector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/_dataset.pyx\u001b[0m in \u001b[0;36mpyarrow._dataset.FileSystemDatasetFactory.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/_fs.pyx\u001b[0m in \u001b[0;36mpyarrow._fs._cb_get_file_info_selector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyarrow/fs.py\u001b[0m in \u001b[0;36mget_file_info_selector\u001b[0;34m(self, selector)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotADirectoryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_not_found\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: mltraining/ISDWeatherDelta/year2008/month"
     ]
    }
   ],
   "source": [
    "\n",
    "data = ray.data.read_parquet(\"az://mltraining/ISDWeatherDelta/year2008/month\", filesystem=abfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8103070"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7f76c7df17f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(scheduler=ray_dask_get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "CPU times: user 5.35 s, sys: 4.77 s, total: 10.1 s\n",
      "Wall time: 35.1 s\n",
      "Downloading...\n",
      "CPU times: user 6.06 s, sys: 4.88 s, total: 10.9 s\n",
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "for year in range(2019, 2020+1):\n",
    "    ds = Dataset.File.from_files(f'{data_url}/year={year}/month=*/*.parquet', validate=False)\n",
    "    print('Downloading...')\n",
    "    %time ds.download(f'/tmp/data/isd/year={year}', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('/tmp/data/isd/year=*/month=*/*.parquet')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(FileNotFoundError)",
     "evalue": "\u001b[36mray::dask:make_meta-04803ab8-eacd-4c1c-8dba-c12bef057b2d\u001b[39m (pid=207, ip=10.0.0.17)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RayTaskError: \u001b[36mray::dask:read_parquet-568d98c5-6b4e-4819-b9bf-b4760b82036f\u001b[39m (pid=207, ip=10.0.0.17)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\", line 350, in dask_task_wrapper\n  File \"/azureml-envs/azureml_8afa3af27adc7f1a69c133d28398582a/lib/python3.8/site-packages/pandas/io/parquet.py\", line 495, in read_parquet\n    return impl.read(\n  File \"/azureml-envs/azureml_8afa3af27adc7f1a69c133d28398582a/lib/python3.8/site-packages/pandas/io/parquet.py\", line 232, in read\n    path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n  File \"/azureml-envs/azureml_8afa3af27adc7f1a69c133d28398582a/lib/python3.8/site-packages/pandas/io/parquet.py\", line 101, in _get_path_or_handle\n    handles = get_handle(\n  File \"/azureml-envs/azureml_8afa3af27adc7f1a69c133d28398582a/lib/python3.8/site-packages/pandas/io/common.py\", line 711, in get_handle\n    handle = open(handle, ioargs.mode)\nFileNotFoundError: [Errno 2] No such file or directory: '/tmp/data/isd/year=2020/month=1/part-00005-tid-3591589134085533387-1f6ac405-45e1-4d55-80c0-7a4da012effb-2670-1.c000.snappy.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(FileNotFoundError)\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_109573/1720535584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_delayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'df.describe().compute()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# CPU times: user 20.5 s, sys: 4.63 s, total: 25.2 s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/io/io.py\u001b[0m in \u001b[0;36mfrom_delayed\u001b[0;34m(dfs, meta, divisions, prefix, verify_meta)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\u001b[0m in \u001b[0;36mray_dask_get\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0menable_progress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mpb_actor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_dask_on_ray_pb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray_get_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_actor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpb_actor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mray_finish_cbs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mray_finish_cbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\u001b[0m in \u001b[0;36mray_get_unpack\u001b[0;34m(object_refs, progress_bar_actor)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;31m# completes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_object_refs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mcomputed_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(object_refs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprogress_bar_actor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mrender_progress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar_actor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1623\u001b[0m                     \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_worker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_object_store_memory_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayTaskError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError(FileNotFoundError)\u001b[0m: \u001b[36mray::dask:make_meta-04803ab8-eacd-4c1c-8dba-c12bef057b2d\u001b[39m (pid=207, ip=10.0.0.17)\n  At least one of the input arguments for this task could not be computed:\nray.exceptions.RayTaskError: \u001b[36mray::dask:read_parquet-568d98c5-6b4e-4819-b9bf-b4760b82036f\u001b[39m (pid=207, ip=10.0.0.17)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\", line 350, in dask_task_wrapper\n  File \"/azureml-envs/azureml_8afa3af27adc7f1a69c133d28398582a/lib/python3.8/site-packages/pandas/io/parquet.py\", line 495, in read_parquet\n    return impl.read(\n  File \"/azureml-envs/azureml_8afa3af27adc7f1a69c133d28398582a/lib/python3.8/site-packages/pandas/io/parquet.py\", line 232, in read\n    path_or_handle, handles, kwargs[\"filesystem\"] = _get_path_or_handle(\n  File \"/azureml-envs/azureml_8afa3af27adc7f1a69c133d28398582a/lib/python3.8/site-packages/pandas/io/parquet.py\", line 101, in _get_path_or_handle\n    handles = get_handle(\n  File \"/azureml-envs/azureml_8afa3af27adc7f1a69c133d28398582a/lib/python3.8/site-packages/pandas/io/common.py\", line 711, in get_handle\n    handle = open(handle, ioargs.mode)\nFileNotFoundError: [Errno 2] No such file or directory: '/tmp/data/isd/year=2020/month=1/part-00005-tid-3591589134085533387-1f6ac405-45e1-4d55-80c0-7a4da012effb-2670-1.c000.snappy.parquet'"
     ]
    }
   ],
   "source": [
    "dfs = [dask.delayed(pd.read_parquet)(file) for file in files]\n",
    "dfs[-5:]\n",
    "df = dd.from_delayed(dfs)\n",
    "%time df.describe().compute()\n",
    "# CPU times: user 20.5 s, sys: 4.63 s, total: 25.2 s\n",
    "# Wall time: 2min 38s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mdask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\u001b[0m in \u001b[0;36mray_dask_get\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0menable_progress_bar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mpb_actor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_dask_on_ray_pb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray_get_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_actor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpb_actor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mray_finish_cbs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mray_finish_cbs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\u001b[0m in \u001b[0;36mray_get_unpack\u001b[0;34m(object_refs, progress_bar_actor)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;31m# completes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpack_object_refs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mcomputed_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/util/dask/scheduler.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(object_refs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprogress_bar_actor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mrender_progress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar_actor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1617\u001b[0m         \u001b[0;31m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m         values, debugger_breakpoint = worker.get_objects(\n\u001b[0m\u001b[1;32m   1619\u001b[0m             object_refs, timeout=timeout)\n\u001b[1;32m   1620\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36mget_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0mtimeout_ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         data_metadata_pairs = self.core_worker.get_objects(\n\u001b[0m\u001b[1;32m    345\u001b[0m             object_refs, self.current_task_id, timeout_ms)\n\u001b[1;32m    346\u001b[0m         \u001b[0mdebugger_breakpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpython/ray/_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time places = df.groupby(df.index)[['longitude', 'latitude', 'year']].mean().compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2021-12-05 05:35:59,006 WARN Utils [Thread-1]: Your hostname, nc6v0 resolves to a loopback address: 127.0.0.1; using 10.0.0.11 instead (on interface eth0)\n",
      "2021-12-05 05:35:59,010 WARN Utils [Thread-1]: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-05 05:35:59,214 WARN NativeCodeLoader [Thread-1]: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2021-12-05 05:35:59,294 INFO SecurityManager [Thread-1]: Changing view acls to: azureuser\n",
      "2021-12-05 05:35:59,295 INFO SecurityManager [Thread-1]: Changing modify acls to: azureuser\n",
      "2021-12-05 05:35:59,295 INFO SecurityManager [Thread-1]: Changing view acls groups to: \n",
      "2021-12-05 05:35:59,296 INFO SecurityManager [Thread-1]: Changing modify acls groups to: \n",
      "2021-12-05 05:35:59,296 INFO SecurityManager [Thread-1]: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(azureuser); groups with view permissions: Set(); users  with modify permissions: Set(azureuser); groups with modify permissions: Set()\n",
      "2021-12-05 05:35:59,569 INFO Utils [Thread-1]: Successfully started service 'RAY_RPC_ENV' on port 39967.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/jars/ray_dist.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-05 05:36:02,814 INFO RayAppMaster$RayAppMasterEndpoint [dispatcher-event-loop-1]: Registering app example\n",
      "2021-12-05 05:36:02,817 INFO RayAppMaster$RayAppMasterEndpoint [dispatcher-event-loop-1]: Registered app example with ID app-20211205053602-0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m [2021-12-05 05:36:02,985 C 157 157] worker_pool.cc:1236:  Check failed: state != states_by_lang_.end() Required Language isn't supported: JAVA\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     ray::raylet::WorkerPool::GetStateForLanguage()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     ray::raylet::WorkerPool::PopWorker()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     ray::raylet::ClusterTaskManager::DispatchScheduledTasksToWorkers()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     ray::raylet::ClusterTaskManager::QueueAndScheduleTask()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     ray::raylet::NodeManager::HandleRequestWorkerLease()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     main\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m     __libc_start_main\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.20)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    4\n",
      "2    9\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.                         (0 + 0) / 1]\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "RuntimeError: reentrant call inside <_io.BufferedReader name=133>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/context.py\", line 292, in signal_handler\n",
      "    self.cancelAllJobs()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/context.py\", line 1195, in cancelAllJobs\n",
      "    self._jsc.sc().cancelAllJobs()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1309, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/sql/utils.py\", line 111, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/py4j/protocol.py\", line 334, in get_return_value\n",
      "    raise Py4JError(\n",
      "py4j.protocol.Py4JError: An error occurred while calling o28.sc\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/py4j/clientserver.py\", line 503, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o107.showString",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29073/4231775335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Execute function as a Spark vectorized UDF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;31m# +-------------------+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# |multiply_func(x, x)|\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1310\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    332\u001b[0m                     format(target_id, \".\", name, value))\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             raise Py4JError(\n\u001b[0m\u001b[1;32m    335\u001b[0m                 \u001b[0;34m\"An error occurred while calling {0}{1}{2}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 format(target_id, \".\", name))\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o107.showString"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 05:36:32,662\tWARNING worker.py:1245 -- The node with node id: 2e302da25deb2e6ec2b45913710812b94636e3f2604b13c93f623695 and ip: 10.0.0.20 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a raylet crashes unexpectedly or has lagging heartbeats.\n",
      "2021-12-05 06:15:31,724\tWARNING worker.py:1245 -- The node with node id: f9377cbb25de1a81861f67bbdd0192e75c2f04901bb5eaff3a643221 and ip: 10.0.0.29 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a raylet crashes unexpectedly or has lagging heartbeats.\n",
      "2021-12-05 06:15:31,724\tWARNING worker.py:1245 -- The node with node id: e4222486f8a5eaa3dbb7aa75ba096e6899736afb704bfb9d38b01330 and ip: 10.0.0.27 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a raylet crashes unexpectedly or has lagging heartbeats.\n",
      "2021-12-05 06:15:31,725\tWARNING worker.py:1245 -- The node with node id: bb3857d6667b5c1b549a493aa67decaea73cab2954ab8273a861e96c and ip: 10.0.0.17 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a raylet crashes unexpectedly or has lagging heartbeats.\n",
      "[Stage 0:>                                                          (0 + 0) / 1]\r"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import raydp\n",
    "import os\n",
    "# ray.shutdown()\n",
    "# ray.init()\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/anaconda/envs/azureml_py38/bin/python3\"\n",
    "\n",
    "# ray.init(address ='ray://10.0.0.11:6379')\n",
    "spark = raydp.init_spark(\n",
    "  app_name = \"example\",\n",
    "  num_executors = 2,\n",
    "  executor_cores = 1,\n",
    "  executor_memory = \"1gb\"\n",
    ")\n",
    "\n",
    "# data =spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://ojsales-simulatedcontainer@azureopendatastorage.blob.core.windows.net/oj_sales_data/Store10*.csv\")\n",
    "\n",
    "\n",
    "# # normal data processesing with Spark\n",
    "# df = spark.createDataFrame([('look',), ('spark',), ('tutorial',), ('spark',), ('look', ), ('python', )], ['word'])\n",
    "# df.show()\n",
    "# word_count = df.groupBy('word').count()\n",
    "# word_count.show()\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "# Declare the function and create the UDF\n",
    "def multiply_func(a: pd.Series, b: pd.Series) -> pd.Series:\n",
    "    return a * b\n",
    "\n",
    "multiply = pandas_udf(multiply_func, returnType=LongType())\n",
    "\n",
    "# The function for a pandas_udf should be able to execute with local Pandas data\n",
    "x = pd.Series([1, 2, 3])\n",
    "print(multiply_func(x, x))\n",
    "# 0    1\n",
    "# 1    4\n",
    "# 2    9\n",
    "# dtype: int64\n",
    "\n",
    "# Create a Spark DataFrame, 'spark' is an existing SparkSession\n",
    "df = spark.createDataFrame(pd.DataFrame(x, columns=[\"x\"]))\n",
    "\n",
    "# Execute function as a Spark vectorized UDF\n",
    "df.select(multiply(col(\"x\"), col(\"x\"))).show()\n",
    "# +-------------------+\n",
    "# |multiply_func(x, x)|\n",
    "# +-------------------+\n",
    "# |                  1|\n",
    "# |                  4|\n",
    "# |                  9|\n",
    "# +-------------------+\n",
    "\n",
    "\n",
    "# stop the spark cluster\n",
    "raydp.stop_spark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
