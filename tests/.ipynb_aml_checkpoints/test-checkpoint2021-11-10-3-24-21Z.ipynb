{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "# from azureml.widgets import RunDetails\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "# from ray_on_azureml.ray_on_aml import getRay\n",
        "import sys\n",
        "sys.path.append(\"../\") # go to parent dir\n",
        "import importlib\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1639106529136
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.ray_on_azureml.ray_on_aml import Ray_On_AML\n",
        "ws = Workspace.from_config()\n",
        "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"worker-cpu-v3\")\n",
        "_, ray = ray_on_aml.getRay()\n",
        "ray.cluster_resources()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "azureml_py38\nFound existing cluster, use it.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-10 03:22:40,057\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 10.0.0.5:6379\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "{'CPU': 48.0,\n 'node:10.0.0.5': 1.0,\n 'memory': 58287493940.0,\n 'object_store_memory': 29143746969.0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1639106560046
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ray_on_aml.shutdown()\r\n",
        "# import ray\r\n",
        "# ray.shutdown()\r\n",
        "# ray.init()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1639106536147
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import ray\n",
        "# ray.init()\n",
        "from ray.util.dask import ray_dask_get\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# ray.shutdown()\n",
        "# client = ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True  )\n",
        "# with client:\n",
        "# Start Ray.\n",
        "# Tip: If connecting to an existing cluster, use ray.init(address=\"auto\").\n",
        "# ray.init(address ='ray://10.0.0.14:10001',ignore_reinit_error=True)\n",
        "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
        "\n",
        "# The Dask scheduler submits the underlying task graph to Ray.\n",
        "d_arr.mean().compute(scheduler=ray_dask_get)\n",
        "\n",
        "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
        "# specify it on each compute call.\n",
        "dask.config.set(scheduler=ray_dask_get)\n",
        "\n",
        "df = dd.from_pandas(\n",
        "    pd.DataFrame(\n",
        "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
        "    npartitions=2)\n",
        "df.groupby([\"age\"]).mean().compute()\n",
        "\n",
        "# ray.shutdown()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "       grade\nage         \n57    3707.0\n106   4563.0\n138   6669.0\n171   6702.0\n175   1546.0\n...      ...\n9818  6851.0\n9847  3783.0\n9875  9748.0\n9889  6494.0\n9946  1265.0\n\n[971 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>grade</th>\n    </tr>\n    <tr>\n      <th>age</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>57</th>\n      <td>3707.0</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>4563.0</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>6669.0</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>6702.0</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>1546.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9818</th>\n      <td>6851.0</td>\n    </tr>\n    <tr>\n      <th>9847</th>\n      <td>3783.0</td>\n    </tr>\n    <tr>\n      <th>9875</th>\n      <td>9748.0</td>\n    </tr>\n    <tr>\n      <th>9889</th>\n      <td>6494.0</td>\n    </tr>\n    <tr>\n      <th>9946</th>\n      <td>1265.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>971 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1639105974201
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ray[default]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting ray[default]\n  Downloading ray-1.9.0-cp38-cp38-manylinux2014_x86_64.whl (57.4 MB)\n\u001b[K     |████████████████████████████████| 57.4 MB 128 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: pyyaml in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (5.4.1)\nRequirement already satisfied: grpcio>=1.28.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (1.32.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (1.0.2)\nRequirement already satisfied: numpy>=1.16; python_version < \"3.9\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (1.18.5)\nRequirement already satisfied: jsonschema in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (3.2.0)\nCollecting redis>=3.5.0\n  Downloading redis-4.0.2-py3-none-any.whl (119 kB)\n\u001b[K     |████████████████████████████████| 119 kB 78.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: click>=7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (8.0.1)\nRequirement already satisfied: attrs in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (21.2.0)\nRequirement already satisfied: filelock in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (3.0.12)\nRequirement already satisfied: protobuf>=3.15.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (3.17.3)\nCollecting aiohttp-cors; extra == \"default\"\n  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\nCollecting gpustat>=1.0.0b1; extra == \"default\"\n  Using cached gpustat-1.0.0b1.tar.gz (82 kB)\nCollecting frozenlist; extra == \"default\"\n  Downloading frozenlist-1.2.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (210 kB)\n\u001b[K     |████████████████████████████████| 210 kB 97.0 MB/s eta 0:00:01\n\u001b[?25hCollecting aiosignal; extra == \"default\"\n  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\nCollecting aioredis<2; extra == \"default\"\n  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n\u001b[K     |████████████████████████████████| 65 kB 4.4 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: aiohttp>=3.7; extra == \"default\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (3.7.4.post0)\nRequirement already satisfied: opencensus; extra == \"default\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (0.7.13)\nRequirement already satisfied: prometheus-client>=0.7.1; extra == \"default\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (0.11.0)\nCollecting py-spy>=0.2.0; extra == \"default\"\n  Downloading py_spy-0.3.11-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n\u001b[K     |████████████████████████████████| 3.0 MB 94.0 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: smart-open; extra == \"default\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (1.9.0)\nRequirement already satisfied: requests; extra == \"default\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ray[default]) (2.26.0)\nCollecting colorful; extra == \"default\"\n  Using cached colorful-0.5.4-py2.py3-none-any.whl (201 kB)\nRequirement already satisfied: six>=1.5.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from grpcio>=1.28.1->ray[default]) (1.15.0)\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema->ray[default]) (50.3.0.post20201006)\nRequirement already satisfied: pyrsistent>=0.14.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jsonschema->ray[default]) (0.18.0)\nRequirement already satisfied: deprecated in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from redis>=3.5.0->ray[default]) (1.2.12)\nRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gpustat>=1.0.0b1; extra == \"default\"->ray[default]) (7.352.0)\nRequirement already satisfied: psutil in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gpustat>=1.0.0b1; extra == \"default\"->ray[default]) (5.8.0)\nCollecting blessed>=1.17.1\n  Using cached blessed-1.19.0-py2.py3-none-any.whl (57 kB)\nCollecting hiredis\n  Downloading hiredis-2.0.0-cp38-cp38-manylinux2010_x86_64.whl (85 kB)\n\u001b[K     |████████████████████████████████| 85 kB 1.1 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: async-timeout in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aioredis<2; extra == \"default\"->ray[default]) (3.0.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp>=3.7; extra == \"default\"->ray[default]) (1.6.3)\nRequirement already satisfied: typing-extensions>=3.6.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp>=3.7; extra == \"default\"->ray[default]) (3.7.4.3)\nRequirement already satisfied: chardet<5.0,>=2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp>=3.7; extra == \"default\"->ray[default]) (4.0.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp>=3.7; extra == \"default\"->ray[default]) (5.1.0)\nRequirement already satisfied: opencensus-context==0.1.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus; extra == \"default\"->ray[default]) (0.1.2)\nRequirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opencensus; extra == \"default\"->ray[default]) (1.31.1)\nRequirement already satisfied: boto>=2.32 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from smart-open; extra == \"default\"->ray[default]) (2.49.0)\nRequirement already satisfied: boto3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from smart-open; extra == \"default\"->ray[default]) (1.15.18)\nRequirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests; extra == \"default\"->ray[default]) (3.2)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests; extra == \"default\"->ray[default]) (2021.5.30)\nRequirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests; extra == \"default\"->ray[default]) (2.0.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests; extra == \"default\"->ray[default]) (1.25.11)\nRequirement already satisfied: wrapt<2,>=1.10 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from deprecated->redis>=3.5.0->ray[default]) (1.12.1)\nRequirement already satisfied: wcwidth>=0.1.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from blessed>=1.17.1->gpustat>=1.0.0b1; extra == \"default\"->ray[default]) (0.2.5)\nRequirement already satisfied: google-auth<2.0dev,>=1.25.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus; extra == \"default\"->ray[default]) (1.34.0)\nRequirement already satisfied: packaging>=14.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus; extra == \"default\"->ray[default]) (21.0)\nRequirement already satisfied: pytz in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus; extra == \"default\"->ray[default]) (2021.1)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-api-core<2.0.0,>=1.0.0->opencensus; extra == \"default\"->ray[default]) (1.53.0)\nRequirement already satisfied: botocore<1.19.0,>=1.18.18 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from boto3->smart-open; extra == \"default\"->ray[default]) (1.18.18)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from boto3->smart-open; extra == \"default\"->ray[default]) (0.10.0)\nRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from boto3->smart-open; extra == \"default\"->ray[default]) (0.3.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2.0.0,>=1.0.0->opencensus; extra == \"default\"->ray[default]) (4.2.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2.0.0,>=1.0.0->opencensus; extra == \"default\"->ray[default]) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2.0.0,>=1.0.0->opencensus; extra == \"default\"->ray[default]) (4.7.2)\nRequirement already satisfied: pyparsing>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus; extra == \"default\"->ray[default]) (2.4.7)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from botocore<1.19.0,>=1.18.18->boto3->smart-open; extra == \"default\"->ray[default]) (2.8.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<2.0.0,>=1.0.0->opencensus; extra == \"default\"->ray[default]) (0.4.8)\nBuilding wheels for collected packages: gpustat\n  Building wheel for gpustat (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25h  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=5a6f7915aaa4c0af77135782ae75074a9cf50d9c2191d2d307659814ec7dda4c\n  Stored in directory: /home/azureuser/.cache/pip/wheels/80/87/f2/ed4a55705071f3671434e31c704883425b71bbc90b0c0cfa1e\nSuccessfully built gpustat\nInstalling collected packages: redis, aiohttp-cors, blessed, gpustat, frozenlist, aiosignal, hiredis, aioredis, py-spy, colorful, ray\nSuccessfully installed aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 blessed-1.19.0 colorful-0.5.4 frozenlist-1.2.0 gpustat-1.0.0b1 hiredis-2.0.0 py-spy-0.3.11 ray-1.9.0 redis-4.0.2\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639105270459
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install fsspec==2021.10.1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: fsspec==2021.10.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (2021.10.1)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639106159084
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow==6.0.1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: pyarrow==6.0.1 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (6.0.1)\r\nRequirement already satisfied: numpy>=1.16.6 in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from pyarrow==6.0.1) (1.18.5)\r\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "\n",
        "storage_options = {'account_name': 'azureopendatastorage'}\n",
        "ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
        "ddf.count()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for -: 'NoneType' and 'int'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-432b255c4f28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'account_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'azureopendatastorage'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mddf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'az://nyctlc/green/puYear=2019/puMonth=*/*.parquet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mddf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, filters, categories, index, storage_options, engine, gather_statistics, split_row_groups, read_from_paths, chunksize, aggregate_files, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mgather_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     read_metadata_result = engine.read_metadata(\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/io/parquet/fastparquet.py\u001b[0m in \u001b[0;36mread_metadata\u001b[0;34m(cls, fs, paths, categories, index, gather_statistics, filters, split_row_groups, chunksize, aggregate_files, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;31m# then each part will correspond to a file.  Otherwise, each part will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;31m# correspond to a row group (populated below).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         parts, pf, gather_statistics, base_path = _determine_pf_parts(\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather_statistics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         )\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/io/parquet/fastparquet.py\u001b[0m in \u001b[0;36m_determine_pf_parts\u001b[0;34m(fs, paths, gather_statistics, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0mpaths_use\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_metadata\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             pf = ParquetFile(\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0mpaths_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             )\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fastparquet/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, verify, open_with, root, sep, fs, pandas_nulls)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__self__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             basepath, fmd = metadata_from_many(fn, verify_schema=verify,\n\u001b[0m\u001b[1;32m    106\u001b[0m                                                \u001b[0mopen_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                                                fs=fs)\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fastparquet/util.py\u001b[0m in \u001b[0;36mmetadata_from_many\u001b[0;34m(file_list, verify_schema, open_with, root, fs)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;31m# permits concurrent fetch of footers; needs fsspec >= 2021.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpf0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mpieces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 sizes = {path: int.from_bytes(piece[-8:-4], \"little\") + 8 for\n\u001b[1;32m    160\u001b[0m                          path, piece in pieces.items()}\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/adlfs/spec.py\u001b[0m in \u001b[0;36mcat\u001b[0;34m(self, path, recursive, on_error, **kwargs)\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m                     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mon_error\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFSTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mcoro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/adlfs/spec.py\u001b[0m in \u001b[0;36m_cat_file\u001b[0;34m(self, path, start, end, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m         ) as bc:\n\u001b[1;32m   1354\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_blob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mResourceNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/core/tracing/decorator_async.py\u001b[0m in \u001b[0;36mwrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mspan_impl_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspan_impl_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/storage/blob/aio/_blob_client_async.py\u001b[0m in \u001b[0;36mdownload_blob\u001b[0;34m(self, offset, length, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m             **kwargs)\n\u001b[1;32m    463\u001b[0m         \u001b[0mdownloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStorageStreamDownloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mawait\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/storage/blob/aio/_download_async.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/storage/blob/aio/_download_async.py\u001b[0m in \u001b[0;36m_initial_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_range\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_range\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_range\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'int'"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1639104458150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask\n",
        "dask.__version__\n",
        "# '2021.09.0'\n",
        "# '2.30.0'\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "'2021.07.2'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1639106144831
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyarrow\r\n",
        "pyarrow.__version__"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "'6.0.1'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639106267724
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade cchardet, pip install -U pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting cchardet\n  Downloading cchardet-2.1.7-cp38-cp38-manylinux2010_x86_64.whl (265 kB)\n\u001b[K     |████████████████████████████████| 265 kB 11.6 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: cchardet\nSuccessfully installed cchardet-2.1.7\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U pyarrow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting pyarrow\n  Downloading pyarrow-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n\u001b[K     |████████████████████████████████| 25.6 MB 11.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.16.6 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pyarrow) (1.18.5)\n\u001b[31mERROR: datasets 1.8.0 has requirement pyarrow<4.0.0,>=1.0.0, but you'll have pyarrow 6.0.1 which is incompatible.\u001b[0m\n\u001b[31mERROR: datasets 1.8.0 has requirement tqdm<4.50.0,>=4.27, but you'll have tqdm 4.61.2 which is incompatible.\u001b[0m\n\u001b[31mERROR: azureml-dataset-runtime 1.33.0 has requirement pyarrow<4.0.0,>=0.17.0, but you'll have pyarrow 6.0.1 which is incompatible.\u001b[0m\nInstalling collected packages: pyarrow\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 5.0.0\n    Uninstalling pyarrow-5.0.0:\n      Successfully uninstalled pyarrow-5.0.0\nSuccessfully installed pyarrow-6.0.1\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1639106233150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyarrow==4.0.1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting pyarrow==4.0.1\n  Using cached pyarrow-4.0.1-cp38-cp38-manylinux2014_x86_64.whl (21.9 MB)\nRequirement already satisfied: numpy>=1.16.6 in /anaconda/envs/azureml_py38_pytorch/lib/python3.8/site-packages (from pyarrow==4.0.1) (1.20.3)\nInstalling collected packages: pyarrow\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 6.0.1\n    Uninstalling pyarrow-6.0.1:\n      Successfully uninstalled pyarrow-6.0.1\n\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\nazureml-dataset-runtime 1.34.0 requires pyarrow<4.0.0,>=0.17.0, but you'll have pyarrow 4.0.1 which is incompatible.\u001b[0m\nSuccessfully installed pyarrow-4.0.1\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "# import ray\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # In this example, we don't change the model architecture\n",
        "        # due to simplicity.\n",
        "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
        "        self.fc = nn.Linear(192, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
        "        x = x.view(-1, 192)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "# Change these values if you want the training to run quicker or slower.\n",
        "EPOCH_SIZE = 512\n",
        "TEST_SIZE = 256\n",
        "\n",
        "def train(model, optimizer, train_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # We set this just for the example to run quickly.\n",
        "        if batch_idx * len(data) > EPOCH_SIZE:\n",
        "            return\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test(model, data_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            # We set this just for the example to run quickly.\n",
        "            if batch_idx * len(data) > TEST_SIZE:\n",
        "                break\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    return correct / total\n",
        "def train_mnist(config):\n",
        "    # Data Setup\n",
        "    mnist_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
        "        batch_size=64,\n",
        "        shuffle=True)\n",
        "    test_loader = DataLoader(\n",
        "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
        "        batch_size=64,\n",
        "        shuffle=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ConvNet()\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
        "    for i in range(10):\n",
        "        train(model, optimizer, train_loader)\n",
        "        acc = test(model, test_loader)\n",
        "\n",
        "        # Send the current training result back to Tune\n",
        "        tune.report(mean_accuracy=acc)\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            # This saves the model to the trial directory\n",
        "            torch.save(model.state_dict(), \"./model.pth\")\n",
        "search_space = {\n",
        "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
        "    \"momentum\": tune.uniform(0.01, 0.09)\n",
        "}\n",
        "\n",
        "# Uncomment this to enable distributed execution\n",
        "# ray.shutdown()\n",
        "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
        "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
        "# Download the dataset first\n",
        "datasets.MNIST(\"~/data\", train=True, download=True)\n",
        "\n",
        "analysis = tune.run(train_mnist, config=search_space)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-10 03:24:14,267\tWARNING function_runner.py:561 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n2021-12-10 03:24:14,281\tINFO logger.py:605 -- pip install \"ray[tune]\" to see TensorBoard files.\n2021-12-10 03:24:14,281\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "== Status ==<br>Current time: 2021-12-10 03:24:14 (running for 00:00:00.11)<br>Memory usage on this node: 7.8/94.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/48 CPUs, 0/0 GPUs, 0.0/54.28 GiB heap, 0.0/27.14 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-10_03-24-14<br>Number of trials: 1/1 (1 PENDING)<br><table>\n<thead>\n<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">      lr</th><th style=\"text-align: right;\">  momentum</th></tr>\n</thead>\n<tbody>\n<tr><td>train_mnist_a6475_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.201532</td><td style=\"text-align: right;\"> 0.0589635</td></tr>\n</tbody>\n</table><br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[2m\u001b[36m(ImplicitFunc pid=24467)\u001b[0m /anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n\u001b[2m\u001b[36m(ImplicitFunc pid=24467)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Result for train_mnist_a6475_00000:\n  date: 2021-12-10_03-24-16\n  done: false\n  experiment_id: 611c4581174c40df89b7d6228c601fa2\n  hostname: janguy2\n  iterations_since_restore: 1\n  mean_accuracy: 0.546875\n  node_ip: 10.0.0.5\n  pid: 24467\n  time_since_restore: 1.1576545238494873\n  time_this_iter_s: 1.1576545238494873\n  time_total_s: 1.1576545238494873\n  timestamp: 1639106656\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: a6475_00000\n  \nResult for train_mnist_a6475_00000:\n  date: 2021-12-10_03-24-17\n  done: true\n  experiment_id: 611c4581174c40df89b7d6228c601fa2\n  experiment_tag: 0_lr=0.20153,momentum=0.058964\n  hostname: janguy2\n  iterations_since_restore: 10\n  mean_accuracy: 0.934375\n  node_ip: 10.0.0.5\n  pid: 24467\n  time_since_restore: 2.322474479675293\n  time_this_iter_s: 0.12954235076904297\n  time_total_s: 2.322474479675293\n  timestamp: 1639106657\n  timesteps_since_restore: 0\n  training_iteration: 10\n  trial_id: a6475_00000\n  \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "== Status ==<br>Current time: 2021-12-10 03:24:17 (running for 00:00:03.22)<br>Memory usage on this node: 7.7/94.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/48 CPUs, 0/0 GPUs, 0.0/54.28 GiB heap, 0.0/27.14 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-10_03-24-14<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name             </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">      lr</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n</thead>\n<tbody>\n<tr><td>train_mnist_a6475_00000</td><td>TERMINATED</td><td>10.0.0.5:24467</td><td style=\"text-align: right;\">0.201532</td><td style=\"text-align: right;\"> 0.0589635</td><td style=\"text-align: right;\">0.934375</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.32247</td></tr>\n</tbody>\n</table><br><br>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-10 03:24:17,624\tINFO tune.py:626 -- Total run time: 3.36 seconds (3.22 seconds for the tuning loop).\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1639106657384
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import sklearn.datasets\n",
        " import sklearn.metrics\n",
        " from sklearn.model_selection import train_test_split\n",
        " import xgboost as xgb\n",
        "\n",
        " from ray import tune\n",
        "\n",
        "\n",
        " def train_breast_cancer(config):\n",
        "     # Load dataset\n",
        "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "     # Split into train and test set\n",
        "     train_x, test_x, train_y, test_y = train_test_split(\n",
        "         data, labels, test_size=0.25)\n",
        "     # Build input matrices for XGBoost\n",
        "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
        "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
        "     # Train the classifier\n",
        "     results = {}\n",
        "     xgb.train(\n",
        "         config,\n",
        "         train_set,\n",
        "         evals=[(test_set, \"eval\")],\n",
        "         evals_result=results,\n",
        "         verbose_eval=False)\n",
        "     # Return prediction accuracy\n",
        "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
        "     tune.report(mean_accuracy=accuracy, done=True)\n",
        "\n",
        "\n",
        " config = {\n",
        "     \"objective\": \"binary:logistic\",\n",
        "     \"eval_metric\": [\"logloss\", \"error\"],\n",
        "     \"max_depth\": tune.randint(1, 9),\n",
        "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
        "     \"subsample\": tune.uniform(0.5, 1.0),\n",
        "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
        " }\n",
        " analysis = tune.run(\n",
        "     train_breast_cancer,\n",
        "     resources_per_trial={\"cpu\": 1},\n",
        "     config=config,\n",
        "     num_samples=10)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-10 03:24:19,734\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "== Status ==<br>Current time: 2021-12-10 03:24:20 (running for 00:00:01.00)<br>Memory usage on this node: 7.5/94.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/48 CPUs, 0/0 GPUs, 0.0/54.28 GiB heap, 0.0/27.14 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-10_03-24-19<br>Number of trials: 10/10 (9 PENDING, 1 RUNNING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_a9876_00000</td><td>RUNNING </td><td>10.0.0.5:24461</td><td style=\"text-align: right;\">0.00378889 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.802378</td></tr>\n<tr><td>train_breast_cancer_a9876_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000491363</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.888983</td></tr>\n<tr><td>train_breast_cancer_a9876_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00230636 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.908011</td></tr>\n<tr><td>train_breast_cancer_a9876_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00456041 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.909479</td></tr>\n<tr><td>train_breast_cancer_a9876_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000478117</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.735239</td></tr>\n<tr><td>train_breast_cancer_a9876_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00181548 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.897581</td></tr>\n<tr><td>train_breast_cancer_a9876_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.000361135</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.543242</td></tr>\n<tr><td>train_breast_cancer_a9876_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00273367 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.975624</td></tr>\n<tr><td>train_breast_cancer_a9876_00008</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.0416131  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.95536 </td></tr>\n<tr><td>train_breast_cancer_a9876_00009</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">0.00919299 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.797331</td></tr>\n</tbody>\n</table><br><br>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1639104485871
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#dask\n",
        "\n",
        "# import ray\n",
        "from ray.util.dask import ray_dask_get\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dask\n",
        "import glob\n",
        "import joblib\n",
        "\n",
        "import pandas as pd\n",
        "import dask.dataframe as dd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from azureml.core import Workspace, Dataset, Model\n",
        "data_url = 'https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather'\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1639106561627
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from adlfs import AzureBlobFileSystem,AzureDatalakeFileSystem\n",
        "sas_token='sp=rle&st=2021-11-27T19:26:49Z&se=2022-04-22T02:26:49Z&spr=https&sv=2020-08-04&sr=c&sig=gpYJ3LofkkjkeWkrMDTY1Ge6NsOCghbUR9CQs65HCvU%3D'\n",
        "account_key='ak7nSgU/iRc5XCvXjaM2UwX18ybS9WO1BsE4Vm42XLmiZvBm1kCyZQD3USeCCOiwusWkDaq0jcRF1JpPHiAMhw=='\n",
        "account_name=\"adlsgen7\"\n",
        "abfs = AzureBlobFileSystem(account_name=\"adlsgen7\",account_key=account_key,  container_name=\"mltraining\")\n",
        "abfs2 = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1639106561845
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "\n",
        "storage_options={'account_name': account_name, 'account_key': account_key}\n",
        "\n",
        "ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year2008', storage_options=storage_options)\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for -: 'NoneType' and 'int'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7f8d82d8c4a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'account_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccount_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'account_key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maccount_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mddf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'az://mltraining/ISDWeatherDelta/year2008'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/io/parquet/core.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, columns, filters, categories, index, storage_options, engine, gather_statistics, split_row_groups, read_from_paths, chunksize, aggregate_files, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mgather_statistics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     read_metadata_result = engine.read_metadata(\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/io/parquet/fastparquet.py\u001b[0m in \u001b[0;36mread_metadata\u001b[0;34m(cls, fs, paths, categories, index, gather_statistics, filters, split_row_groups, chunksize, aggregate_files, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;31m# then each part will correspond to a file.  Otherwise, each part will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;31m# correspond to a row group (populated below).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m         parts, pf, gather_statistics, base_path = _determine_pf_parts(\n\u001b[0m\u001b[1;32m    734\u001b[0m             \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgather_statistics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         )\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/dask/dataframe/io/parquet/fastparquet.py\u001b[0m in \u001b[0;36m_determine_pf_parts\u001b[0;34m(fs, paths, gather_statistics, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mgather_statistics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;31m# Scan every file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mpf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParquetFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;31m# Use _common_metadata file if it is available.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fastparquet/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, verify, open_with, root, sep, fs, pandas_nulls)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__self__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             basepath, fmd = metadata_from_many(fn, verify_schema=verify,\n\u001b[0m\u001b[1;32m    106\u001b[0m                                                \u001b[0mopen_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                                                fs=fs)\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fastparquet/util.py\u001b[0m in \u001b[0;36mmetadata_from_many\u001b[0;34m(file_list, verify_schema, open_with, root, fs)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# activate new code path here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mpf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParquetFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpf0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_scheme\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'empty'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'simple'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0;31m# set of directories, revert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fastparquet/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, verify, open_with, root, sep, fs, pandas_nulls)\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No files in dir\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     basepath, fmd = metadata_from_many(allfiles, verify_schema=verify,\n\u001b[0m\u001b[1;32m    150\u001b[0m                                                        \u001b[0mopen_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                                                        fs=fs)\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fastparquet/util.py\u001b[0m in \u001b[0;36mmetadata_from_many\u001b[0;34m(file_list, verify_schema, open_with, root, fs)\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;31m# permits concurrent fetch of footers; needs fsspec >= 2021.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpf0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mpieces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 sizes = {path: int.from_bytes(piece[-8:-4], \"little\") + 8 for\n\u001b[1;32m    160\u001b[0m                          path, piece in pieces.items()}\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/adlfs/spec.py\u001b[0m in \u001b[0;36mcat\u001b[0;34m(self, path, recursive, on_error, **kwargs)\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ls_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFSTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/fsspec/asyn.py\u001b[0m in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mcoro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoro\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/adlfs/spec.py\u001b[0m in \u001b[0;36m_cat_file\u001b[0;34m(self, path, start, end, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_isdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1355\u001b[0;31m         \u001b[0;34m\"\"\"Is this entry directory-like?\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdircache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdircache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/core/tracing/decorator_async.py\u001b[0m in \u001b[0;36mwrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mspan_impl_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracing_implementation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspan_impl_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/storage/blob/aio/_blob_client_async.py\u001b[0m in \u001b[0;36mdownload_blob\u001b[0;34m(self, offset, length, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m             **kwargs)\n\u001b[1;32m    463\u001b[0m         \u001b[0mdownloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStorageStreamDownloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mawait\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/storage/blob/aio/_download_async.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azure/storage/blob/aio/_download_async.py\u001b[0m in \u001b[0;36m_initial_request\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_end_range\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_range\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_range\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'int'"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1639098137329
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade adlfs"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting adlfs\n  Using cached adlfs-2021.10.0.tar.gz (38 kB)\nRequirement already satisfied, skipping upgrade: aiohttp in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from adlfs) (3.7.4.post0)\nRequirement already satisfied, skipping upgrade: azure-core>=1.7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from adlfs) (1.16.0)\nRequirement already satisfied, skipping upgrade: azure-datalake-store<0.1,>=0.0.46 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from adlfs) (0.0.52)\nRequirement already satisfied, skipping upgrade: azure-identity in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from adlfs) (1.4.1)\nRequirement already satisfied, skipping upgrade: azure-storage-blob>=12.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from adlfs) (12.8.1)\nRequirement already satisfied, skipping upgrade: fsspec>=2021.6.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from adlfs) (2021.10.1)\nRequirement already satisfied, skipping upgrade: attrs>=17.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->adlfs) (21.2.0)\nRequirement already satisfied, skipping upgrade: typing-extensions>=3.6.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->adlfs) (3.7.4.3)\nRequirement already satisfied, skipping upgrade: multidict<7.0,>=4.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->adlfs) (5.1.0)\nRequirement already satisfied, skipping upgrade: yarl<2.0,>=1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->adlfs) (1.6.3)\nRequirement already satisfied, skipping upgrade: async-timeout<4.0,>=3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->adlfs) (3.0.1)\nRequirement already satisfied, skipping upgrade: chardet<5.0,>=2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from aiohttp->adlfs) (4.0.0)\nRequirement already satisfied, skipping upgrade: requests>=2.18.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core>=1.7.0->adlfs) (2.26.0)\nRequirement already satisfied, skipping upgrade: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core>=1.7.0->adlfs) (1.15.0)\nRequirement already satisfied, skipping upgrade: adal>=0.4.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-datalake-store<0.1,>=0.0.46->adlfs) (1.2.7)\nRequirement already satisfied, skipping upgrade: cffi in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-datalake-store<0.1,>=0.0.46->adlfs) (1.14.6)\nRequirement already satisfied, skipping upgrade: msal<2.0.0,>=1.3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity->adlfs) (1.13.0)\nRequirement already satisfied, skipping upgrade: msal-extensions~=0.2.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity->adlfs) (0.2.2)\nRequirement already satisfied, skipping upgrade: cryptography>=2.1.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-identity->adlfs) (3.4.7)\nRequirement already satisfied, skipping upgrade: msrest>=0.6.18 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-storage-blob>=12.5.0->adlfs) (0.6.21)\nRequirement already satisfied, skipping upgrade: idna>=2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from yarl<2.0,>=1.0->aiohttp->adlfs) (3.2)\nRequirement already satisfied, skipping upgrade: charset-normalizer~=2.0.0; python_version >= \"3\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core>=1.7.0->adlfs) (2.0.3)\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core>=1.7.0->adlfs) (2021.5.30)\nRequirement already satisfied, skipping upgrade: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.18.4->azure-core>=1.7.0->adlfs) (1.25.11)\nRequirement already satisfied, skipping upgrade: PyJWT<3,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from adal>=0.4.2->azure-datalake-store<0.1,>=0.0.46->adlfs) (2.1.0)\nRequirement already satisfied, skipping upgrade: python-dateutil<3,>=2.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from adal>=0.4.2->azure-datalake-store<0.1,>=0.0.46->adlfs) (2.8.2)\nRequirement already satisfied, skipping upgrade: pycparser in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from cffi->azure-datalake-store<0.1,>=0.0.46->adlfs) (2.20)\nRequirement already satisfied, skipping upgrade: portalocker~=1.0; platform_system != \"Windows\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msal-extensions~=0.2.2->azure-identity->adlfs) (1.7.1)\nRequirement already satisfied, skipping upgrade: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->azure-storage-blob>=12.5.0->adlfs) (1.3.0)\nRequirement already satisfied, skipping upgrade: isodate>=0.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.6.18->azure-storage-blob>=12.5.0->adlfs) (0.6.0)\nRequirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.18->azure-storage-blob>=12.5.0->adlfs) (3.1.1)\nBuilding wheels for collected packages: adlfs\n  Building wheel for adlfs (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25h  Created wheel for adlfs: filename=adlfs-2021.10.0-py3-none-any.whl size=22091 sha256=1e9a15f30e409f5c37f616a064daf19981e72d2193739a5991f437863e214f48\n  Stored in directory: /home/azureuser/.cache/pip/wheels/1b/39/d0/78f8b16ac5e059f499d871eba0422c1eb7fa51ef749a33361b\nSuccessfully built adlfs\nInstalling collected packages: adlfs\n  Attempting uninstall: adlfs\n    Found existing installation: adlfs 2021.7.1\n    Uninstalling adlfs-2021.7.1:\n      Successfully uninstalled adlfs-2021.7.1\nSuccessfully installed adlfs-2021.10.0\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1639106475690
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://adlsgen7.blob.core.windows.net/mltraining/ISDWeatherDelta/year2008/month/part-00009-21953d01-b5b8-4fa7-8bd2-96b025a24bc3.c000.snappy.parquet\n",
        "# https://adlsgen7.blob.core.windows.net/mltraining/ISDWeatherDelta/year2008/month10/part-00001-1b0e76df-8a22-4221-9b5a-8b7936aa13ea.c000.snappy.parquet\n",
        "data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs2)\n",
        "data2 = ray.data.read_parquet(\"az://mltraining/ISDWeatherDelta/year2008\", filesystem=abfs)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.73it/s]\nMetadata Fetch Progress: 100%|██████████| 8/8 [00:00<00:00, 20.81it/s]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1639106595487
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2.count()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "97581959"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1639106595820
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddf.count().compute()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "usaf                       97581959\nwban                       97581959\ndatetime                   97581959\nlatitude                   97581959\nlongitude                  97581959\nelevation                  97581959\nwindAngle                  79483952\nwindSpeed                  82288222\ntemperature                95119398\nseaLvlPressure             35943606\ncloudCoverage              57138202\npresentWeatherIndicator     9538179\npastWeatherIndicator        4114610\nprecipTime                 19003392\nprecipDepth                19003392\nsnowDepth                    353685\nstationName                97319338\ncountryOrRegion            97267449\np_k                        97581959\nday                        97581959\nversion                    97581959\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1639098172528
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "dask.config.set(scheduler=ray_dask_get)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "<dask.config.set at 0x7fc4810f4c70>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data.count()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "98904376"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "import raydp\n",
        "import os\n",
        "ray.shutdown()\n",
        "ray.init()\n",
        "os.environ[\"PYSPARK_PYTHON\"]=\"/anaconda/envs/azureml_py38/bin/python3\"\n",
        "\n",
        "# ray.init(address ='ray://10.0.0.11:6379')\n",
        "spark = raydp.init_spark(\n",
        "  app_name = \"example\",\n",
        "  num_executors = 2,\n",
        "  executor_cores = 1,\n",
        "  executor_memory = \"1gb\"\n",
        ")\n",
        "\n",
        "# data =spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://ojsales-simulatedcontainer@azureopendatastorage.blob.core.windows.net/oj_sales_data/Store10*.csv\")\n",
        "\n",
        "\n",
        "# # normal data processesing with Spark\n",
        "# df = spark.createDataFrame([('look',), ('spark',), ('tutorial',), ('spark',), ('look', ), ('python', )], ['word'])\n",
        "# df.show()\n",
        "# word_count = df.groupBy('word').count()\n",
        "# word_count.show()\n",
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql.functions import col, pandas_udf\n",
        "from pyspark.sql.types import LongType\n",
        "\n",
        "# Declare the function and create the UDF\n",
        "def multiply_func(a: pd.Series, b: pd.Series) -> pd.Series:\n",
        "    return a * b\n",
        "\n",
        "multiply = pandas_udf(multiply_func, returnType=LongType())\n",
        "\n",
        "# The function for a pandas_udf should be able to execute with local Pandas data\n",
        "x = pd.Series([1, 2, 3])\n",
        "print(multiply_func(x, x))\n",
        "# 0    1\n",
        "# 1    4\n",
        "# 2    9\n",
        "# dtype: int64\n",
        "\n",
        "# Create a Spark DataFrame, 'spark' is an existing SparkSession\n",
        "df = spark.createDataFrame(pd.DataFrame(x, columns=[\"x\"]))\n",
        "\n",
        "# Execute function as a Spark vectorized UDF\n",
        "df.select(multiply(col(\"x\"), col(\"x\"))).show()\n",
        "# +-------------------+\n",
        "# |multiply_func(x, x)|\n",
        "# +-------------------+\n",
        "# |                  1|\n",
        "# |                  4|\n",
        "# |                  9|\n",
        "# +-------------------+\n",
        "\n",
        "\n",
        "# stop the spark cluster\n",
        "raydp.stop_spark()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-06 19:48:42,187\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n2021-12-06 19:48:45,043 WARN Utils [Thread-1]: Your hostname, nc6v0 resolves to a loopback address: 127.0.0.1; using 10.0.0.11 instead (on interface eth0)\n2021-12-06 19:48:45,046 WARN Utils [Thread-1]: Set SPARK_LOCAL_IP if you need to bind to another address\n2021-12-06 19:48:45,240 WARN NativeCodeLoader [Thread-1]: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING: An illegal reflective access operation has occurred\nWARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2021-12-06 19:48:45,321 INFO SecurityManager [Thread-1]: Changing view acls to: azureuser\n2021-12-06 19:48:45,321 INFO SecurityManager [Thread-1]: Changing modify acls to: azureuser\n2021-12-06 19:48:45,322 INFO SecurityManager [Thread-1]: Changing view acls groups to: \n2021-12-06 19:48:45,322 INFO SecurityManager [Thread-1]: Changing modify acls groups to: \n2021-12-06 19:48:45,323 INFO SecurityManager [Thread-1]: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(azureuser); groups with view permissions: Set(); users  with modify permissions: Set(azureuser); groups with modify permissions: Set()\n2021-12-06 19:48:45,591 INFO Utils [Thread-1]: Successfully started service 'RAY_RPC_ENV' on port 44621.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/jars/ray_dist.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "WARNING: An illegal reflective access operation has occurred\nWARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\nWARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\nWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\nWARNING: All illegal access operations will be denied in a future release\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2021-12-06 19:48:48,798 INFO RayAppMaster$RayAppMasterEndpoint [dispatcher-event-loop-1]: Registering app example\n2021-12-06 19:48:48,802 INFO RayAppMaster$RayAppMasterEndpoint [dispatcher-event-loop-1]: Registered app example with ID app-20211206194848-0000\n0    1\n1    4\n2    9\ndtype: int64\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n                                                                                \r"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "+-------------------+\n|multiply_func(x, x)|\n+-------------------+\n|                  1|\n|                  4|\n|                  9|\n+-------------------+\n\n2021-12-06 19:48:59,086 INFO RayAppMaster [Thread-1]: Stopping RayAppMaster\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "raydp.stop_spark()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.1",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}