{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "# from ray_on_azureml.ray_on_aml import getRay\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "import importlib\n",
    "from src.ray_on_azureml.ray_on_aml import Ray_On_AML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"worker-cpu-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_py38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:29:15,626\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:29:29,086\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 10.0.0.11:6379\n",
      "2021-12-06 19:29:29,237\tWARNING worker.py:1219 -- The autoscaler failed with the following error:\n",
      "Terminated with signal 15\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 543, in <module>\n",
      "    monitor.run()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 439, in run\n",
      "    self._run()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 346, in _run\n",
      "    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m [2021-12-06 19:39:10,595 C 139 139] gcs_client.cc:328: Couldn't reconnect to GCS server. The last attempted GCS server address was :0\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     ray::gcs::GcsClient::ReconnectGcsServer()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     std::function<>::operator()()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     ray::rpc::ClientCallImpl<>::OnReplyReceived()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     main\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m     __libc_start_main\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.21)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m [2021-12-06 19:39:10,574 C 138 138] gcs_client.cc:328: Couldn't reconnect to GCS server. The last attempted GCS server address was :0\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     ray::gcs::GcsClient::ReconnectGcsServer()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     std::function<>::operator()()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     ray::rpc::ClientCallImpl<>::OnReplyReceived()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     main\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m     __libc_start_main\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.19)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m [2021-12-06 19:39:10,619 C 142 142] gcs_client.cc:328: Couldn't reconnect to GCS server. The last attempted GCS server address was :0\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     ray::gcs::GcsClient::ReconnectGcsServer()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     std::function<>::operator()()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     ray::rpc::ClientCallImpl<>::OnReplyReceived()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     main\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m     __libc_start_main\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.18)\u001b[0m \n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m [2021-12-06 19:39:10,617 C 135 135] gcs_client.cc:328: Couldn't reconnect to GCS server. The last attempted GCS server address was :0\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m *** StackTrace Information ***\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     ray::SpdLogMessage::Flush()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     ray::RayLog::~RayLog()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     ray::gcs::GcsClient::ReconnectGcsServer()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     std::function<>::operator()()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     ray::rpc::ClientCallImpl<>::OnReplyReceived()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     std::_Function_handler<>::_M_invoke()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     boost::asio::detail::scheduler::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     boost::asio::io_context::run()\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     main\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m     __libc_start_main\n",
      "\u001b[2m\u001b[33m(raylet, ip=10.0.0.17)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Preparing\n",
      "Waiting: Cluster status is in  Queued\n"
     ]
    }
   ],
   "source": [
    "run, ray = ray_on_aml.getRay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 20:04:28,364\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 10.0.0.11:6379\n",
      "2021-12-06 20:04:28,498\tWARNING worker.py:1219 -- The autoscaler failed with the following error:\n",
      "Terminated with signal 15\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 543, in <module>\n",
      "    monitor.run()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 439, in run\n",
      "    self._run()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 346, in _run\n",
      "    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node:10.0.0.11': 1.0,\n",
       " 'CPU': 26.0,\n",
       " 'object_store_memory': 38203898264.0,\n",
       " 'GPU': 1.0,\n",
       " 'accelerator_type:K80': 1.0,\n",
       " 'memory': 83492836968.0,\n",
       " 'node:10.0.0.12': 1.0,\n",
       " 'node:10.0.0.18': 1.0,\n",
       " 'node:10.0.0.19': 1.0,\n",
       " 'node:10.0.0.17': 1.0,\n",
       " 'node:10.0.0.21': 1.0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_on_aml.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4097.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9912</th>\n",
       "      <td>4781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9915</th>\n",
       "      <td>315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9925</th>\n",
       "      <td>5243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>6629.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>7446.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>963 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade\n",
       "age         \n",
       "1       58.0\n",
       "14    1373.0\n",
       "30    5584.0\n",
       "43    6454.0\n",
       "45    4097.5\n",
       "...      ...\n",
       "9912  4781.0\n",
       "9915   315.0\n",
       "9925  5243.0\n",
       "9971  6629.0\n",
       "9994  7446.0\n",
       "\n",
       "[963 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ray\n",
    "# ray.init()\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# ray.shutdown()\n",
    "# client = ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True  )\n",
    "# with client:\n",
    "# Start Ray.\n",
    "# Tip: If connecting to an existing cluster, use ray.init(address=\"auto\").\n",
    "# ray.init(address ='ray://10.0.0.14:10001',ignore_reinit_error=True)\n",
    "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
    "\n",
    "# The Dask scheduler submits the underlying task graph to Ray.\n",
    "d_arr.mean().compute(scheduler=ray_dask_get)\n",
    "\n",
    "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
    "# specify it on each compute call.\n",
    "dask.config.set(scheduler=ray_dask_get)\n",
    "\n",
    "df = dd.from_pandas(\n",
    "    pd.DataFrame(\n",
    "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
    "    npartitions=2)\n",
    "df.groupby([\"age\"]).mean().compute()\n",
    "\n",
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "doLocationId    int64\n",
       "vendorID          ...\n",
       "dtype: int64\n",
       "Dask Name: dataframe-count-agg, 17 tasks"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "storage_options = {'account_name': 'azureopendatastorage'}\n",
    "ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
    "ddf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021.09.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "dask.__version__\n",
    "# '2021.09.0'\n",
    "# '2.30.0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cchardet\n",
      "  Downloading cchardet-2.1.7-cp38-cp38-manylinux2010_x86_64.whl (265 kB)\n",
      "\u001b[K     |████████████████████████████████| 265 kB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: cchardet\n",
      "Successfully installed cchardet-2.1.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade cchardet, pip install -U pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Using cached pyarrow-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.16.6 in /anaconda/envs/azureml_py38_pytorch/lib/python3.8/site-packages (from pyarrow) (1.20.3)\n",
      "Installing collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 3.0.0\n",
      "    Uninstalling pyarrow-3.0.0:\n",
      "      Successfully uninstalled pyarrow-3.0.0\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "azureml-dataset-runtime 1.34.0 requires pyarrow<4.0.0,>=0.17.0, but you'll have pyarrow 6.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed pyarrow-6.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow==4.0.1\n",
      "  Using cached pyarrow-4.0.1-cp38-cp38-manylinux2014_x86_64.whl (21.9 MB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /anaconda/envs/azureml_py38_pytorch/lib/python3.8/site-packages (from pyarrow==4.0.1) (1.20.3)\n",
      "Installing collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 6.0.1\n",
      "    Uninstalling pyarrow-6.0.1:\n",
      "      Successfully uninstalled pyarrow-6.0.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "azureml-dataset-runtime 1.34.0 requires pyarrow<4.0.0,>=0.17.0, but you'll have pyarrow 4.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed pyarrow-4.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow==4.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 19:23:21,876\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
      "2021-12-05 19:23:21,881\tWARNING tune.py:570 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-05 19:23:21 (running for 00:00:00.11)<br>Memory usage on this node: 3.4/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/77.71 GiB heap, 0.0/35.56 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-05_19-23-21<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_cf3ca_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">6.53338e-10</td><td style=\"text-align: right;\">  0.028065</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=18877)\u001b[0m /anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=18877)\u001b[0m   return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_mnist_cf3ca_00000:\n",
      "  date: 2021-12-05_19-23-23\n",
      "  done: false\n",
      "  experiment_id: 9f757a3a0c714628aac18bfc57156d2d\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.1\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 18877\n",
      "  time_since_restore: 0.25525641441345215\n",
      "  time_this_iter_s: 0.25525641441345215\n",
      "  time_total_s: 0.25525641441345215\n",
      "  timestamp: 1638732203\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: cf3ca_00000\n",
      "  \n",
      "Result for train_mnist_cf3ca_00000:\n",
      "  date: 2021-12-05_19-23-25\n",
      "  done: true\n",
      "  experiment_id: 9f757a3a0c714628aac18bfc57156d2d\n",
      "  experiment_tag: 0_lr=6.5334e-10,momentum=0.028065\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 10\n",
      "  mean_accuracy: 0.103125\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 18877\n",
      "  time_since_restore: 2.0997562408447266\n",
      "  time_this_iter_s: 0.20371103286743164\n",
      "  time_total_s: 2.0997562408447266\n",
      "  timestamp: 1638732205\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: cf3ca_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-05 19:23:25 (running for 00:00:03.26)<br>Memory usage on this node: 3.5/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/77.71 GiB heap, 0.0/35.56 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-05_19-23-21<br>Number of trials: 1/1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_cf3ca_00000</td><td>TERMINATED</td><td>10.0.0.11:18877</td><td style=\"text-align: right;\">6.53338e-10</td><td style=\"text-align: right;\">  0.028065</td><td style=\"text-align: right;\">0.103125</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         2.09976</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 19:23:25,249\tINFO tune.py:626 -- Total run time: 3.42 seconds (3.25 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "# import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # In this example, we don't change the model architecture\n",
    "        # due to simplicity.\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "# Change these values if you want the training to run quicker or slower.\n",
    "EPOCH_SIZE = 512\n",
    "TEST_SIZE = 256\n",
    "\n",
    "def train(model, optimizer, train_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # We set this just for the example to run quickly.\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "            return\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # We set this just for the example to run quickly.\n",
    "            if batch_idx * len(data) > TEST_SIZE:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "def train_mnist(config):\n",
    "    # Data Setup\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = ConvNet()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "    for i in range(10):\n",
    "        train(model, optimizer, train_loader)\n",
    "        acc = test(model, test_loader)\n",
    "\n",
    "        # Send the current training result back to Tune\n",
    "        tune.report(mean_accuracy=acc)\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            # This saves the model to the trial directory\n",
    "            torch.save(model.state_dict(), \"./model.pth\")\n",
    "search_space = {\n",
    "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
    "    \"momentum\": tune.uniform(0.01, 0.09)\n",
    "}\n",
    "\n",
    "# Uncomment this to enable distributed execution\n",
    "# ray.shutdown()\n",
    "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
    "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
    "# Download the dataset first\n",
    "datasets.MNIST(\"~/data\", train=True, download=True)\n",
    "\n",
    "analysis = tune.run(train_mnist, config=search_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 19:23:25,481\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
      "2021-12-05 19:23:25,485\tWARNING tune.py:570 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-05 19:23:25 (running for 00:00:00.15)<br>Memory usage on this node: 3.4/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/77.71 GiB heap, 0.0/35.56 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-05_19-23-25<br>Number of trials: 10/10 (10 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_breast_cancer_d1628_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000556531</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.990753</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000364689</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.592571</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000363326</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.560972</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00226183 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.621186</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0429831  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.910877</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00948015 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.698004</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0353399  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.697988</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00260922 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.64144 </td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0699687  </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.596595</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000318741</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.979203</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_breast_cancer_d1628_00001:\n",
      "  date: 2021-12-05_19-23-26\n",
      "  done: true\n",
      "  experiment_id: d950d71995514495bd05ca75b5b29411\n",
      "  hostname: 3df5e2599339442e992df3f7ab924256000005\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.944056\n",
      "  node_ip: 10.0.0.21\n",
      "  pid: 262\n",
      "  time_since_restore: 0.09344601631164551\n",
      "  time_this_iter_s: 0.09344601631164551\n",
      "  time_total_s: 0.09344601631164551\n",
      "  timestamp: 1638732206\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d1628_00001\n",
      "  \n",
      "Result for train_breast_cancer_d1628_00000:\n",
      "  date: 2021-12-05_19-23-26\n",
      "  done: true\n",
      "  experiment_id: 966f336b8cc740d393e99f5297ec3a29\n",
      "  hostname: 3df5e2599339442e992df3f7ab924256000000\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.8671329999999999\n",
      "  node_ip: 10.0.0.12\n",
      "  pid: 253\n",
      "  time_since_restore: 0.08426094055175781\n",
      "  time_this_iter_s: 0.08426094055175781\n",
      "  time_total_s: 0.08426094055175781\n",
      "  timestamp: 1638732206\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d1628_00000\n",
      "  \n",
      "Result for train_breast_cancer_d1628_00008:\n",
      "  date: 2021-12-05_19-23-27\n",
      "  done: true\n",
      "  experiment_id: b5cc151fc4e145e6a621ad1519f55c01\n",
      "  hostname: 3df5e2599339442e992df3f7ab924256000000\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.958042\n",
      "  node_ip: 10.0.0.12\n",
      "  pid: 254\n",
      "  time_since_restore: 0.08347344398498535\n",
      "  time_this_iter_s: 0.08347344398498535\n",
      "  time_total_s: 0.08347344398498535\n",
      "  timestamp: 1638732207\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d1628_00008\n",
      "  \n",
      "Result for train_breast_cancer_d1628_00003:\n",
      "  date: 2021-12-05_19-23-27\n",
      "  done: true\n",
      "  experiment_id: 58e7e79c697c40a38c979604d4a82dd8\n",
      "  hostname: 3df5e2599339442e992df3f7ab924256000003\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.93007\n",
      "  node_ip: 10.0.0.19\n",
      "  pid: 227\n",
      "  time_since_restore: 0.08287525177001953\n",
      "  time_this_iter_s: 0.08287525177001953\n",
      "  time_total_s: 0.08287525177001953\n",
      "  timestamp: 1638732207\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d1628_00003\n",
      "  \n",
      "Result for train_breast_cancer_d1628_00007:\n",
      "  date: 2021-12-05_19-23-27\n",
      "  done: true\n",
      "  experiment_id: 541f230d5764419b982574e8b5465407\n",
      "  hostname: 3df5e2599339442e992df3f7ab924256000005\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.895105\n",
      "  node_ip: 10.0.0.21\n",
      "  pid: 226\n",
      "  time_since_restore: 0.08813285827636719\n",
      "  time_this_iter_s: 0.08813285827636719\n",
      "  time_total_s: 0.08813285827636719\n",
      "  timestamp: 1638732207\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d1628_00007\n",
      "  \n",
      "Result for train_breast_cancer_d1628_00005:\n",
      "  date: 2021-12-05_19-23-27\n",
      "  done: true\n",
      "  experiment_id: 33cf255ec0d94f46a7ffe52fab82fb7d\n",
      "  hostname: 3df5e2599339442e992df3f7ab924256000006\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.958042\n",
      "  node_ip: 10.0.0.22\n",
      "  pid: 228\n",
      "  time_since_restore: 0.15333223342895508\n",
      "  time_this_iter_s: 0.15333223342895508\n",
      "  time_total_s: 0.15333223342895508\n",
      "  timestamp: 1638732207\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d1628_00005\n",
      "  \n",
      "Result for train_breast_cancer_d1628_00009:\n",
      "  date: 2021-12-05_19-23-27\n",
      "  done: true\n",
      "  experiment_id: b25b5a3ba61c410389a4438bf29c2fce\n",
      "  hostname: 3df5e2599339442e992df3f7ab924256000006\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.839161\n",
      "  node_ip: 10.0.0.22\n",
      "  pid: 231\n",
      "  time_since_restore: 0.09108281135559082\n",
      "  time_this_iter_s: 0.09108281135559082\n",
      "  time_total_s: 0.09108281135559082\n",
      "  timestamp: 1638732207\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d1628_00009\n",
      "  \n",
      "Result for train_breast_cancer_d1628_00004:\n",
      "  date: 2021-12-05_19-23-29\n",
      "  done: true\n",
      "  experiment_id: ec946c26339a41bab887e3df981e182e\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.916084\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 18911\n",
      "  time_since_restore: 1.4016528129577637\n",
      "  time_this_iter_s: 1.4016528129577637\n",
      "  time_total_s: 1.4016528129577637\n",
      "  timestamp: 1638732209\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d1628_00004\n",
      "  \n",
      "Result for train_breast_cancer_d1628_00006:\n",
      "  date: 2021-12-05_19-23-29\n",
      "  done: true\n",
      "  experiment_id: 5390d919bb8d456cba30ef1e06b8f1fa\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.972028\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 18909\n",
      "  time_since_restore: 1.4347193241119385\n",
      "  time_this_iter_s: 1.4347193241119385\n",
      "  time_total_s: 1.4347193241119385\n",
      "  timestamp: 1638732209\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d1628_00006\n",
      "  \n",
      "Result for train_breast_cancer_d1628_00002:\n",
      "  date: 2021-12-05_19-23-29\n",
      "  done: true\n",
      "  experiment_id: f2359fe601c2456987db3897792bcc6f\n",
      "  hostname: nc6v0\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.895105\n",
      "  node_ip: 10.0.0.11\n",
      "  pid: 18910\n",
      "  time_since_restore: 1.4355478286743164\n",
      "  time_this_iter_s: 1.4355478286743164\n",
      "  time_total_s: 1.4355478286743164\n",
      "  timestamp: 1638732209\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: d1628_00002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-05 19:23:29 (running for 00:00:03.79)<br>Memory usage on this node: 3.4/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/77.71 GiB heap, 0.0/35.56 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-05_19-23-25<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_breast_cancer_d1628_00000</td><td>TERMINATED</td><td>10.0.0.12:253  </td><td style=\"text-align: right;\">0.000556531</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.990753</td><td style=\"text-align: right;\">0.867133</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0842609</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00001</td><td>TERMINATED</td><td>10.0.0.21:262  </td><td style=\"text-align: right;\">0.000364689</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.592571</td><td style=\"text-align: right;\">0.944056</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.093446 </td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00002</td><td>TERMINATED</td><td>10.0.0.11:18910</td><td style=\"text-align: right;\">0.000363326</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.560972</td><td style=\"text-align: right;\">0.895105</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       1.43555  </td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00003</td><td>TERMINATED</td><td>10.0.0.19:227  </td><td style=\"text-align: right;\">0.00226183 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.621186</td><td style=\"text-align: right;\">0.93007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0828753</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00004</td><td>TERMINATED</td><td>10.0.0.11:18911</td><td style=\"text-align: right;\">0.0429831  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.910877</td><td style=\"text-align: right;\">0.916084</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       1.40165  </td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00005</td><td>TERMINATED</td><td>10.0.0.22:228  </td><td style=\"text-align: right;\">0.00948015 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.698004</td><td style=\"text-align: right;\">0.958042</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.153332 </td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00006</td><td>TERMINATED</td><td>10.0.0.11:18909</td><td style=\"text-align: right;\">0.0353399  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.697988</td><td style=\"text-align: right;\">0.972028</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       1.43472  </td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00007</td><td>TERMINATED</td><td>10.0.0.21:226  </td><td style=\"text-align: right;\">0.00260922 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.64144 </td><td style=\"text-align: right;\">0.895105</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0881329</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00008</td><td>TERMINATED</td><td>10.0.0.12:254  </td><td style=\"text-align: right;\">0.0699687  </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.596595</td><td style=\"text-align: right;\">0.958042</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0834734</td></tr>\n",
       "<tr><td>train_breast_cancer_d1628_00009</td><td>TERMINATED</td><td>10.0.0.22:231  </td><td style=\"text-align: right;\">0.000318741</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.979203</td><td style=\"text-align: right;\">0.839161</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0910828</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 19:23:29,391\tINFO tune.py:626 -- Total run time: 3.95 seconds (3.78 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    " import sklearn.datasets\n",
    " import sklearn.metrics\n",
    " from sklearn.model_selection import train_test_split\n",
    " import xgboost as xgb\n",
    "\n",
    " from ray import tune\n",
    "\n",
    "\n",
    " def train_breast_cancer(config):\n",
    "     # Load dataset\n",
    "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "     # Split into train and test set\n",
    "     train_x, test_x, train_y, test_y = train_test_split(\n",
    "         data, labels, test_size=0.25)\n",
    "     # Build input matrices for XGBoost\n",
    "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
    "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
    "     # Train the classifier\n",
    "     results = {}\n",
    "     xgb.train(\n",
    "         config,\n",
    "         train_set,\n",
    "         evals=[(test_set, \"eval\")],\n",
    "         evals_result=results,\n",
    "         verbose_eval=False)\n",
    "     # Return prediction accuracy\n",
    "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
    "     tune.report(mean_accuracy=accuracy, done=True)\n",
    "\n",
    "\n",
    " config = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"eval_metric\": [\"logloss\", \"error\"],\n",
    "     \"max_depth\": tune.randint(1, 9),\n",
    "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
    "     \"subsample\": tune.uniform(0.5, 1.0),\n",
    "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
    " }\n",
    " analysis = tune.run(\n",
    "     train_breast_cancer,\n",
    "     resources_per_trial={\"cpu\": 1},\n",
    "     config=config,\n",
    "     num_samples=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dask\n",
    "\n",
    "# import ray\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import glob\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Model\n",
    "data_url = 'https://azureopendatastorage.blob.core.windows.net/isdweatherdatacontainer/ISDWeather'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adlfs import AzureBlobFileSystem,AzureDatalakeFileSystem\n",
    "sas_token='sp=rle&st=2021-11-27T19:26:49Z&se=2022-04-22T02:26:49Z&spr=https&sv=2020-08-04&sr=c&sig=gpYJ3LofkkjkeWkrMDTY1Ge6NsOCghbUR9CQs65HCvU%3D'\n",
    "account_key='ak7nSgU/iRc5XCvXjaM2UwX18ybS9WO1BsE4Vm42XLmiZvBm1kCyZQD3USeCCOiwusWkDaq0jcRF1JpPHiAMhw=='\n",
    "account_name=\"adlsgen7\"\n",
    "abfs = AzureBlobFileSystem(account_name=\"adlsgen7\",account_key=account_key,  container_name=\"mltraining\")\n",
    "abfs2 = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "storage_options={'account_name': account_name, 'account_key': account_key}\n",
    "\n",
    "ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year2008', storage_options=storage_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.24it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 8/8 [00:01<00:00,  4.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# https://adlsgen7.blob.core.windows.net/mltraining/ISDWeatherDelta/year2008/month/part-00009-21953d01-b5b8-4fa7-8bd2-96b025a24bc3.c000.snappy.parquet\n",
    "# https://adlsgen7.blob.core.windows.net/mltraining/ISDWeatherDelta/year2008/month10/part-00001-1b0e76df-8a22-4221-9b5a-8b7936aa13ea.c000.snappy.parquet\n",
    "data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs2)\n",
    "data2 = ray.data.read_parquet(\"az://mltraining/ISDWeatherDelta/year2008\", filesystem=abfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97581959"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "usaf                       97581959\n",
       "wban                       97581959\n",
       "datetime                   97581959\n",
       "latitude                   97581959\n",
       "longitude                  97581959\n",
       "elevation                  97581959\n",
       "windAngle                  79483952\n",
       "windSpeed                  82288222\n",
       "temperature                95119398\n",
       "seaLvlPressure             35943606\n",
       "cloudCoverage              57138202\n",
       "presentWeatherIndicator     9538179\n",
       "pastWeatherIndicator        4114610\n",
       "precipTime                 19003392\n",
       "precipDepth                19003392\n",
       "snowDepth                    353685\n",
       "stationName                97319338\n",
       "countryOrRegion            97267449\n",
       "p_k                        97581959\n",
       "day                        97581959\n",
       "version                    97581959\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7fc4810f4c70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(scheduler=ray_dask_get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98904376"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:48:42,187\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2021-12-06 19:48:45,043 WARN Utils [Thread-1]: Your hostname, nc6v0 resolves to a loopback address: 127.0.0.1; using 10.0.0.11 instead (on interface eth0)\n",
      "2021-12-06 19:48:45,046 WARN Utils [Thread-1]: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "2021-12-06 19:48:45,240 WARN NativeCodeLoader [Thread-1]: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:48:45,321 INFO SecurityManager [Thread-1]: Changing view acls to: azureuser\n",
      "2021-12-06 19:48:45,321 INFO SecurityManager [Thread-1]: Changing modify acls to: azureuser\n",
      "2021-12-06 19:48:45,322 INFO SecurityManager [Thread-1]: Changing view acls groups to: \n",
      "2021-12-06 19:48:45,322 INFO SecurityManager [Thread-1]: Changing modify acls groups to: \n",
      "2021-12-06 19:48:45,323 INFO SecurityManager [Thread-1]: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(azureuser); groups with view permissions: Set(); users  with modify permissions: Set(azureuser); groups with modify permissions: Set()\n",
      "2021-12-06 19:48:45,591 INFO Utils [Thread-1]: Successfully started service 'RAY_RPC_ENV' on port 44621.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/jars/ray_dist.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-06 19:48:48,798 INFO RayAppMaster$RayAppMasterEndpoint [dispatcher-event-loop-1]: Registering app example\n",
      "2021-12-06 19:48:48,802 INFO RayAppMaster$RayAppMasterEndpoint [dispatcher-event-loop-1]: Registered app example with ID app-20211206194848-0000\n",
      "0    1\n",
      "1    4\n",
      "2    9\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|multiply_func(x, x)|\n",
      "+-------------------+\n",
      "|                  1|\n",
      "|                  4|\n",
      "|                  9|\n",
      "+-------------------+\n",
      "\n",
      "2021-12-06 19:48:59,086 INFO RayAppMaster [Thread-1]: Stopping RayAppMaster\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import raydp\n",
    "import os\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "os.environ[\"PYSPARK_PYTHON\"]=\"/anaconda/envs/azureml_py38/bin/python3\"\n",
    "\n",
    "# ray.init(address ='ray://10.0.0.11:6379')\n",
    "spark = raydp.init_spark(\n",
    "  app_name = \"example\",\n",
    "  num_executors = 2,\n",
    "  executor_cores = 1,\n",
    "  executor_memory = \"1gb\"\n",
    ")\n",
    "\n",
    "# data =spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://ojsales-simulatedcontainer@azureopendatastorage.blob.core.windows.net/oj_sales_data/Store10*.csv\")\n",
    "\n",
    "\n",
    "# # normal data processesing with Spark\n",
    "# df = spark.createDataFrame([('look',), ('spark',), ('tutorial',), ('spark',), ('look', ), ('python', )], ['word'])\n",
    "# df.show()\n",
    "# word_count = df.groupBy('word').count()\n",
    "# word_count.show()\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf\n",
    "from pyspark.sql.types import LongType\n",
    "\n",
    "# Declare the function and create the UDF\n",
    "def multiply_func(a: pd.Series, b: pd.Series) -> pd.Series:\n",
    "    return a * b\n",
    "\n",
    "multiply = pandas_udf(multiply_func, returnType=LongType())\n",
    "\n",
    "# The function for a pandas_udf should be able to execute with local Pandas data\n",
    "x = pd.Series([1, 2, 3])\n",
    "print(multiply_func(x, x))\n",
    "# 0    1\n",
    "# 1    4\n",
    "# 2    9\n",
    "# dtype: int64\n",
    "\n",
    "# Create a Spark DataFrame, 'spark' is an existing SparkSession\n",
    "df = spark.createDataFrame(pd.DataFrame(x, columns=[\"x\"]))\n",
    "\n",
    "# Execute function as a Spark vectorized UDF\n",
    "df.select(multiply(col(\"x\"), col(\"x\"))).show()\n",
    "# +-------------------+\n",
    "# |multiply_func(x, x)|\n",
    "# +-------------------+\n",
    "# |                  1|\n",
    "# |                  4|\n",
    "# |                  9|\n",
    "# +-------------------+\n",
    "\n",
    "\n",
    "# stop the spark cluster\n",
    "raydp.stop_spark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raydp.stop_spark()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - PyTorch",
   "language": "python",
   "name": "azureml_py38_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
