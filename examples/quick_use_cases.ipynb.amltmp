{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Testing for Interactive use case"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade ray-on-aml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "# from azureml.widgets import RunDetails\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "import platform\n",
        "import sys\n",
        "# sys.path.append(\"../\") # go to parent dir\n",
        "import importlib\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1639423111876
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You can pre-provision \"worker-cpu-v3\" in the same vnet with your compute instance\n",
        "from ray_on_aml.core import Ray_On_AML\n",
        "ws = Workspace.from_config()\n",
        "# shin-dask-vnet/dask-public\n",
        "# net_rg = None, compute_cluster = 'cpu-cluster', vm_size='STANDARD_DS3_V2',vnet='rayvnet', subnet='default'\n",
        "\n",
        "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"worker-cpu-v3\", vnet_rg = 'shin-dask-rg', vnet='shin-dask-vnet', subnet='dask-public' )\n",
        "_, ray = ray_on_aml.getRay()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "rank returned is  None\nrank returned is  None\nazureml_py38\nInProgress..\nSucceededProvisioning operation finished, operation \"Succeeded\"\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-13 19:23:37,758\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n2021-12-13 19:24:05,679\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 10.1.0.5:6379\n2021-12-13 19:24:05,824\tWARNING worker.py:1219 -- The autoscaler failed with the following error:\nTerminated with signal 15\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 543, in <module>\n    monitor.run()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 439, in run\n    self._run()\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 346, in _run\n    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1639423878281
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ray.cluster_resources()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "{'node:10.1.0.12': 1.0,\n 'memory': 55648434588.0,\n 'CPU': 24.0,\n 'object_store_memory': 24289927985.0,\n 'node:10.1.0.5': 1.0,\n 'node:10.1.0.11': 1.0,\n 'node:10.1.0.13': 1.0,\n 'node:10.1.0.15': 1.0,\n 'node:10.1.0.9': 1.0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1639428530663
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ray_on_aml.shutdown()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1639106683762
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing with Dask on Ray"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import ray\n",
        "# ray.init()\n",
        "from ray.util.dask import ray_dask_get\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "dask.config.set(scheduler=ray_dask_get)\n",
        "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
        "\n",
        "# The Dask scheduler submits the underlying task graph to Ray.\n",
        "d_arr.mean().compute(scheduler=ray_dask_get)\n",
        "\n",
        "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
        "# specify it on each compute call.\n",
        "\n",
        "df = dd.from_pandas(\n",
        "    pd.DataFrame(\n",
        "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
        "    npartitions=2)\n",
        "df.groupby([\"age\"]).mean().compute()\n",
        "\n",
        "# ray.shutdown()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "       grade\nage         \n11    1604.0\n13    4258.5\n16    2995.0\n27    1715.0\n37    5443.0\n...      ...\n9901  7171.0\n9916   932.0\n9962  5476.0\n9986  2555.0\n9987  2220.0\n\n[981 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>grade</th>\n    </tr>\n    <tr>\n      <th>age</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>1604.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4258.5</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2995.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1715.0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>5443.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9901</th>\n      <td>7171.0</td>\n    </tr>\n    <tr>\n      <th>9916</th>\n      <td>932.0</td>\n    </tr>\n    <tr>\n      <th>9962</th>\n      <td>5476.0</td>\n    </tr>\n    <tr>\n      <th>9986</th>\n      <td>2555.0</td>\n    </tr>\n    <tr>\n      <th>9987</th>\n      <td>2220.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>981 rows Ã— 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1639428544183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dask.dataframe as dd\n",
        "\n",
        "# storage_options = {'account_name': 'azureopendatastorage'}\n",
        "# ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
        "# ddf.count().compute()\n",
        "#This still have error about parquet, need to fix, might be lib version conflict"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1639104458150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dask\n",
        "\n",
        "# import ray\n",
        "from ray.util.dask import ray_dask_get\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dask\n",
        "import dask.dataframe as dd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from azureml.core import Workspace, Dataset, Model\n",
        "from adlfs import AzureBlobFileSystem\n",
        "\n",
        "abfs = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
        "\n",
        "data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs)\n",
        "\n",
        "data.count()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\r  0%|          | 0/16 [00:00<?, ?it/s]\rMetadata Fetch Progress:   0%|          | 0/16 [00:00<?, ?it/s]"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1639106144831
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Ray Tune for distributed ML tunning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "# import ray\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # In this example, we don't change the model architecture\n",
        "        # due to simplicity.\n",
        "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
        "        self.fc = nn.Linear(192, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
        "        x = x.view(-1, 192)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "# Change these values if you want the training to run quicker or slower.\n",
        "EPOCH_SIZE = 512\n",
        "TEST_SIZE = 256\n",
        "\n",
        "def train(model, optimizer, train_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # We set this just for the example to run quickly.\n",
        "        if batch_idx * len(data) > EPOCH_SIZE:\n",
        "            return\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test(model, data_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            # We set this just for the example to run quickly.\n",
        "            if batch_idx * len(data) > TEST_SIZE:\n",
        "                break\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    return correct / total\n",
        "def train_mnist(config):\n",
        "    # Data Setup\n",
        "    mnist_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
        "        batch_size=64,\n",
        "        shuffle=True)\n",
        "    test_loader = DataLoader(\n",
        "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
        "        batch_size=64,\n",
        "        shuffle=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ConvNet()\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
        "    for i in range(10):\n",
        "        train(model, optimizer, train_loader)\n",
        "        acc = test(model, test_loader)\n",
        "\n",
        "        # Send the current training result back to Tune\n",
        "        tune.report(mean_accuracy=acc)\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            # This saves the model to the trial directory\n",
        "            torch.save(model.state_dict(), \"./model.pth\")\n",
        "search_space = {\n",
        "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
        "    \"momentum\": tune.uniform(0.01, 0.09)\n",
        "}\n",
        "\n",
        "# Uncomment this to enable distributed execution\n",
        "# ray.shutdown()\n",
        "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
        "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
        "# Download the dataset first\n",
        "datasets.MNIST(\"~/data\", train=True, download=True)\n",
        "\n",
        "analysis = tune.run(train_mnist, config=search_space)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1639106657384
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import sklearn.datasets\n",
        " import sklearn.metrics\n",
        " from sklearn.model_selection import train_test_split\n",
        " import xgboost as xgb\n",
        "\n",
        " from ray import tune\n",
        "\n",
        "\n",
        " def train_breast_cancer(config):\n",
        "     # Load dataset\n",
        "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "     # Split into train and test set\n",
        "     train_x, test_x, train_y, test_y = train_test_split(\n",
        "         data, labels, test_size=0.25)\n",
        "     # Build input matrices for XGBoost\n",
        "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
        "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
        "     # Train the classifier\n",
        "     results = {}\n",
        "     xgb.train(\n",
        "         config,\n",
        "         train_set,\n",
        "         evals=[(test_set, \"eval\")],\n",
        "         evals_result=results,\n",
        "         verbose_eval=False)\n",
        "     # Return prediction accuracy\n",
        "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
        "     tune.report(mean_accuracy=accuracy, done=True)\n",
        "\n",
        "\n",
        " config = {\n",
        "     \"objective\": \"binary:logistic\",\n",
        "     \"eval_metric\": [\"logloss\", \"error\"],\n",
        "     \"max_depth\": tune.randint(1, 9),\n",
        "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
        "     \"subsample\": tune.uniform(0.5, 1.0),\n",
        "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
        " }\n",
        " analysis = tune.run(\n",
        "     train_breast_cancer,\n",
        "     resources_per_trial={\"cpu\": 1},\n",
        "     config=config,\n",
        "     num_samples=10)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1639106681808
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Spark on Ray (#todo)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import ray\n",
        "# import raydp\n",
        "# import os\n",
        "# ray.shutdown()\n",
        "# ray.init()\n",
        "# os.environ[\"PYSPARK_PYTHON\"]=\"/anaconda/envs/azureml_py38/bin/python3\"\n",
        "\n",
        "# # ray.init(address ='ray://10.0.0.11:6379')\n",
        "# spark = raydp.init_spark(\n",
        "#   app_name = \"example\",\n",
        "#   num_executors = 2,\n",
        "#   executor_cores = 1,\n",
        "#   executor_memory = \"1gb\"\n",
        "# )\n",
        "\n",
        "# # data =spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://ojsales-simulatedcontainer@azureopendatastorage.blob.core.windows.net/oj_sales_data/Store10*.csv\")\n",
        "\n",
        "\n",
        "# # # normal data processesing with Spark\n",
        "# # df = spark.createDataFrame([('look',), ('spark',), ('tutorial',), ('spark',), ('look', ), ('python', )], ['word'])\n",
        "# # df.show()\n",
        "# # word_count = df.groupBy('word').count()\n",
        "# # word_count.show()\n",
        "# import pandas as pd\n",
        "\n",
        "# from pyspark.sql.functions import col, pandas_udf\n",
        "# from pyspark.sql.types import LongType\n",
        "\n",
        "# # Declare the function and create the UDF\n",
        "# def multiply_func(a: pd.Series, b: pd.Series) -> pd.Series:\n",
        "#     return a * b\n",
        "\n",
        "# multiply = pandas_udf(multiply_func, returnType=LongType())\n",
        "\n",
        "# # The function for a pandas_udf should be able to execute with local Pandas data\n",
        "# x = pd.Series([1, 2, 3])\n",
        "# print(multiply_func(x, x))\n",
        "# # 0    1\n",
        "# # 1    4\n",
        "# # 2    9\n",
        "# # dtype: int64\n",
        "\n",
        "# # Create a Spark DataFrame, 'spark' is an existing SparkSession\n",
        "# df = spark.createDataFrame(pd.DataFrame(x, columns=[\"x\"]))\n",
        "\n",
        "# # Execute function as a Spark vectorized UDF\n",
        "# df.select(multiply(col(\"x\"), col(\"x\"))).show()\n",
        "# # +-------------------+\n",
        "# # |multiply_func(x, x)|\n",
        "# # +-------------------+\n",
        "# # |                  1|\n",
        "# # |                  4|\n",
        "# # |                  9|\n",
        "# # +-------------------+\n",
        "\n",
        "\n",
        "# # stop the spark cluster\n",
        "# raydp.stop_spark()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Ray on Job Cluster"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# base_conda_dep =['adlfs>=2021.10.0','pytorch','matplotlib','torchvision','pip']\n",
        "# base_pip_dep = ['sklearn','xgboost','lightgbm','ray[default]==1.9.0', 'xgboost_ray', 'dask','pyarrow>=6.0.1', 'azureml-mlflow']\n",
        "compute_cluster = 'worker-cpu-v3'\n",
        "maxnode =5\n",
        "vm_size='STANDARD_DS3_V2'\n",
        "vnet='rayvnet'\n",
        "subnet='default'\n",
        "exp ='ray_on_aml_job'\n",
        "ws_detail = ws.get_details()\n",
        "ws_rg = ws_detail['id'].split(\"/\")[4]\n",
        "vnet_rg=None\n",
        "try:\n",
        "    ray_cluster = ComputeTarget(workspace=ws, name=compute_cluster)\n",
        "\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    if vnet_rg is None:\n",
        "        vnet_rg = ws_rg\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
        "                                                        min_nodes=0, max_nodes=maxnode,\n",
        "                                                        vnet_resourcegroup_name=vnet_rg,\n",
        "                                                        vnet_name=vnet,\n",
        "                                                        subnet_name=subnet)\n",
        "    ray_cluster = ComputeTarget.create(ws, compute_cluster, compute_config)\n",
        "\n",
        "    ray_cluster.wait_for_completion(show_output=True)\n",
        "\n",
        "\n",
        "# python_version = [\"python=\"+platform.python_version()]\n",
        "\n",
        "\n",
        "\n",
        "# conda_packages = python_version+base_conda_dep\n",
        "# pip_packages = base_pip_dep \n",
        "\n",
        "# conda_dep = CondaDependencies()\n",
        "\n",
        "# rayEnv = Environment(name=\"rayEnv\")\n",
        "rayEnv = Environment.get(ws, \"rayEnv\", version=18)\n",
        "# for conda_package in conda_packages:\n",
        "#     conda_dep.add_conda_package(conda_package)\n",
        "\n",
        "# for pip_package in pip_packages:\n",
        "#     conda_dep.add_pip_package(pip_package)\n",
        "\n",
        "# # Adds dependencies to PythonSection of myenv\n",
        "# rayEnv.python.conda_dependencies=conda_dep\n",
        "\n",
        "src = ScriptRunConfig(source_directory='job',\n",
        "                script='aml_job.py',\n",
        "                environment=rayEnv,\n",
        "                compute_target=ray_cluster,\n",
        "                distributed_job_config=PyTorchConfiguration(node_count=maxnode),\n",
        "                    # arguments = [\"--master_ip\",master_ip]\n",
        "                )\n",
        "run = Experiment(ws, exp).submit(src)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "cac4749ce6e64bfd07fafd5bf9c175e86cc05b1d81ce0d05824a22ecc489c963"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}