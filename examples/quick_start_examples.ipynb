{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Quick examples to demostrate AML Ray/Dask cluster usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive mode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install at this your conda notebook environment to run interactive examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade adlfs ray==2.2.0 ray[air]==2.2.0 ray[data]==2.2.0 azure-ai-ml ray-on-aml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for torch\n",
    "# conda install -y -c pytorch -c conda-forge cudatoolkit=11.1 pytorch torchvision torchaudio\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start ML client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639183943936
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command, Input\n",
    "from azure.identity import DefaultAzureCredential\n",
    "# Enter details of your AML workspace\n",
    "subscription_id = \"840b5c5c-3f4a-459a-94fc-6bad2a969f9d\"\n",
    "resource_group = \"ml\"\n",
    "workspace = \"ws02ent\"\n",
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please make sure to create compute cluster in the same vnet with your compute instance. You need to have vnet, otherwise compute cannot communicate with each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639185778952
    }
   },
   "outputs": [],
   "source": [
    "from ray_on_aml.core import Ray_On_AML\n",
    "\n",
    "# from src.ray_on_aml.core import Ray_On_AML\n",
    "\n",
    "import logging\n",
    "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"d13\")\n",
    "#Note that if you need to customize the pip installation of the cluster, you also needs to support the ray package e.g. ray[data] which \n",
    "#match the version of the ray package(s) in your compute instance. If you don't specify pip_packages then ray[default] is inserted \n",
    "#automatically\n",
    "\n",
    "ray = ray_on_aml.getRay(num_node=2,pip_packages=[\"ray[air]==2.2.0\",\"ray[data]==2.2.0\",\"torch==1.13.0\",\"fastparquet==2022.12.0\", \n",
    "\"azureml-mlflow==1.48.0\", \"pyarrow==6.0.1\", \"dask==2022.12.0\", \"adlfs==2022.11.2\", \"fsspec==2022.11.0\"])\n",
    "client = ray.init(f\"ray://{ray_on_aml.headnode_private_ip}:10001\")\n",
    "\n",
    "#if you want to use CI as head node set ci_is_head=True as in ray_on_aml.getRay(ci_is_head=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.cluster_resources()\n",
    "#if may take some time for all cluster resources to show up, run this again if you don't see all resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask on Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can use Dask on this Ray cluster by telling Dask to use Ray as the scheduler. By doing this, you will have a cluster with both Dask and Ray without having to setup them saperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639183635290
    }
   },
   "outputs": [],
   "source": [
    "#Scaling up date with Dask dataframe API.\n",
    "#Please make sure you have pandas version 1.4+ and restart to run this successfully.\n",
    "import dask\n",
    "from ray.util.dask import enable_dask_on_ray\n",
    "enable_dask_on_ray()\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "storage_options = {'account_name': 'azureopendatastorage'}\n",
    "ddf = dd.read_parquet('az://nyctlc/green/puYear=2015/puMonth=*/*.parquet', storage_options=storage_options)\n",
    "ddf.count().compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639186778862
    }
   },
   "outputs": [],
   "source": [
    "#Ray also support Ray dataset. You can read into ray dataset then convert to Dask or other ML format which is convenient for ML training.https://docs.ray.io/en/latest/data/dataset.html\n",
    "# you may need to upgrade pyarrow to run this successfully\n",
    "from adlfs import AzureBlobFileSystem\n",
    "\n",
    "abfs = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
    "#if read all years and months\n",
    "# data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather//\", filesystem=abfs)\n",
    "data =ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2015/\"], filesystem=abfs)\n",
    "data.count()\n",
    "# 1,584,481,119 is the count for all data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disconnect your client and shutdown ray cluster after use\n",
    "client.disconnect()\n",
    "ray_on_aml.shutdown()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount remote data to your ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of using input and output for interactive job. You need to define adlsstore0001 in your Azure ML workspace first\n",
    "from azure.ai.ml import command, Input, Output\n",
    "from ray_on_aml.core import Ray_On_AML\n",
    "import logging\n",
    "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"ds11\", verbosity=logging.INFO )\n",
    "#Define inputs and/or outputs and setup ray cluster & client\n",
    "inputs={\n",
    "\n",
    "    \"ISDWeather\": Input(\n",
    "        type=\"uri_folder\",\n",
    "        path=\"azureml://datastores/adlsstore0001/paths/ISDWeather/year=2008\",\n",
    "    )\n",
    "}\n",
    "\n",
    "outputs={\n",
    "    \"output1\": Output(\n",
    "        type=\"uri_folder\",\n",
    "        path=\"azureml://datastores/adlsstore0001/paths/dev\",\n",
    "    ),\n",
    "    \"output2\": Output(\n",
    "        type=\"uri_folder\",\n",
    "        path=\"azureml://datastores/adlsstore0001/paths/dev\",\n",
    "    )\n",
    "}\n",
    "\n",
    "ray = ray_on_aml.getRay(inputs = inputs,outputs=outputs, num_node=2,\n",
    "pip_packages=[\"ray[air]==2.2.0\",\"ray[data]==2.2.0\",\"torch==1.13.0\",\"fastparquet==2022.12.0\", \n",
    "\"azureml-mlflow==1.48.0\", \"pyarrow==6.0.1\", \"dask==2022.2.0\", \"adlfs==2022.11.2\", \"fsspec==2022.11.0\"])\n",
    "client = ray.init(f\"ray://{ray_on_aml.headnode_private_ip}:10001\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now you can refer to the mount points with assigned name to use \n",
    "data = ray.data.read_parquet(ray_on_aml.mount_points['ISDWeather'])\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disconnect your client and shutdown ray cluster after use\n",
    "client.disconnect()\n",
    "ray_on_aml.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Tune for distributed ML tunning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pls use azureml_py38_PT_TF environment. It has stable tensorflow and pytorch installation and install following additional library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ray[air]==2.2.0 xgboost xgboost_ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray_on_aml.core import Ray_On_AML\n",
    "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"d13\")\n",
    "\n",
    "\n",
    "# For use as client mode, uncomment these lines\n",
    "ray = ray_on_aml.getRay(ci_is_head=True, num_node=2,pip_packages=[\"ray[air]==2.2.0\",\"torch==1.13.0\",\"xgboost\", \"xgboost_ray\",\"azureml-mlflow==1.48.0\", \"pyarrow==6.0.1\"])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train ML with Ray[AIR] and pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "\n",
    "# Load data.\n",
    "dataset = ray.data.read_csv(\"s3://anonymous@air-example-data/breast_cancer.csv\")\n",
    "\n",
    "# Split data into train and validation.\n",
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.3)\n",
    "\n",
    "# Create a test dataset by dropping the target column.\n",
    "test_dataset = valid_dataset.drop_columns(cols=[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from ray.data.preprocessors import Concatenator, Chain, StandardScaler\n",
    "\n",
    "# Create a preprocessor to scale some columns and concatenate the result.\n",
    "preprocessor = Chain(\n",
    "    StandardScaler(columns=[\"mean radius\", \"mean texture\"]),\n",
    "    Concatenator(exclude=[\"target\"], dtype=np.float32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from ray import train\n",
    "from ray.air import session\n",
    "from ray.air.config import ScalingConfig\n",
    "from ray.train.torch import TorchCheckpoint, TorchTrainer\n",
    "\n",
    "\n",
    "def create_model(input_features):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(in_features=input_features, out_features=16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 1),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "\n",
    "def train_loop_per_worker(config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"num_epochs\"]\n",
    "    num_features = config[\"num_features\"]\n",
    "\n",
    "    # Get the Ray Dataset shard for this data parallel worker,\n",
    "    # and convert it to a PyTorch Dataset.\n",
    "    train_data = session.get_dataset_shard(\"train\")\n",
    "    # Create model.\n",
    "    model = create_model(num_features)\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for cur_epoch in range(epochs):\n",
    "        for batch in train_data.iter_torch_batches(\n",
    "            batch_size=batch_size, dtypes=torch.float32\n",
    "        ):\n",
    "            # \"concat_out\" is the output column of the Concatenator.\n",
    "            inputs, labels = batch[\"concat_out\"], batch[\"target\"]\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(inputs)\n",
    "            train_loss = loss_fn(predictions, labels.unsqueeze(1))\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        loss = train_loss.item()\n",
    "        session.report({\"loss\": loss}, checkpoint=TorchCheckpoint.from_model(model))\n",
    "\n",
    "\n",
    "num_features = len(train_dataset.schema().names) - 1\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    train_loop_per_worker=train_loop_per_worker,\n",
    "    train_loop_config={\n",
    "        \"batch_size\": 128,\n",
    "        \"num_epochs\": 20,\n",
    "        \"num_features\": num_features,\n",
    "        \"lr\": 0.001,\n",
    "    },\n",
    "    scaling_config=ScalingConfig(\n",
    "        num_workers=3,  # Number of workers to use for data parallelism.\n",
    "        use_gpu=False,\n",
    "        trainer_resources={\"CPU\": 0},  # so that the example works on Colab.\n",
    "    ),\n",
    "    datasets={\"train\": train_dataset},\n",
    "    preprocessor=preprocessor,\n",
    ")\n",
    "# Execute training.\n",
    "result = trainer.fit()\n",
    "print(f\"Last result: {result.metrics}\")\n",
    "# Last result: {'loss': 0.6559339960416158, ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributed XGBoost https://docs.ray.io/en/latest/xgboost-ray.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost_ray import RayXGBClassifier, RayParams\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "clf = RayXGBClassifier(\n",
    "    n_jobs=10,  # In XGBoost-Ray, n_jobs sets the number of actors\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# scikit-learn API will automatically conver the data\n",
    "# to RayDMatrix format as needed.\n",
    "# You can also pass X as a RayDMatrix, in which case\n",
    "# y will be ignored.\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred_ray = clf.predict(X_test)\n",
    "print(pred_ray.shape)\n",
    "\n",
    "pred_proba_ray = clf.predict_proba(X_test)\n",
    "print(pred_proba_ray.shape)\n",
    "\n",
    "# It is also possible to pass a RayParams object\n",
    "# to fit/predict/predict_proba methods - will override\n",
    "# n_jobs set during initialization\n",
    "\n",
    "clf.fit(X_train, y_train, ray_params=RayParams(num_actors=10))\n",
    "\n",
    "pred_ray = clf.predict(X_test, ray_params=RayParams(num_actors=10))\n",
    "print(pred_ray.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "train_x, train_y = load_breast_cancer(return_X_y=True)\n",
    "train_set = RayDMatrix(train_x, train_y)\n",
    "\n",
    "evals_result = {}\n",
    "bst = train(\n",
    "    {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    },\n",
    "    train_set,\n",
    "    evals_result=evals_result,\n",
    "    evals=[(train_set, \"train\")],\n",
    "    verbose_eval=False,\n",
    "    ray_params=RayParams(\n",
    "        num_actors=10,  # Number of remote actors\n",
    "        cpus_per_actor=1))\n",
    "\n",
    "bst.save_model(\"model.xgb\")\n",
    "print(\"Final training error: {:.4f}\".format(\n",
    "    evals_result[\"train\"][\"error\"][-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install library at compute instance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gym dm-tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    }
   ],
   "source": [
    "#Install additional library at Ray cluster\n",
    "from ray_on_aml.core import Ray_On_AML\n",
    "ray_on_aml =Ray_On_AML(ml_client=ml_client, compute_cluster =\"d13\")\n",
    "\n",
    "\n",
    "# For use as client mode, uncomment these lines\n",
    "ray = ray_on_aml.getRay(ci_is_head=True, num_node=2,pip_packages=[\"ray[air]==2.2.0\",\"torch==1.13.0\",\"xgboost\", \"xgboost_ray\",\"azureml-mlflow==1.48.0\", \"pyarrow==6.0.1\",\n",
    "'gym','dm-tree','scikit-image','opencv-python','tensorflow'])\n",
    "\n",
    "\n",
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RL algorithm (Trainer) we would like to use.\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "\n",
    "# Configure the algorithm.\n",
    "config = {\n",
    "    # Environment (RLlib understands openAI gym registered strings).\n",
    "    \"env\": \"Taxi-v3\",\n",
    "    # Use 2 environment workers (aka \"rollout workers\") that parallelly\n",
    "    # collect samples from their own environment clone(s).\n",
    "    \"num_workers\": 2,\n",
    "    # Change this to \"framework: torch\", if you are using PyTorch.\n",
    "    # Also, use \"framework: tf2\" for tf2.x eager execution.\n",
    "    \"framework\": \"torch\",\n",
    "    # Tweak the default model provided automatically by RLlib,\n",
    "    # given the environment's observation- and action spaces.\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [64, 64],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    # Set up a separate evaluation worker set for the\n",
    "    # `trainer.evaluate()` call after training (see below).\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    # Only for evaluation runs, render the env.\n",
    "    \"evaluation_config\": {\n",
    "        \"render_env\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create our RLlib Trainer.\n",
    "trainer = PPOTrainer(config=config)\n",
    "\n",
    "# Run it for n training iterations. A training iteration includes\n",
    "# parallel sample collection by the environment workers as well as\n",
    "# loss calculation on the collected batch and a model update.\n",
    "for _ in range(3):\n",
    "    print(trainer.train())\n",
    "\n",
    "# Evaluate the trained Trainer (and render each timestep to the shell's\n",
    "# output).\n",
    "trainer.evaluate()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shutdown interactive cluster when not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_on_aml.shutdown()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray on Job Cluster "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can ray this example with either SDK v1 or with CLI v2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SDK V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1639179342786
    }
   },
   "outputs": [],
   "source": [
    "#this example uses v1 sdk but you can also use v2 or CLI to submit the job\n",
    "from azureml.core import Workspace, Experiment, Environment,ScriptRunConfig\n",
    "# from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DockerConfiguration,RunConfiguration\n",
    "\n",
    "#Remember the AML job has to have distribted setings (MPI type) for ray-on-aml to work correctly.\n",
    "ws = Workspace.from_config()\n",
    "compute_cluster = 'nc6s' #This can be another cluster different from the interactive cluster. \n",
    "ray_cluster = ComputeTarget(workspace=ws, name=compute_cluster)\n",
    "\n",
    "aml_run_config_ml = RunConfiguration(communicator='OpenMpi')\n",
    "docker_config = DockerConfiguration(use_docker=True, shm_size='24g')\n",
    "\n",
    "\n",
    "rayEnv = Environment.from_conda_specification(name = \"RLEnv\",\n",
    "                                             file_path = \"job/conda_env.yml\")\n",
    "rayEnv.docker.base_image = \"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20211221.v1\"\n",
    "\n",
    "aml_run_config_ml.target = ray_cluster\n",
    "aml_run_config_ml.node_count = 2\n",
    "aml_run_config_ml.environment = rayEnv\n",
    "aml_run_config_ml.docker =docker_config\n",
    "\n",
    "src = ScriptRunConfig(source_directory='../examples/job',\n",
    "                    script='aml_job.py',\n",
    "                    run_config = aml_run_config_ml,\n",
    "                   )\n",
    "\n",
    "run = Experiment(ws, \"rl_on_aml_job\").submit(src)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CLI v2 run this in a command line:\n",
    "az ml job create -f job/job.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bf611d01214d33a3a828f9dde8882d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/rl_on_aml_job_1671217927_1643ab06?wsid=/subscriptions/840b5c5c-3f4a-459a-94fc-6bad2a969f9d/resourcegroups/ml/workspaces/ws02ent&tid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9\", \"run_id\": \"rl_on_aml_job_1671217927_1643ab06\", \"run_properties\": {\"run_id\": \"rl_on_aml_job_1671217927_1643ab06\", \"created_utc\": \"2022-12-16T19:12:13.23571Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlctrain\", \"ContentSnapshotId\": \"f4bdca59-2e28-42f6-9c6e-6ed599c38396\", \"azureml.git.repository_uri\": \"https://github.com/microsoft/ray-on-aml.git\", \"mlflow.source.git.repoURL\": \"https://github.com/microsoft/ray-on-aml.git\", \"azureml.git.branch\": \"james-dev\", \"mlflow.source.git.branch\": \"james-dev\", \"azureml.git.commit\": \"ab73bd4758f7f7fabf86b2defaf4bb27115b10a6\", \"mlflow.source.git.commit\": \"ab73bd4758f7f7fabf86b2defaf4bb27115b10a6\", \"azureml.git.dirty\": \"True\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\", \"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"aml_job.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2022-12-16T19:49:55.104482Z\", \"status\": \"Failed\", \"log_files\": {\"azureml-logs/20_image_build_log.txt\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=sDewvYdU%2FVbXW4cvVEv1mWQIdYXDRt2PVJFHJQeno0A%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A02%3A14Z&ske=2022-12-18T03%3A12%3A14Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A45%3A23Z&se=2022-12-17T03%3A55%3A23Z&sp=r\", \"user_logs/mpi_log.txt\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/user_logs/mpi_log.txt?sv=2019-07-07&sr=b&sig=r6ZIJCABZtDOiUDt9VvHC6ul1k3f37RkGld7QonLa9M%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A02%3A14Z&ske=2022-12-18T03%3A12%3A14Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A19Z&se=2022-12-17T04%3A00%3A19Z&sp=r\", \"user_logs/std_log_process_0.txt\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/user_logs/std_log_process_0.txt?sv=2019-07-07&sr=b&sig=bHFSzSBhw%2FVtFHP1Ws3eEUvWdAMpSQWGUKc2a0TU%2BYI%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A02%3A14Z&ske=2022-12-18T03%3A12%3A14Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A19Z&se=2022-12-17T04%3A00%3A19Z&sp=r\", \"user_logs/std_log_process_1.txt\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/user_logs/std_log_process_1.txt?sv=2019-07-07&sr=b&sig=imVjh08Ncp8eQIiFwW70CQkvwSDKI5CCgLQTB4JvXNQ%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A02%3A14Z&ske=2022-12-18T03%3A12%3A14Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A19Z&se=2022-12-17T04%3A00%3A19Z&sp=r\", \"system_logs/cs_capability/0/cs-capability.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/cs_capability/0/cs-capability.log?sv=2019-07-07&sr=b&sig=uwq4f56YmwmAJ%2BIqZgOfcPrtkA3atjuct7wg4DUK91M%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/cs_capability/1/cs-capability.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/cs_capability/1/cs-capability.log?sv=2019-07-07&sr=b&sig=6WvP2UH1Gu32lPYl0reVa6N2bdzQUbErvltzRR41Viw%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/hosttools_capability/0/hosttools-capability.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/hosttools_capability/0/hosttools-capability.log?sv=2019-07-07&sr=b&sig=mhyA2JaBunBwKsEH2sfphP3UJdO5wKbgqesDcpU1hr8%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/hosttools_capability/1/hosttools-capability.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/hosttools_capability/1/hosttools-capability.log?sv=2019-07-07&sr=b&sig=PZPsvJp4IdRGCn7w%2BC4E29kigcjTJnC%2FkT4V1VtB23A%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/lifecycler/0/execution-wrapper.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/lifecycler/0/execution-wrapper.log?sv=2019-07-07&sr=b&sig=N%2Fo3WPDVAKxmgIMbIzmP5%2BdDmqFdJNkTBijGssFUf54%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/lifecycler/0/lifecycler.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/lifecycler/0/lifecycler.log?sv=2019-07-07&sr=b&sig=b4yxyxNyCVIxGnFJcO%2B1HnN96oFUMwiGgvnMrcN2rvE%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/lifecycler/0/mpi-execution-000.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/lifecycler/0/mpi-execution-000.log?sv=2019-07-07&sr=b&sig=4aVYJ3QANA5vXSkwXQ%2BeZ3CTrSiqfuaeEegQ5IVXNQQ%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/lifecycler/0/mpi_rsh_agent.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/lifecycler/0/mpi_rsh_agent.log?sv=2019-07-07&sr=b&sig=%2FnpgNd1dyxpUKcRwsIYUTigaffwz1qhNHE4DU8hQhdU%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/lifecycler/1/execution-wrapper.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/lifecycler/1/execution-wrapper.log?sv=2019-07-07&sr=b&sig=FmdiUmJcVZLFJaeZvwD7Qwud1xo2UC3EhbLc3e16Xf4%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/lifecycler/1/lifecycler.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/lifecycler/1/lifecycler.log?sv=2019-07-07&sr=b&sig=h4Z9ipWq%2BvmxBHNJ2MqIVyuWnRFpxKt7EjRcT15E5yA%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/lifecycler/1/mpi-execution-001.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/lifecycler/1/mpi-execution-001.log?sv=2019-07-07&sr=b&sig=Ke4cA6vr8LKYcj412%2BXNRxw5X4Pz%2FHrE6tXff4w%2BUmQ%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/lifecycler/1/mpi_orted_1.txt\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/lifecycler/1/mpi_orted_1.txt?sv=2019-07-07&sr=b&sig=n9qgz%2Fzc2jynYwj4wu1YrLticy3XXDplOOAaS40kBfM%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/metrics_capability/0/metrics-capability.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/metrics_capability/0/metrics-capability.log?sv=2019-07-07&sr=b&sig=gmIfYwa6qQIDTl3l%2F3E6mvOPog8KGxNis5IDMIJVwPU%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/metrics_capability/1/metrics-capability.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/metrics_capability/1/metrics-capability.log?sv=2019-07-07&sr=b&sig=5xoHbJ4chjz8mXZl5HyMo4HnuWcTfo6QKToKselmIYE%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/snapshot_capability/0/snapshot-capability.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/snapshot_capability/0/snapshot-capability.log?sv=2019-07-07&sr=b&sig=1%2F2DcTcx%2FmezzY57bZcuwFj8%2FZa1c4YecITcFQ9Fykg%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\", \"system_logs/snapshot_capability/1/snapshot-capability.log\": \"https://ws02ent2335216205.blob.core.windows.net/azureml/ExperimentRun/dcid.rl_on_aml_job_1671217927_1643ab06/system_logs/snapshot_capability/1/snapshot-capability.log?sv=2019-07-07&sr=b&sig=4LqomeZS%2FeZOkGMOBUJ4tH%2BW9vBTFfxwhgskltrsabM%3D&skoid=81676473-a897-4db4-bb45-76c568d9b702&sktid=0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9&skt=2022-12-16T19%3A39%3A49Z&ske=2022-12-18T03%3A49%3A49Z&sks=b&skv=2019-07-07&st=2022-12-16T19%3A50%3A20Z&se=2022-12-17T04%3A00%3A20Z&sp=r\"}, \"log_groups\": [[\"user_logs/mpi_log.txt\"], [\"user_logs/std_log_process_0.txt\", \"system_logs/cs_capability/0/cs-capability.log\", \"system_logs/hosttools_capability/0/hosttools-capability.log\", \"system_logs/lifecycler/0/execution-wrapper.log\", \"system_logs/lifecycler/0/lifecycler.log\", \"system_logs/lifecycler/0/mpi_rsh_agent.log\", \"system_logs/metrics_capability/0/metrics-capability.log\", \"system_logs/snapshot_capability/0/snapshot-capability.log\", \"system_logs/lifecycler/0/mpi-execution-000.log\"], [\"user_logs/std_log_process_1.txt\", \"system_logs/cs_capability/1/cs-capability.log\", \"system_logs/hosttools_capability/1/hosttools-capability.log\", \"system_logs/lifecycler/1/execution-wrapper.log\", \"system_logs/lifecycler/1/lifecycler.log\", \"system_logs/metrics_capability/1/metrics-capability.log\", \"system_logs/snapshot_capability/1/snapshot-capability.log\", \"system_logs/lifecycler/1/mpi-execution-001.log\", \"system_logs/lifecycler/1/mpi_orted_1.txt\"], [\"azureml-logs/20_image_build_log.txt\"]], \"run_duration\": \"0:37:41\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2022-12-16T19:49:38.001509Z  INFO mpi_rsh_agent: boot_telemetry_init\\n2022-12-16T19:49:38.001630Z  INFO telemetry: RUST_LOG env was not set, start log filtering from new dirs\\n2022-12-16T19:49:38.001752Z  INFO telemetry: [telemetry] telemetry_builder.build layer=\\\"file\\\" folder=\\\"/mnt/azureml/cr/j/7cf301cd2bf1485289cb72b7c4c4c425/cap/lifecycler/wd/.azureml_cr_log\\\" file=mpi_rsh_agent.log\\n2022-12-16T19:49:38.003383Z  INFO telemetry: [telemetry] telemetry_builder.build layer=\\\"appinsights\\\" instrumentation_key=\\\"c1e9008a-8df1-4b8c-acab-1f33e2ced73b\\\"\\n2022-12-16T19:49:38.003639Z  INFO telemetry: [telemetry] telemetry_builder.init_tracer\\n2022-12-16T19:49:38.003756Z  INFO telemetry: [telemetry] telemetry_builder.init_tracer.appinsights instrumentation_key=\\\"c1e9008a-8df1-4b8c-acab-1f33e2ced73b\\\"\\n2022-12-16T19:49:38.003846Z  WARN telemetry: No config defined for tracer collector_config=CollectorConfig { receiver: None, exporter: Some(ExporterConfig { appinsights: Some(AppinsightsExporterConfig { instrumentation_key: \\\"c1e9008a-8df1-4b8c-acab-1f33e2ced73b\\\" }), jaeger: None, prometheus: None, timeout_millis: None, level: None }) }\\n2022-12-16T19:49:38.003872Z  INFO telemetry: [init_telemetry()] Logging Initialized artifact_type=installed branch=origin/81054120cd828a2ec1414804c93d07c3ec6d5936 ci_number=20221212.2 ci_name=CommonRuntime-prod-build\\n[1,1]<stdout>:Process with rank 1 exited with code 1, more details can be found in 'user_logs/std_log_process_1.txt'.\\n--------------------------------------------------------------------------\\nPrimary job  terminated normally, but 1 process returned\\na non-zero exit code. Per user-direction, the job has been aborted.\\n--------------------------------------------------------------------------\\n[1,0]<stdout>:Process with rank 0 exited with code 1, more details can be found in 'user_logs/std_log_process_0.txt'.\\n--------------------------------------------------------------------------\\nmpirun detected that one or more processes exited with non-zero status, thus causing\\nthe job to be terminated. The first process to do so was:\\n\\n  Process name: [[1055,1],1]\\n  Exit code:    1\\n--------------------------------------------------------------------------\\n\\nError occurred: {\\n  \\\"code\\\": \\\"ExecutionFailed\\\",\\n  \\\"category\\\": \\\"UserError\\\",\\n  \\\"message\\\": {\\n    \\\"NonCompliant\\\": \\\"Process 'mpirun' exited with code 1 and error message 'Execution failed. Process exited with status code 1. Error: 2022-12-16T19:49:38.001630Z  INFO telemetry: RUST_LOG env was not set, start log filtering from new dirs\\\\n2022-12-16T19:49:38.001752Z  INFO telemetry: [telemetry] telemetry_builder.build layer=\\\\\\\"file\\\\\\\" folder=\\\\\\\"/mnt/azureml/cr/j/7cf301cd2bf1485289cb72b7c4c4c425/cap/lifecycler/wd/.azureml_cr_log\\\\\\\" file=mpi_rsh_agent.log\\\\n2022-12-16T19:49:38.003383Z  INFO telemetry: [telemetry] telemetry_builder.build layer=\\\\\\\"appinsights\\\\\\\" instrumentation_key=\\\\\\\"c1e9008a-8df1-4b8c-acab-1f33e2ced73b\\\\\\\"\\\\n2022-12-16T19:49:38.003639Z  INFO telemetry: [telemetry] telemetry_builder.init_tracer\\\\n2022-12-16T19:49:38.003756Z  INFO telemetry: [telemetry] telemetry_builder.init_tracer.appinsights instrumentation_key=\\\\\\\"c1e9008a-8df1-4b8c-acab-1f33e2ced73b\\\\\\\"\\\\n2022-12-16T19:49:38.003846Z  WARN telemetry: No config defined for tracer collector_config=CollectorConfig { receiver: None, exporter: Some(ExporterConfig { appinsights: Some(AppinsightsExporterConfig { instrumentation_key: \\\\\\\"c1e9008a-8df1-4b8c-acab-1f33e2ced73b\\\\\\\" }), jaeger: None, prometheus: None, timeout_millis: None, level: None }) }\\\\n2022-12-16T19:49:38.003872Z  INFO telemetry: [init_telemetry()] Logging Initialized artifact_type=installed branch=origin/81054120cd828a2ec1414804c93d07c3ec6d5936 ci_number=20221212.2 ci_name=CommonRuntime-prod-build\\\\n[1,1]<stdout>:Process with rank 1 exited with code 1, more details can be found in 'user_logs/std_log_process_1.txt'.\\\\n--------------------------------------------------------------------------\\\\nPrimary job  terminated normally, but 1 process returned\\\\na non-zero exit code. Per user-direction, the job has been aborted.\\\\n--------------------------------------------------------------------------\\\\n[1,0]<stdout>:Process with rank 0 exited with code 1, more details can be found in 'user_logs/std_log_process_0.txt'.\\\\n--------------------------------------------------------------------------\\\\nmpirun detected that one or more processes exited with non-zero status, thus causing\\\\nthe job to be terminated. The first process to do so was:\\\\n\\\\n  Process name: [[1055,1],1]\\\\n  Exit code:    1\\\\n--------------------------------------------------------------------------\\\\n'. Please check the log file 'user_logs/mpi_log.txt' for more details.\\\"\\n  },\\n  \\\"details\\\": [\\n    {\\n      \\\"name\\\": \\\"exit_codes\\\",\\n      \\\"value\\\": {\\n        \\\"Literal\\\": {\\n          \\\"Compliant\\\": \\\"1\\\"\\n        }\\n      }\\n    }\\n  ],\\n  \\\"error\\\": null,\\n  \\\"node_info\\\": null\\n}\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.43.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.cancel()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "dlresearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8858a4df92b06e9052bc306608e3218c33233584bc6448961c72d65ba55843de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
