{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Quick examples to demostrate AML Ray/Dask cluster usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive use cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade ray-on-aml pandas pyarrow xgboost xgboost_ray==0.1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1639183943936
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Environment,ScriptRunConfig\n",
    "# from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.environment import Environment\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please make sure to create compute cluster in the same vnet with your compute instance. You need to have vnet, otherwise compute cannot communicate with each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1639185778952
    }
   },
   "outputs": [
    {
     "ename": "UserErrorException",
     "evalue": "UserErrorException:\n\tMessage: You are currently logged-in to 0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9 tenant. You don't have access to 0e9bace8-7a81-4922-83b5-d995ff706507 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \n [SubscriptionInfo(subscription_name=\"James Nguyen's Research and Demo Subscription\", subscription_id='840b5c5c-3f4a-459a-94fc-6bad2a969f9d')]. \n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"You are currently logged-in to 0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9 tenant. You don't have access to 0e9bace8-7a81-4922-83b5-d995ff706507 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \\n [SubscriptionInfo(subscription_name=\\\"James Nguyen's Research and Demo Subscription\\\", subscription_id='840b5c5c-3f4a-459a-94fc-6bad2a969f9d')]. \\n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUserErrorException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray_on_aml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ray_On_AML\n\u001b[0;32m----> 3\u001b[0m ws \u001b[38;5;241m=\u001b[39m \u001b[43mWorkspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"d15-v2\",additional_pip_packages=['torch==1.10.0', 'torchvision', 'sklearn','xgboost_ray==0.1.6'], maxnode=2,exp_name='ray-on-aml-test')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m ray_on_aml \u001b[38;5;241m=\u001b[39mRay_On_AML(ws\u001b[38;5;241m=\u001b[39mws, compute_cluster \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md13\u001b[39m\u001b[38;5;124m\"\u001b[39m, maxnode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/workspace.py:292\u001b[0m, in \u001b[0;36mWorkspace.from_config\u001b[0;34m(path, auth, _logger, _file_name)\u001b[0m\n\u001b[1;32m    288\u001b[0m subscription_id, resource_group, workspace_name \u001b[38;5;241m=\u001b[39m project_info\u001b[38;5;241m.\u001b[39mget_workspace_info(\n\u001b[1;32m    289\u001b[0m     found_path)\n\u001b[1;32m    291\u001b[0m _logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound the config file in: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, found_path)\n\u001b[0;32m--> 292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWorkspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_group\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/workspace.py:607\u001b[0m, in \u001b[0;36mWorkspace.get\u001b[0;34m(name, auth, subscription_id, resource_group, location, cloud, id)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m auth:\n\u001b[1;32m    605\u001b[0m     auth \u001b[38;5;241m=\u001b[39m InteractiveLoginAuthentication()\n\u001b[0;32m--> 607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mWorkspace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_cloud\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcloud\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_workspace_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/workspace.py:205\u001b[0m, in \u001b[0;36mWorkspace.__init__\u001b[0;34m(self, subscription_id, resource_group, workspace_name, auth, _location, _disable_service_check, _workspace_id, sku, tags, _cloud)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workspace_autorest_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _disable_service_check:\n\u001b[0;32m--> 205\u001b[0m     auto_rest_workspace \u001b[38;5;241m=\u001b[39m \u001b[43m_commands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_workspace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkspace_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_cloud\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_workspace_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workspace_autorest_object \u001b[38;5;241m=\u001b[39m auto_rest_workspace\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_service_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_project/_commands.py:466\u001b[0m, in \u001b[0;36mget_workspace\u001b[0;34m(auth, subscription_id, resource_group_name, workspace_name, location, cloud, workspace_id)\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 466\u001b[0m         workspaces \u001b[38;5;241m=\u001b[39m \u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_service_client\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m            \u001b[49m\u001b[43mAzureMachineLearningWorkspaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mworkspaces\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m WorkspacesOperations\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    470\u001b[0m             workspaces,\n\u001b[1;32m    471\u001b[0m             resource_group_name,\n\u001b[1;32m    472\u001b[0m             workspace_name)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ClientRequestError:\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;66;03m# this most likely is because of failure to talk to arm.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m         \u001b[38;5;66;03m# Provide error message to user if they are in synapse enviroment.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;66;03m# Additional params will enable aml dataplane get workspace call. \u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/authentication.py:230\u001b[0m, in \u001b[0;36mAbstractAuthentication._get_service_client\u001b[0;34m(self, client_class, subscription_id, subscription_bound, base_url, is_check_subscription)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subscription_id \u001b[38;5;129;01mand\u001b[39;00m is_check_subscription:\n\u001b[1;32m    229\u001b[0m     all_subscription_list, tenant_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_all_subscription_ids()\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_if_subscription_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_subscription_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m base_url:\n\u001b[1;32m    233\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cloud_type\u001b[38;5;241m.\u001b[39mendpoints\u001b[38;5;241m.\u001b[39mresource_manager\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/authentication.py:681\u001b[0m, in \u001b[0;36mInteractiveLoginAuthentication._check_if_subscription_exists\u001b[0;34m(self, subscription_id, subscription_id_list, tenant_id)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_if_subscription_exists\u001b[39m(\u001b[38;5;28mself\u001b[39m, subscription_id, subscription_id_list, tenant_id):\n\u001b[0;32m--> 681\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mInteractiveLoginAuthentication\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_if_subscription_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubscription_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                                                                              \u001b[49m\u001b[43msubscription_id_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtenant_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/authentication.py:338\u001b[0m, in \u001b[0;36mAbstractAuthentication._check_if_subscription_exists\u001b[0;34m(self, subscription_id, subscription_id_list, tenant_id)\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserErrorException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt looks like you have specified subscription name, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, instead of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubscription id. Subscription names may not be unique, please specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    335\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubscription id from this list \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(subscription_id,\n\u001b[1;32m    336\u001b[0m                                                                            subscription_id_list))\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UserErrorException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are currently logged-in to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m tenant. You don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have access \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    339\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m subscription, please check if it is in this tenant. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    340\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll the subscriptions that you have access to in this tenant are = \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Please refer to aka.ms/aml-notebook-auth for different \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthentication mechanisms in azureml-sdk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tenant_id,\n\u001b[1;32m    343\u001b[0m                                                                                 subscription_id,\n\u001b[1;32m    344\u001b[0m                                                                                 subscription_id_list))\n",
      "\u001b[0;31mUserErrorException\u001b[0m: UserErrorException:\n\tMessage: You are currently logged-in to 0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9 tenant. You don't have access to 0e9bace8-7a81-4922-83b5-d995ff706507 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \n [SubscriptionInfo(subscription_name=\"James Nguyen's Research and Demo Subscription\", subscription_id='840b5c5c-3f4a-459a-94fc-6bad2a969f9d')]. \n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"You are currently logged-in to 0fbe7234-45ea-498b-b7e4-1a8b2d3be4d9 tenant. You don't have access to 0e9bace8-7a81-4922-83b5-d995ff706507 subscription, please check if it is in this tenant. All the subscriptions that you have access to in this tenant are = \\n [SubscriptionInfo(subscription_name=\\\"James Nguyen's Research and Demo Subscription\\\", subscription_id='840b5c5c-3f4a-459a-94fc-6bad2a969f9d')]. \\n Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from ray_on_aml.core import Ray_On_AML\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "# ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"d15-v2\",additional_pip_packages=['torch==1.10.0', 'torchvision', 'sklearn','xgboost_ray==0.1.6'], maxnode=2,exp_name='ray-on-aml-test')\n",
    "\n",
    "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"d13\", maxnode=2)\n",
    "ray = ray_on_aml.getRay()\n",
    "# Note that by default, ci_is_head=True which means  compute instance as head node and all nodes in the remote compute cluster as workers \n",
    "# But if you want to use one of the nodes in the remote AML compute cluster is used as head node and the remaining are worker nodes.\n",
    "# then simply specify ray = ray_on_aml.getRay(ci_is_head=False)\n",
    "# To install additional library, use additional_pip_packages and additional_conda_packages parameters.\n",
    "time.sleep(50)\n",
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dask on Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can use Dask on this Ray cluster by telling Dask to use Ray as the scheduler. By doing this, you will have a cluster with both Dask and Ray without having to setup them saperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639183635290
    }
   },
   "outputs": [],
   "source": [
    "#Scaling up date with Dask dataframe API.\n",
    "#Please make sure you have pandas version 1.4+ and restart to run this successfully.\n",
    "# pip install pandas==1.4.2\n",
    "import dask\n",
    "from ray.util.dask import ray_dask_get,enable_dask_on_ray\n",
    "enable_dask_on_ray()\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "storage_options = {'account_name': 'azureopendatastorage'}\n",
    "ddf = dd.read_parquet('az://nyctlc/green/puYear=2015/puMonth=*/*.parquet', storage_options=storage_options)\n",
    "ddf.count().compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639186778862
    }
   },
   "outputs": [],
   "source": [
    "#Ray also support Ray dataset. You can read into ray dataset then convert to Dask or other ML format which is convenient for ML training.https://docs.ray.io/en/latest/data/dataset.html\n",
    "# you may need to upgrade pyarrow to run this successfully\n",
    "from adlfs import AzureBlobFileSystem\n",
    "\n",
    "abfs = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
    "#if read all years and months\n",
    "# data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather//\", filesystem=abfs)\n",
    "data =ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2015/\"], filesystem=abfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()\n",
    "# 1,584,481,119 is the count for all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "#convert Ray dataset to Dask dataframe \n",
    "result = data.to_dask().describe().compute()\n",
    "print(result)\n",
    "stop = time.time()\n",
    "print(\"duration \", (stop-start))\n",
    "#717s for single machine nc6\n",
    "# duration  307.69699811935425s for CI as head and 4 workers of DS14_v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ray Tune for distributed ML tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639186714110
    }
   },
   "outputs": [],
   "source": [
    " import sklearn.datasets\n",
    " import sklearn.metrics\n",
    " from sklearn.model_selection import train_test_split\n",
    " import xgboost as xgb\n",
    "\n",
    " from ray import tune\n",
    "\n",
    "\n",
    " def train_breast_cancer(config):\n",
    "     # Load dataset\n",
    "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "     # Split into train and test set\n",
    "     train_x, test_x, train_y, test_y = train_test_split(\n",
    "         data, labels, test_size=0.25)\n",
    "     # Build input matrices for XGBoost\n",
    "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
    "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
    "     # Train the classifier\n",
    "     results = {}\n",
    "     xgb.train(\n",
    "         config,\n",
    "         train_set,\n",
    "         evals=[(test_set, \"eval\")],\n",
    "         evals_result=results,\n",
    "         verbose_eval=False)\n",
    "     # Return prediction accuracy\n",
    "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
    "     tune.report(mean_accuracy=accuracy, done=True)\n",
    "\n",
    "\n",
    " config = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"eval_metric\": [\"logloss\", \"error\"],\n",
    "     \"max_depth\": tune.randint(1, 9),\n",
    "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
    "     \"subsample\": tune.uniform(0.5, 1.0),\n",
    "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
    " }\n",
    " analysis = tune.run(\n",
    "     train_breast_cancer,\n",
    "     resources_per_trial={\"cpu\": 1},\n",
    "     config=config,\n",
    "     num_samples=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distributed XGBoost https://docs.ray.io/en/latest/xgboost-ray.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost_ray import RayXGBClassifier, RayParams\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "clf = RayXGBClassifier(\n",
    "    n_jobs=10,  # In XGBoost-Ray, n_jobs sets the number of actors\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# scikit-learn API will automatically conver the data\n",
    "# to RayDMatrix format as needed.\n",
    "# You can also pass X as a RayDMatrix, in which case\n",
    "# y will be ignored.\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred_ray = clf.predict(X_test)\n",
    "print(pred_ray.shape)\n",
    "\n",
    "pred_proba_ray = clf.predict_proba(X_test)\n",
    "print(pred_proba_ray.shape)\n",
    "\n",
    "# It is also possible to pass a RayParams object\n",
    "# to fit/predict/predict_proba methods - will override\n",
    "# n_jobs set during initialization\n",
    "\n",
    "clf.fit(X_train, y_train, ray_params=RayParams(num_actors=10))\n",
    "\n",
    "pred_ray = clf.predict(X_test, ray_params=RayParams(num_actors=10))\n",
    "print(pred_ray.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "train_x, train_y = load_breast_cancer(return_X_y=True)\n",
    "train_set = RayDMatrix(train_x, train_y)\n",
    "\n",
    "evals_result = {}\n",
    "bst = train(\n",
    "    {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    },\n",
    "    train_set,\n",
    "    evals_result=evals_result,\n",
    "    evals=[(train_set, \"train\")],\n",
    "    verbose_eval=False,\n",
    "    ray_params=RayParams(\n",
    "        num_actors=10,  # Number of remote actors\n",
    "        cpus_per_actor=1))\n",
    "\n",
    "bst.save_model(\"model.xgb\")\n",
    "print(\"Final training error: {:.4f}\".format(\n",
    "    evals_result[\"train\"][\"error\"][-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install library at compute instance: pip install gym,dm-tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install additional library at Ray cluster\n",
    "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"d15-v2\",additional_pip_packages=['torch==1.10.0', 'torchvision', 'sklearn', 'pyspark','gym==0.2.1','dm-tree','scikit-image','opencv-python','tensorflow'], maxnode=1)\n",
    "ray = ray_on_aml.getRay()\n",
    "time.sleep(20)\n",
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RL algorithm (Trainer) we would like to use.\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "\n",
    "# Configure the algorithm.\n",
    "config = {\n",
    "    # Environment (RLlib understands openAI gym registered strings).\n",
    "    \"env\": \"Taxi-v3\",\n",
    "    # Use 2 environment workers (aka \"rollout workers\") that parallelly\n",
    "    # collect samples from their own environment clone(s).\n",
    "    \"num_workers\": 2,\n",
    "    # Change this to \"framework: torch\", if you are using PyTorch.\n",
    "    # Also, use \"framework: tf2\" for tf2.x eager execution.\n",
    "    \"framework\": \"torch\",\n",
    "    # Tweak the default model provided automatically by RLlib,\n",
    "    # given the environment's observation- and action spaces.\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [64, 64],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "    },\n",
    "    # Set up a separate evaluation worker set for the\n",
    "    # `trainer.evaluate()` call after training (see below).\n",
    "    \"evaluation_num_workers\": 1,\n",
    "    # Only for evaluation runs, render the env.\n",
    "    \"evaluation_config\": {\n",
    "        \"render_env\": True,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create our RLlib Trainer.\n",
    "trainer = PPOTrainer(config=config)\n",
    "\n",
    "# Run it for n training iterations. A training iteration includes\n",
    "# parallel sample collection by the environment workers as well as\n",
    "# loss calculation on the collected batch and a model update.\n",
    "for _ in range(3):\n",
    "    print(trainer.train())\n",
    "\n",
    "# Evaluate the trained Trainer (and render each timestep to the shell's\n",
    "# output).\n",
    "trainer.evaluate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutdown interactive cluster when not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_on_aml.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray on Job Cluster with GPU (you don't need interactive Ray cluster to be on to submit the AML job )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1639179342786
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Environment,ScriptRunConfig\n",
    "# from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DockerConfiguration,RunConfiguration\n",
    "\n",
    "#Remember the AML job has to have distribted setings (MPI type) for ray-on-aml to work correctly.\n",
    "ws = Workspace.from_config()\n",
    "compute_cluster = 'gpunc6' #This can be another cluster different from the interactive cluster. \n",
    "ray_cluster = ComputeTarget(workspace=ws, name=compute_cluster)\n",
    "\n",
    "aml_run_config_ml = RunConfiguration(communicator='OpenMpi')\n",
    "docker_config = DockerConfiguration(use_docker=True, shm_size='48gb')\n",
    "\n",
    "\n",
    "rayEnv = Environment.from_conda_specification(name = \"RLEnv\",\n",
    "                                             file_path = \"conda_env.yml\")\n",
    "rayEnv.docker.base_image = \"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.1-cudnn8-ubuntu18.04:20220329.v1\"\n",
    "\n",
    "aml_run_config_ml.target = ray_cluster\n",
    "aml_run_config_ml.node_count = 2\n",
    "aml_run_config_ml.environment = rayEnv\n",
    "aml_run_config_ml.docker =docker_config\n",
    "\n",
    "src = ScriptRunConfig(source_directory='../examples/job',\n",
    "                    script='aml_job.py',\n",
    "                    run_config = aml_run_config_ml,\n",
    "                   )\n",
    "\n",
    "run = Experiment(ws, \"rl_on_aml_job\").submit(src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "run.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8858a4df92b06e9052bc306608e3218c33233584bc6448961c72d65ba55843de"
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
