{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Interactive use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade ray-on-aml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1639183943936
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "# from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import platform\n",
    "import sys\n",
    "# sys.path.append(\"../\") # go to parent dir\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1639185778952
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank returned is  None\n",
      "rank returned is  None\n",
      "azureml_py38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 23:51:22,372\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 23:51:38,353\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 10.0.0.13:6379\n",
      "2021-12-14 23:51:38,486\tWARNING worker.py:1219 -- The autoscaler failed with the following error:\n",
      "Terminated with signal 15\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 543, in <module>\n",
      "    monitor.run()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 439, in run\n",
      "    self._run()\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/autoscaler/_private/monitor.py\", line 346, in _run\n",
      "    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting: Cluster status is in  Queued\n",
      "Waiting: Cluster status is in  Queued\n",
      "Waiting: Cluster status is in  Queued\n",
      "Waiting: Cluster status is in  Queued\n"
     ]
    }
   ],
   "source": [
    "#You can pre-provision \"worker-cpu-v3\" in the same vnet with your compute instance\n",
    "from ray_on_aml.core import Ray_On_AML\n",
    "ws = Workspace.from_config()\n",
    "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"worker-cpu-v3\", additional_pip_packages=['torch==1.10.0'])\n",
    "_, ray = ray_on_aml.getRay()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1639186321954
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CPU': 26.0,\n",
       " 'node:10.0.0.21': 1.0,\n",
       " 'object_store_memory': 37732648548.0,\n",
       " 'memory': 82534642896.0,\n",
       " 'node:10.0.0.18': 1.0,\n",
       " 'node:10.0.0.20': 1.0,\n",
       " 'node:10.0.0.17': 1.0,\n",
       " 'node:10.0.0.22': 1.0,\n",
       " 'GPU': 1.0,\n",
       " 'accelerator_type:K80': 1.0,\n",
       " 'node:10.0.0.13': 1.0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask on Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "gather": {
     "logged": 1639183635290
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 05:32:12,050\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n",
      "2021-12-13 05:32:12,054\tWARNING services.py:1816 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 5310255104 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=10.24gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4318.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6895.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9895</th>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9915</th>\n",
       "      <td>7781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9951</th>\n",
       "      <td>7748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9969</th>\n",
       "      <td>3398.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>5400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>976 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade\n",
       "age         \n",
       "6     4318.0\n",
       "45     885.0\n",
       "46    6405.0\n",
       "77    6895.0\n",
       "81    8404.0\n",
       "...      ...\n",
       "9895  8000.0\n",
       "9915  7781.0\n",
       "9951  7748.0\n",
       "9969  3398.0\n",
       "9992  5400.0\n",
       "\n",
       "[976 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "ray.init()\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dask.config.set(scheduler=ray_dask_get)\n",
    "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
    "\n",
    "# The Dask scheduler submits the underlying task graph to Ray.\n",
    "d_arr.mean().compute(scheduler=ray_dask_get)\n",
    "\n",
    "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
    "# specify it on each compute call.\n",
    "\n",
    "df = dd.from_pandas(\n",
    "    pd.DataFrame(\n",
    "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
    "    npartitions=2)\n",
    "df.groupby([\"age\"]).mean().compute()\n",
    "\n",
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "gather": {
     "logged": 1639186778862
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:09<00:00,  1.64it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:05<00:00,  3.12it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.28it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.35it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:05<00:00,  3.07it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:04<00:00,  3.42it/s]\n"
     ]
    }
   ],
   "source": [
    "#dask\n",
    "\n",
    "# import ray\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Model\n",
    "from adlfs import AzureBlobFileSystem\n",
    "# account_key = ws.get_default_keyvault().get_secret(\"adls7-account-key\")\n",
    "# account_name=\"adlsgen7\"\n",
    "# abfs = AzureBlobFileSystem(account_name=\"adlsgen7\",account_key=account_key,  container_name=\"mltraining\")\n",
    "abfs2 = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
    "\n",
    "\n",
    "storage_options={'account_name': account_name, 'account_key': account_key}\n",
    "\n",
    "# ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year2008', storage_options=storage_options)\n",
    "\n",
    "data = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2012/\"], filesystem=abfs2)\n",
    "data1 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2015/\"], filesystem=abfs2)\n",
    "data2 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2010/\"], filesystem=abfs2)\n",
    "data3 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2009/\"], filesystem=abfs2)\n",
    "data4 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2011/\"], filesystem=abfs2)\n",
    "data5 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2013/\"], filesystem=abfs2)\n",
    "data6 = ray.data.read_parquet([\"az://isdweatherdatacontainer/ISDWeather/year=2014/\"], filesystem=abfs2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690211698"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data =data.union(data1).union(data2).union(data3).union(data4).union(data5).union(data6)\n",
    "all_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:('quantiles-1-d7cd6e40aa11b038fe5ca5a773d25ac8', 298) pid=906, ip=10.0.0.22)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:('from-delayed-37bcded3107f2c11146104d14a59d0ad', 368) pid=80603)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:('quantiles-1-6e697189017d81f71030f5e8bf0ee8a2', 189) pid=263, ip=10.0.0.22)\u001b[0m \n",
      "\u001b[2m\u001b[36m(dask:('quantiles-1-040e133c45167fb786e4c5b3a28faf1c', 66) pid=905, ip=10.0.0.22)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:block_to_df-c2e390a0-5836-4fea-82e3-19ef23ae7d25 pid=198, ip=10.0.0.22)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:('dropna-ba9cf0277682a5953a58639127dd84bd', 192) pid=2029, ip=10.0.0.20)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:('dataframe-count-chunk-794783190c86b2d3594773c9ffe513ce', 0, 186, 0) pid=195, ip=10.0.0.20)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:('quantiles-1-046f250e7af81064a522328b34088f5b', 410) pid=29527, ip=10.0.0.20)\u001b[0m \n",
      "\u001b[2m\u001b[36m(dask:('dropna-d24804d88d961fea6af2f5601cea6261', 493) pid=2574, ip=10.0.0.17)\u001b[0m \n",
      "\u001b[2m\u001b[36m(dask:('dropna-8598322c3d00cd5ed4009f78d212d981', 303) pid=2574, ip=10.0.0.17)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:('from-delayed-37bcded3107f2c11146104d14a59d0ad', 429) pid=374, ip=10.0.0.17)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:('quantiles-1-24c4de00c62d75056557559435285835', 561) pid=2574, ip=10.0.0.17)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(dask:('dropna-d4e810db3c5e478a2250add67fbce6c8', 506) pid=200, ip=10.0.0.17)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           latitude     longitude     elevation     windAngle     windSpeed  \\\n",
      "count  6.902117e+08  6.902117e+08  6.902117e+08  5.414428e+08  5.624939e+08   \n",
      "mean   3.796754e+01 -4.137369e+01  4.173534e+02  1.642972e+02  3.452701e+00   \n",
      "std    2.068093e+01  7.837449e+01  6.445339e+02  1.146524e+02  2.888769e+00   \n",
      "min   -9.000000e+01 -1.799830e+02 -3.500000e+02  0.000000e+00  0.000000e+00   \n",
      "25%    3.395600e+01 -9.571000e+01  5.000000e+01  8.000000e+01  2.000000e+00   \n",
      "50%    4.155400e+01 -7.619200e+01  2.100000e+02  1.900000e+02  3.100000e+00   \n",
      "75%    4.918300e+01  1.668300e+01  5.500000e+02  2.800000e+02  5.700000e+00   \n",
      "max    8.733300e+01  9.999990e+02  9.999000e+03  3.600000e+02  9.000000e+01   \n",
      "\n",
      "        temperature  seaLvlPressure  presentWeatherIndicator  \\\n",
      "count  6.779744e+08    2.284912e+08             6.001119e+07   \n",
      "mean   1.185499e+01    1.014672e+03             2.821610e+01   \n",
      "std    1.247398e+01    9.456261e+00             2.883805e+01   \n",
      "min   -8.860000e+01    8.727000e+02             0.000000e+00   \n",
      "25%    8.700000e+00    1.011600e+03             1.000000e+01   \n",
      "50%    1.610000e+01    1.017200e+03             1.300000e+01   \n",
      "75%    2.780000e+01    1.026000e+03             6.100000e+01   \n",
      "max    6.120000e+01    1.090000e+03             9.900000e+01   \n",
      "\n",
      "       pastWeatherIndicator    precipTime   precipDepth     snowDepth  \\\n",
      "count          2.584350e+07  1.329948e+08  1.329948e+08  3.270731e+06   \n",
      "mean           4.273148e+00  5.674848e+00  2.966430e+02  2.157168e+01   \n",
      "std            2.998129e+00  8.696258e+00  1.669186e+03  3.609434e+01   \n",
      "min            0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%            2.000000e+00  1.000000e+00  0.000000e+00  3.000000e+00   \n",
      "50%            6.000000e+00  1.000000e+00  0.000000e+00  2.000000e+01   \n",
      "75%            8.000000e+00  6.000000e+00  7.000000e+00  6.500000e+01   \n",
      "max            9.000000e+00  9.900000e+01  9.999000e+03  9.980000e+02   \n",
      "\n",
      "               year           day      version         month  \n",
      "count  6.902117e+08  6.902117e+08  690211698.0  6.902117e+08  \n",
      "mean   2.012449e+03  1.572335e+01          1.0  6.565310e+00  \n",
      "std    1.912755e+00  8.809711e+00          0.0  3.461218e+00  \n",
      "min    2.009000e+03  1.000000e+00          1.0  1.000000e+00  \n",
      "25%    2.011000e+03  8.000000e+00          1.0  4.000000e+00  \n",
      "50%    2.013000e+03  1.600000e+01          1.0  7.000000e+00  \n",
      "75%    2.014000e+03  2.400000e+01          1.0  1.000000e+01  \n",
      "max    2.015000e+03  3.100000e+01          1.0  1.200000e+01  \n",
      "duration  1361.3095450401306\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#convert Ray dataset to Dask dataframe \n",
    "all_data_dask = all_data.to_dask().describe().compute()\n",
    "print(all_data_dask)\n",
    "stop = time.time()\n",
    "print(\"duration \", (stop-start))\n",
    "#717s for single machine nc6\n",
    "#duration  1854.3798034191132 cluster 1st time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray Tune for distributed ML tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "gather": {
     "logged": 1639186335816
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "# import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # In this example, we don't change the model architecture\n",
    "        # due to simplicity.\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "# Change these values if you want the training to run quicker or slower.\n",
    "EPOCH_SIZE = 512\n",
    "TEST_SIZE = 256\n",
    "\n",
    "def train(model, optimizer, train_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # We set this just for the example to run quickly.\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "            return\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # We set this just for the example to run quickly.\n",
    "            if batch_idx * len(data) > TEST_SIZE:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "def train_mnist(config):\n",
    "    # Data Setup\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = ConvNet()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "    for i in range(10):\n",
    "        train(model, optimizer, train_loader)\n",
    "        acc = test(model, test_loader)\n",
    "\n",
    "        # Send the current training result back to Tune\n",
    "        tune.report(mean_accuracy=acc)\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            # This saves the model to the trial directory\n",
    "            torch.save(model.state_dict(), \"./model.pth\")\n",
    "search_space = {\n",
    "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
    "    \"momentum\": tune.uniform(0.01, 0.09)\n",
    "}\n",
    "\n",
    "# Uncomment this to enable distributed execution\n",
    "# ray.shutdown()\n",
    "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
    "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
    "# Download the dataset first\n",
    "datasets.MNIST(\"~/data\", train=True, download=True)\n",
    "\n",
    "analysis = tune.run(train_mnist, config=search_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1639186714110
    }
   },
   "outputs": [],
   "source": [
    " import sklearn.datasets\n",
    " import sklearn.metrics\n",
    " from sklearn.model_selection import train_test_split\n",
    " import xgboost as xgb\n",
    "\n",
    " from ray import tune\n",
    "\n",
    "\n",
    " def train_breast_cancer(config):\n",
    "     # Load dataset\n",
    "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "     # Split into train and test set\n",
    "     train_x, test_x, train_y, test_y = train_test_split(\n",
    "         data, labels, test_size=0.25)\n",
    "     # Build input matrices for XGBoost\n",
    "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
    "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
    "     # Train the classifier\n",
    "     results = {}\n",
    "     xgb.train(\n",
    "         config,\n",
    "         train_set,\n",
    "         evals=[(test_set, \"eval\")],\n",
    "         evals_result=results,\n",
    "         verbose_eval=False)\n",
    "     # Return prediction accuracy\n",
    "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
    "     tune.report(mean_accuracy=accuracy, done=True)\n",
    "\n",
    "\n",
    " config = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"eval_metric\": [\"logloss\", \"error\"],\n",
    "     \"max_depth\": tune.randint(1, 9),\n",
    "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
    "     \"subsample\": tune.uniform(0.5, 1.0),\n",
    "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
    " }\n",
    " analysis = tune.run(\n",
    "     train_breast_cancer,\n",
    "     resources_per_trial={\"cpu\": 1},\n",
    "     config=config,\n",
    "     num_samples=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed XGBoost https://docs.ray.io/en/latest/xgboost-ray.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost_ray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 00:02:37,433\tINFO main.py:971 -- [RayXGBoost] Created 10 new actors (10 total actors). Waiting until actors are ready for training.\n",
      "2021-12-15 00:02:39,774\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=19133)\u001b[0m [00:02:39] task [xgboost.ray]:140672750021792 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=19223)\u001b[0m [00:02:39] task [xgboost.ray]:140510980246064 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=582, ip=10.0.0.17)\u001b[0m [00:02:39] task [xgboost.ray]:139840916503568 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=736, ip=10.0.0.18)\u001b[0m [00:02:40] task [xgboost.ray]:140534154546144 got new rank 4\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=737, ip=10.0.0.18)\u001b[0m [00:02:39] task [xgboost.ray]:140264658713568 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=643, ip=10.0.0.20)\u001b[0m [00:02:40] task [xgboost.ray]:140177723526160 got new rank 5\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=642, ip=10.0.0.20)\u001b[0m [00:02:40] task [xgboost.ray]:140138270759952 got new rank 6\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=612, ip=10.0.0.21)\u001b[0m [00:02:40] task [xgboost.ray]:140231251999760 got new rank 7\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=740, ip=10.0.0.22)\u001b[0m [00:02:40] task [xgboost.ray]:140457813146640 got new rank 8\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=739, ip=10.0.0.22)\u001b[0m [00:02:40] task [xgboost.ray]:140115865205776 got new rank 9\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=19133)\u001b[0m [00:02:40] WARNING: /mnt/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=19223)\u001b[0m [00:02:40] WARNING: /mnt/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=739, ip=10.0.0.22)\u001b[0m [00:02:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=736, ip=10.0.0.18)\u001b[0m [00:02:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=737, ip=10.0.0.18)\u001b[0m [00:02:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=582, ip=10.0.0.17)\u001b[0m [00:02:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=612, ip=10.0.0.21)\u001b[0m [00:02:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=643, ip=10.0.0.20)\u001b[0m [00:02:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=642, ip=10.0.0.20)\u001b[0m [00:02:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=740, ip=10.0.0.22)\u001b[0m [00:02:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-12-15 00:02:53,489\tINFO main.py:1495 -- [RayXGBoost] Finished XGBoost training on training data with total N=142 in 16.80 seconds (13.71 pure XGBoost training time).\n",
      "2021-12-15 00:02:53,510\tINFO main.py:1535 -- [RayXGBoost] Created 10 remote actors.\n",
      "2021-12-15 00:02:55,814\tINFO main.py:1552 -- [RayXGBoost] Starting XGBoost prediction.\n",
      "2021-12-15 00:02:55,891\tINFO main.py:1535 -- [RayXGBoost] Created 10 remote actors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 00:02:58,173\tINFO main.py:1552 -- [RayXGBoost] Starting XGBoost prediction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 00:02:58,935\tINFO main.py:971 -- [RayXGBoost] Created 10 new actors (10 total actors). Waiting until actors are ready for training.\n",
      "2021-12-15 00:03:01,175\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=19735)\u001b[0m [00:03:01] task [xgboost.ray]:140123512409152 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=19827)\u001b[0m [00:03:01] task [xgboost.ray]:140234076301920 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=19826)\u001b[0m [00:03:01] task [xgboost.ray]:140698420431408 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=704, ip=10.0.0.17)\u001b[0m [00:03:01] task [xgboost.ray]:140432323750928 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=705, ip=10.0.0.17)\u001b[0m [00:03:01] task [xgboost.ray]:139777258818576 got new rank 4\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=861, ip=10.0.0.18)\u001b[0m [00:03:01] task [xgboost.ray]:139846296669152 got new rank 5\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=860, ip=10.0.0.18)\u001b[0m [00:03:01] task [xgboost.ray]:140087635639264 got new rank 6\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=826, ip=10.0.0.20)\u001b[0m [00:03:01] task [xgboost.ray]:139725035740176 got new rank 7\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=734, ip=10.0.0.21)\u001b[0m [00:03:01] task [xgboost.ray]:139849433975824 got new rank 8\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=953, ip=10.0.0.22)\u001b[0m [00:03:01] task [xgboost.ray]:140259147193360 got new rank 9\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=19735)\u001b[0m [00:03:02] WARNING: /mnt/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=19826)\u001b[0m [00:03:02] WARNING: /mnt/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=734, ip=10.0.0.21)\u001b[0m [00:03:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=826, ip=10.0.0.20)\u001b[0m [00:03:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=860, ip=10.0.0.18)\u001b[0m [00:03:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=861, ip=10.0.0.18)\u001b[0m [00:03:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=953, ip=10.0.0.22)\u001b[0m [00:03:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=19827)\u001b[0m [00:03:02] WARNING: /mnt/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=705, ip=10.0.0.17)\u001b[0m [00:03:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=704, ip=10.0.0.17)\u001b[0m [00:03:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "2021-12-15 00:03:16,115\tINFO main.py:1495 -- [RayXGBoost] Finished XGBoost training on training data with total N=142 in 17.87 seconds (14.93 pure XGBoost training time).\n",
      "2021-12-15 00:03:16,148\tINFO main.py:1535 -- [RayXGBoost] Created 10 remote actors.\n",
      "2021-12-15 00:03:18,572\tINFO main.py:1552 -- [RayXGBoost] Starting XGBoost prediction.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(427,)\n"
     ]
    }
   ],
   "source": [
    "from xgboost_ray import RayXGBClassifier, RayParams\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "clf = RayXGBClassifier(\n",
    "    n_jobs=10,  # In XGBoost-Ray, n_jobs sets the number of actors\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# scikit-learn API will automatically conver the data\n",
    "# to RayDMatrix format as needed.\n",
    "# You can also pass X as a RayDMatrix, in which case\n",
    "# y will be ignored.\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred_ray = clf.predict(X_test)\n",
    "print(pred_ray.shape)\n",
    "\n",
    "pred_proba_ray = clf.predict_proba(X_test)\n",
    "print(pred_proba_ray.shape)\n",
    "\n",
    "# It is also possible to pass a RayParams object\n",
    "# to fit/predict/predict_proba methods - will override\n",
    "# n_jobs set during initialization\n",
    "\n",
    "clf.fit(X_train, y_train, ray_params=RayParams(num_actors=10))\n",
    "\n",
    "pred_ray = clf.predict(X_test, ray_params=RayParams(num_actors=10))\n",
    "print(pred_ray.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 00:02:11,779\tINFO main.py:971 -- [RayXGBoost] Created 10 new actors (10 total actors). Waiting until actors are ready for training.\n",
      "2021-12-15 00:02:14,038\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=549, ip=10.0.0.17)\u001b[0m [00:02:14] task [xgboost.ray]:140446530374672 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=18505)\u001b[0m [00:02:14] task [xgboost.ray]:139997222566784 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=18596)\u001b[0m [00:02:14] task [xgboost.ray]:140666678270560 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=18595)\u001b[0m [00:02:14] task [xgboost.ray]:139792895871680 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=674, ip=10.0.0.18)\u001b[0m [00:02:14] task [xgboost.ray]:140170164730848 got new rank 4\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=673, ip=10.0.0.18)\u001b[0m [00:02:14] task [xgboost.ray]:140613048720352 got new rank 5\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=610, ip=10.0.0.20)\u001b[0m [00:02:14] task [xgboost.ray]:140270350560272 got new rank 6\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=550, ip=10.0.0.21)\u001b[0m [00:02:14] task [xgboost.ray]:140555926060048 got new rank 7\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=549, ip=10.0.0.21)\u001b[0m [00:02:14] task [xgboost.ray]:139716220537872 got new rank 8\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=707, ip=10.0.0.22)\u001b[0m [00:02:14] task [xgboost.ray]:139681225985040 got new rank 9\n",
      "2021-12-15 00:02:18,097\tINFO main.py:1495 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 6.93 seconds (4.05 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training error: 0.0035\n"
     ]
    }
   ],
   "source": [
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "train_x, train_y = load_breast_cancer(return_X_y=True)\n",
    "train_set = RayDMatrix(train_x, train_y)\n",
    "\n",
    "evals_result = {}\n",
    "bst = train(\n",
    "    {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    },\n",
    "    train_set,\n",
    "    evals_result=evals_result,\n",
    "    evals=[(train_set, \"train\")],\n",
    "    verbose_eval=False,\n",
    "    ray_params=RayParams(\n",
    "        num_actors=10,  # Number of remote actors\n",
    "        cpus_per_actor=1))\n",
    "\n",
    "bst.save_model(\"model.xgb\")\n",
    "print(\"Final training error: {:.4f}\".format(\n",
    "    evals_result[\"train\"][\"error\"][-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 00:06:57,649\tWARNING function_runner.py:561 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "2021-12-15 00:06:57,685\tINFO logger.py:605 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2021-12-15 00:06:57,685\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
      "2021-12-15 00:06:57,703\tWARNING tune.py:570 -- Tune detects GPUs, but no trials are using GPUs. To enable trials to use GPUs, set tune.run(resources_per_trial={'gpu': 1}...) which allows Tune to expose 1 GPU to each trial. You can also override `Trainable.default_resource_request` if using the Trainable API.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-15 00:06:57 (running for 00:00:00.13)<br>Memory usage on this node: 4.6/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/76.87 GiB heap, 0.0/35.14 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_model_2021-12-15_00-06-57<br>Number of trials: 4/4 (4 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_eb29e_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0393359  </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">   0.57664 </td></tr>\n",
       "<tr><td>train_model_eb29e_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000317791</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.885296</td></tr>\n",
       "<tr><td>train_model_eb29e_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00621972 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">   0.824497</td></tr>\n",
       "<tr><td>train_model_eb29e_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0110035  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.570246</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=866, ip=10.0.0.20)\u001b[0m 2021-12-15 00:06:59,785\tINFO main.py:971 -- [RayXGBoost] Created 10 new actors (10 total actors). Waiting until actors are ready for training.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=22893)\u001b[0m 2021-12-15 00:07:00,215\tINFO main.py:971 -- [RayXGBoost] Created 10 new actors (10 total actors). Waiting until actors are ready for training.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=866, ip=10.0.0.20)\u001b[0m 2021-12-15 00:07:02,358\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=806, ip=10.0.0.17)\u001b[0m [00:07:02] task [xgboost.ray]:139956931050512 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=807, ip=10.0.0.17)\u001b[0m [00:07:02] task [xgboost.ray]:140015142816784 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=809, ip=10.0.0.17)\u001b[0m [00:07:02] task [xgboost.ray]:140486460611600 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=808, ip=10.0.0.17)\u001b[0m [00:07:02] task [xgboost.ray]:139929721162768 got new rank 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-15 00:07:02 (running for 00:00:05.20)<br>Memory usage on this node: 5.5/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 22.0/26 CPUs, 0/1 GPUs, 0.0/76.87 GiB heap, 0.0/35.14 GiB objects (0.0/1.0 accelerator_type:K80)<br>Result logdir: /home/azureuser/ray_results/train_model_2021-12-15_00-06-57<br>Number of trials: 4/4 (2 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_eb29e_00000</td><td>RUNNING </td><td>10.0.0.13:22893</td><td style=\"text-align: right;\">0.0393359  </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">   0.57664 </td></tr>\n",
       "<tr><td>train_model_eb29e_00001</td><td>RUNNING </td><td>10.0.0.20:866  </td><td style=\"text-align: right;\">0.000317791</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.885296</td></tr>\n",
       "<tr><td>train_model_eb29e_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.00621972 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">   0.824497</td></tr>\n",
       "<tr><td>train_model_eb29e_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.0110035  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.570246</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=22893)\u001b[0m 2021-12-15 00:07:02,884\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=22923)\u001b[0m [00:07:02] task [xgboost.ray]:140088291420720 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=22927)\u001b[0m [00:07:02] task [xgboost.ray]:140535787313712 got new rank 4\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=22926)\u001b[0m [00:07:02] task [xgboost.ray]:140507433106016 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=22925)\u001b[0m [00:07:02] task [xgboost.ray]:140169966602800 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=22924)\u001b[0m [00:07:02] task [xgboost.ray]:140184059836976 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=897, ip=10.0.0.20)\u001b[0m [00:07:02] task [xgboost.ray]:140358549548048 got new rank 5\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=896, ip=10.0.0.20)\u001b[0m [00:07:02] task [xgboost.ray]:139644901964816 got new rank 4\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1000, ip=10.0.0.18)\u001b[0m [00:07:02] task [xgboost.ray]:140669231053840 got new rank 5\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=898, ip=10.0.0.20)\u001b[0m [00:07:03] task [xgboost.ray]:140655978810384 got new rank 6\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=998, ip=10.0.0.18)\u001b[0m [00:07:03] task [xgboost.ray]:140083606076432 got new rank 6\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1054, ip=10.0.0.22)\u001b[0m [00:07:03] task [xgboost.ray]:140399885855760 got new rank 7\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=999, ip=10.0.0.18)\u001b[0m [00:07:03] task [xgboost.ray]:139784944749584 got new rank 7\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1055, ip=10.0.0.22)\u001b[0m [00:07:03] task [xgboost.ray]:140675389156368 got new rank 8\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1025, ip=10.0.0.18)\u001b[0m [00:07:03] task [xgboost.ray]:140205027748832 got new rank 8\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=824, ip=10.0.0.21)\u001b[0m [00:07:03] task [xgboost.ray]:139967233416208 got new rank 9\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1056, ip=10.0.0.22)\u001b[0m [00:07:03] task [xgboost.ray]:139909043321872 got new rank 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_eb29e_00000:\n",
      "  date: 2021-12-15_00-07-05\n",
      "  done: false\n",
      "  experiment_id: 78a1d44ceba94b8780b65035ecf42077\n",
      "  hostname: nc6ic2\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.13\n",
      "  pid: 22893\n",
      "  time_since_restore: 5.622757196426392\n",
      "  time_this_iter_s: 5.622757196426392\n",
      "  time_total_s: 5.622757196426392\n",
      "  timestamp: 1639526825\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.080844\n",
      "  train-logloss: 0.665133\n",
      "  training_iteration: 1\n",
      "  trial_id: eb29e_00000\n",
      "  \n",
      "Result for train_model_eb29e_00000:\n",
      "  date: 2021-12-15_00-07-05\n",
      "  done: true\n",
      "  experiment_id: 78a1d44ceba94b8780b65035ecf42077\n",
      "  experiment_tag: 0_eta=0.039336,max_depth=1,subsample=0.57664\n",
      "  hostname: nc6ic2\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.0.0.13\n",
      "  pid: 22893\n",
      "  time_since_restore: 5.7859721183776855\n",
      "  time_this_iter_s: 0.11247491836547852\n",
      "  time_total_s: 5.7859721183776855\n",
      "  timestamp: 1639526825\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.068541\n",
      "  train-logloss: 0.48409800000000003\n",
      "  training_iteration: 10\n",
      "  trial_id: eb29e_00000\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=22893)\u001b[0m 2021-12-15 00:07:05,937\tINFO main.py:1495 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 5.79 seconds (3.04 pure XGBoost training time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_eb29e_00001:\n",
      "  date: 2021-12-15_00-07-06\n",
      "  done: false\n",
      "  experiment_id: cc609424206d4295b17ec44a5a138956\n",
      "  hostname: 58ed1aa158f4456e8dc2bdb7ba9efb83000004\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.20\n",
      "  pid: 866\n",
      "  time_since_restore: 6.45006537437439\n",
      "  time_this_iter_s: 6.45006537437439\n",
      "  time_total_s: 6.45006537437439\n",
      "  timestamp: 1639526826\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.02812\n",
      "  train-logloss: 0.6928669999999999\n",
      "  training_iteration: 1\n",
      "  trial_id: eb29e_00001\n",
      "  \n",
      "Result for train_model_eb29e_00001:\n",
      "  date: 2021-12-15_00-07-06\n",
      "  done: true\n",
      "  experiment_id: cc609424206d4295b17ec44a5a138956\n",
      "  experiment_tag: 1_eta=0.00031779,max_depth=8,subsample=0.8853\n",
      "  hostname: 58ed1aa158f4456e8dc2bdb7ba9efb83000004\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.0.0.20\n",
      "  pid: 866\n",
      "  time_since_restore: 7.119829416275024\n",
      "  time_this_iter_s: 0.0076334476470947266\n",
      "  time_total_s: 7.119829416275024\n",
      "  timestamp: 1639526826\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.01406\n",
      "  train-logloss: 0.6903699999999999\n",
      "  training_iteration: 10\n",
      "  trial_id: eb29e_00001\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=866, ip=10.0.0.20)\u001b[0m 2021-12-15 00:07:06,816\tINFO main.py:1495 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 7.12 seconds (4.45 pure XGBoost training time).\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=23074)\u001b[0m 2021-12-15 00:07:08,414\tINFO main.py:971 -- [RayXGBoost] Created 10 new actors (10 total actors). Waiting until actors are ready for training.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-15 00:07:08 (running for 00:00:11.19)<br>Memory usage on this node: 5.1/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 22.0/26 CPUs, 0/1 GPUs, 0.0/76.87 GiB heap, 0.0/35.14 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: eb29e_00001 with train-error=0.01406 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0003177912687455016, 'subsample': 0.8852956856563128, 'max_depth': 8, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /home/azureuser/ray_results/train_model_2021-12-15_00-06-57<br>Number of trials: 4/4 (2 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_eb29e_00002</td><td>RUNNING   </td><td>10.0.0.13:23074</td><td style=\"text-align: right;\">0.00621972 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">   0.824497</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
       "<tr><td>train_model_eb29e_00003</td><td>RUNNING   </td><td>10.0.0.20:1028 </td><td style=\"text-align: right;\">0.0110035  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.570246</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
       "<tr><td>train_model_eb29e_00000</td><td>TERMINATED</td><td>10.0.0.13:22893</td><td style=\"text-align: right;\">0.0393359  </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">   0.57664 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5.78597</td><td style=\"text-align: right;\">       0.484098</td><td style=\"text-align: right;\">     0.068541</td></tr>\n",
       "<tr><td>train_model_eb29e_00001</td><td>TERMINATED</td><td>10.0.0.20:866  </td><td style=\"text-align: right;\">0.000317791</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.885296</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         7.11983</td><td style=\"text-align: right;\">       0.69037 </td><td style=\"text-align: right;\">     0.01406 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1028, ip=10.0.0.20)\u001b[0m 2021-12-15 00:07:09,010\tINFO main.py:971 -- [RayXGBoost] Created 10 new actors (10 total actors). Waiting until actors are ready for training.\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1028, ip=10.0.0.20)\u001b[0m 2021-12-15 00:07:11,489\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=933, ip=10.0.0.17)\u001b[0m [00:07:11] task [xgboost.ray]:139646933847056 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=934, ip=10.0.0.17)\u001b[0m [00:07:11] task [xgboost.ray]:140188030110736 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=932, ip=10.0.0.17)\u001b[0m [00:07:11] task [xgboost.ray]:140133288811536 got new rank 2\n",
      "\u001b[2m\u001b[36m(ImplicitFunc pid=23074)\u001b[0m 2021-12-15 00:07:11,875\tINFO main.py:1016 -- [RayXGBoost] Starting XGBoost training.\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=931, ip=10.0.0.17)\u001b[0m [00:07:11] task [xgboost.ray]:139919402679312 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=23110)\u001b[0m [00:07:11] task [xgboost.ray]:140479971858992 got new rank 3\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=23111)\u001b[0m [00:07:11] task [xgboost.ray]:140512168856160 got new rank 4\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=23108)\u001b[0m [00:07:11] task [xgboost.ray]:140414656612960 got new rank 1\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=23107)\u001b[0m [00:07:11] task [xgboost.ray]:140222895139376 got new rank 0\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=23109)\u001b[0m [00:07:11] task [xgboost.ray]:140027330726544 got new rank 2\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1148, ip=10.0.0.18)\u001b[0m [00:07:11] task [xgboost.ray]:139710560213984 got new rank 5\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1059, ip=10.0.0.20)\u001b[0m [00:07:12] task [xgboost.ray]:140612557163536 got new rank 4\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1149, ip=10.0.0.18)\u001b[0m [00:07:12] task [xgboost.ray]:140030605650912 got new rank 6\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1060, ip=10.0.0.20)\u001b[0m [00:07:12] task [xgboost.ray]:140193768660032 got new rank 5\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1061, ip=10.0.0.20)\u001b[0m [00:07:12] task [xgboost.ray]:140342795279376 got new rank 6\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1150, ip=10.0.0.18)\u001b[0m [00:07:12] task [xgboost.ray]:140378566343648 got new rank 7\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1148, ip=10.0.0.22)\u001b[0m [00:07:12] task [xgboost.ray]:140661545499664 got new rank 7\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1229, ip=10.0.0.18)\u001b[0m [00:07:12] task [xgboost.ray]:140681535708128 got new rank 8\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1149, ip=10.0.0.22)\u001b[0m [00:07:12] task [xgboost.ray]:139966762609680 got new rank 8\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=894, ip=10.0.0.21)\u001b[0m [00:07:12] task [xgboost.ray]:139756268563568 got new rank 9\n",
      "\u001b[2m\u001b[36m(_RemoteRayXGBoostActor pid=1150, ip=10.0.0.22)\u001b[0m [00:07:12] task [xgboost.ray]:140118901447696 got new rank 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-15 00:07:13 (running for 00:00:16.21)<br>Memory usage on this node: 5.6/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 22.0/26 CPUs, 0/1 GPUs, 0.0/76.87 GiB heap, 0.0/35.14 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: eb29e_00001 with train-error=0.01406 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0003177912687455016, 'subsample': 0.8852956856563128, 'max_depth': 8, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /home/azureuser/ray_results/train_model_2021-12-15_00-06-57<br>Number of trials: 4/4 (2 RUNNING, 2 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_eb29e_00002</td><td>RUNNING   </td><td>10.0.0.13:23074</td><td style=\"text-align: right;\">0.00621972 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">   0.824497</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
       "<tr><td>train_model_eb29e_00003</td><td>RUNNING   </td><td>10.0.0.20:1028 </td><td style=\"text-align: right;\">0.0110035  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.570246</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">               </td><td style=\"text-align: right;\">             </td></tr>\n",
       "<tr><td>train_model_eb29e_00000</td><td>TERMINATED</td><td>10.0.0.13:22893</td><td style=\"text-align: right;\">0.0393359  </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">   0.57664 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5.78597</td><td style=\"text-align: right;\">       0.484098</td><td style=\"text-align: right;\">     0.068541</td></tr>\n",
       "<tr><td>train_model_eb29e_00001</td><td>TERMINATED</td><td>10.0.0.20:866  </td><td style=\"text-align: right;\">0.000317791</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.885296</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         7.11983</td><td style=\"text-align: right;\">       0.69037 </td><td style=\"text-align: right;\">     0.01406 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_model_eb29e_00003:\n",
      "  date: 2021-12-15_00-07-14\n",
      "  done: false\n",
      "  experiment_id: c07865d953a744a2899443cd2658c046\n",
      "  hostname: 58ed1aa158f4456e8dc2bdb7ba9efb83000004\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.20\n",
      "  pid: 1028\n",
      "  time_since_restore: 6.072114706039429\n",
      "  time_this_iter_s: 6.072114706039429\n",
      "  time_total_s: 6.072114706039429\n",
      "  timestamp: 1639526834\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.049209\n",
      "  train-logloss: 0.684121\n",
      "  training_iteration: 1\n",
      "  trial_id: eb29e_00003\n",
      "  \n",
      "Result for train_model_eb29e_00002:\n",
      "  date: 2021-12-15_00-07-15\n",
      "  done: false\n",
      "  experiment_id: be2b5b01d83344bd848c536dfd188e25\n",
      "  hostname: nc6ic2\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 10.0.0.13\n",
      "  pid: 23074\n",
      "  time_since_restore: 6.861549377441406\n",
      "  time_this_iter_s: 6.861549377441406\n",
      "  time_total_s: 6.861549377441406\n",
      "  timestamp: 1639526835\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.050967000000000005\n",
      "  train-logloss: 0.688002\n",
      "  training_iteration: 1\n",
      "  trial_id: eb29e_00002\n",
      "  \n",
      "Result for train_model_eb29e_00003:\n",
      "  date: 2021-12-15_00-07-15\n",
      "  done: true\n",
      "  experiment_id: c07865d953a744a2899443cd2658c046\n",
      "  experiment_tag: 3_eta=0.011003,max_depth=3,subsample=0.57025\n",
      "  hostname: 58ed1aa158f4456e8dc2bdb7ba9efb83000004\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.0.0.20\n",
      "  pid: 1028\n",
      "  time_since_restore: 6.3609747886657715\n",
      "  time_this_iter_s: 0.22673463821411133\n",
      "  time_total_s: 6.3609747886657715\n",
      "  timestamp: 1639526835\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.024604999999999995\n",
      "  train-logloss: 0.609653\n",
      "  training_iteration: 10\n",
      "  trial_id: eb29e_00003\n",
      "  \n",
      "Result for train_model_eb29e_00002:\n",
      "  date: 2021-12-15_00-07-15\n",
      "  done: true\n",
      "  experiment_id: be2b5b01d83344bd848c536dfd188e25\n",
      "  experiment_tag: 2_eta=0.0062197,max_depth=2,subsample=0.8245\n",
      "  hostname: nc6ic2\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 10.0.0.13\n",
      "  pid: 23074\n",
      "  time_since_restore: 7.070994138717651\n",
      "  time_this_iter_s: 0.1654648780822754\n",
      "  time_total_s: 7.070994138717651\n",
      "  timestamp: 1639526835\n",
      "  timesteps_since_restore: 0\n",
      "  train-error: 0.045694\n",
      "  train-logloss: 0.6452310000000001\n",
      "  training_iteration: 10\n",
      "  trial_id: eb29e_00002\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=1028, ip=10.0.0.20)\u001b[0m 2021-12-15 00:07:15,268\tINFO main.py:1495 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 6.36 seconds (3.77 pure XGBoost training time).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-15 00:07:15 (running for 00:00:17.74)<br>Memory usage on this node: 5.6/54.9 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/26 CPUs, 0/1 GPUs, 0.0/76.87 GiB heap, 0.0/35.14 GiB objects (0.0/1.0 accelerator_type:K80)<br>Current best trial: eb29e_00001 with train-error=0.01406 and parameters={'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0003177912687455016, 'subsample': 0.8852956856563128, 'max_depth': 8, 'nthread': 1, 'n_jobs': 1}<br>Result logdir: /home/azureuser/ray_results/train_model_2021-12-15_00-06-57<br>Number of trials: 4/4 (4 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  train-logloss</th><th style=\"text-align: right;\">  train-error</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_model_eb29e_00000</td><td>TERMINATED</td><td>10.0.0.13:22893</td><td style=\"text-align: right;\">0.0393359  </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">   0.57664 </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5.78597</td><td style=\"text-align: right;\">       0.484098</td><td style=\"text-align: right;\">     0.068541</td></tr>\n",
       "<tr><td>train_model_eb29e_00001</td><td>TERMINATED</td><td>10.0.0.20:866  </td><td style=\"text-align: right;\">0.000317791</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">   0.885296</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         7.11983</td><td style=\"text-align: right;\">       0.69037 </td><td style=\"text-align: right;\">     0.01406 </td></tr>\n",
       "<tr><td>train_model_eb29e_00002</td><td>TERMINATED</td><td>10.0.0.13:23074</td><td style=\"text-align: right;\">0.00621972 </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">   0.824497</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         7.07099</td><td style=\"text-align: right;\">       0.645231</td><td style=\"text-align: right;\">     0.045694</td></tr>\n",
       "<tr><td>train_model_eb29e_00003</td><td>TERMINATED</td><td>10.0.0.20:1028 </td><td style=\"text-align: right;\">0.0110035  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">   0.570246</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         6.36097</td><td style=\"text-align: right;\">       0.609653</td><td style=\"text-align: right;\">     0.024605</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ImplicitFunc pid=23074)\u001b[0m 2021-12-15 00:07:15,420\tINFO main.py:1495 -- [RayXGBoost] Finished XGBoost training on training data with total N=569 in 7.07 seconds (3.54 pure XGBoost training time).\n",
      "2021-12-15 00:07:15,560\tINFO tune.py:626 -- Total run time: 17.91 seconds (17.73 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters {'tree_method': 'approx', 'objective': 'binary:logistic', 'eval_metric': ['logloss', 'error'], 'eta': 0.0003177912687455016, 'subsample': 0.8852956856563128, 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "from xgboost_ray import RayDMatrix, RayParams, train\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "num_actors = 10\n",
    "num_cpus_per_actor = 1\n",
    "\n",
    "ray_params = RayParams(\n",
    "    num_actors=num_actors,\n",
    "    cpus_per_actor=num_cpus_per_actor)\n",
    "\n",
    "def train_model(config):\n",
    "    train_x, train_y = load_breast_cancer(return_X_y=True)\n",
    "    train_set = RayDMatrix(train_x, train_y)\n",
    "\n",
    "    evals_result = {}\n",
    "    bst = train(\n",
    "        params=config,\n",
    "        dtrain=train_set,\n",
    "        evals_result=evals_result,\n",
    "        evals=[(train_set, \"train\")],\n",
    "        verbose_eval=False,\n",
    "        ray_params=ray_params)\n",
    "    bst.save_model(\"model.xgb\")\n",
    "\n",
    "from ray import tune\n",
    "\n",
    "# Specify the hyperparameter search space.\n",
    "config = {\n",
    "    \"tree_method\": \"approx\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": [\"logloss\", \"error\"],\n",
    "    \"eta\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"subsample\": tune.uniform(0.5, 1.0),\n",
    "    \"max_depth\": tune.randint(1, 9)\n",
    "}\n",
    "\n",
    "# Make sure to use the `get_tune_resources` method to set the `resources_per_trial`\n",
    "analysis = tune.run(\n",
    "    train_model,\n",
    "    config=config,\n",
    "    metric=\"train-error\",\n",
    "    mode=\"min\",\n",
    "    num_samples=4,\n",
    "    resources_per_trial=ray_params.get_tune_resources())\n",
    "print(\"Best hyperparameters\", analysis.best_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shutdown when not used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray_on_aml.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Ray on Job Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1639179342786
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "compute_cluster = 'worker-cpu-v3'\n",
    "maxnode =5\n",
    "vm_size='STANDARD_DS3_V2'\n",
    "vnet='rayvnet'\n",
    "subnet='default'\n",
    "exp ='ray_on_aml_job'\n",
    "ws_detail = ws.get_details()\n",
    "ws_rg = ws_detail['id'].split(\"/\")[4]\n",
    "vnet_rg=None\n",
    "try:\n",
    "    ray_cluster = ComputeTarget(workspace=ws, name=compute_cluster)\n",
    "\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    if vnet_rg is None:\n",
    "        vnet_rg = ws_rg\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                        min_nodes=0, max_nodes=maxnode,\n",
    "                                                        vnet_resourcegroup_name=vnet_rg,\n",
    "                                                        vnet_name=vnet,\n",
    "                                                        subnet_name=subnet)\n",
    "    ray_cluster = ComputeTarget.create(ws, compute_cluster, compute_config)\n",
    "\n",
    "    ray_cluster.wait_for_completion(show_output=True)\n",
    "\n",
    "\n",
    "rayEnv = Environment.from_conda_specification(name = \"rayEnv\",\n",
    "                                             file_path = \"../examples/conda_env.yml\")\n",
    "\n",
    "# rayEnv = Environment.get(ws, \"rayEnv\", version=19)\n",
    "\n",
    "\n",
    "src = ScriptRunConfig(source_directory='../examples/job',\n",
    "                script='aml_job.py',\n",
    "                environment=rayEnv,\n",
    "                compute_target=ray_cluster,\n",
    "                distributed_job_config=PyTorchConfiguration(node_count=maxnode),\n",
    "                    # arguments = [\"--master_ip\",master_ip]\n",
    "                )\n",
    "run = Experiment(ws, exp).submit(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
