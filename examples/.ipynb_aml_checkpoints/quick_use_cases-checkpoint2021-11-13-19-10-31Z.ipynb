{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Interactive use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade ray-on-aml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1639168219519
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "# from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import platform\n",
    "import sys\n",
    "# sys.path.append(\"../\") # go to parent dir\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1639167793538
    }
   },
   "outputs": [],
   "source": [
    "#You can pre-provision \"worker-cpu-v3\" in the same vnet with your compute instance\n",
    "from ray_on_aml.core import Ray_On_AML\n",
    "ws = Workspace.from_config()\n",
    "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"worker-cpu-v3\")\n",
    "_, ray = ray_on_aml.getRay()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node:10.0.0.26': 1.0,\n",
       " 'CPU': 24.0,\n",
       " 'object_store_memory': 24947750089.0,\n",
       " 'memory': 56963684356.0,\n",
       " 'node:10.0.0.18': 1.0,\n",
       " 'node:10.0.0.17': 1.0,\n",
       " 'node:10.0.0.21': 1.0,\n",
       " 'node:10.0.0.20': 1.0,\n",
       " 'node:10.0.0.25': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.cluster_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1639106683762
    }
   },
   "outputs": [],
   "source": [
    "# ray_on_aml.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with Dask on Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1639105974201
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8738.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5914.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9952</th>\n",
       "      <td>2387.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>2121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2554.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>974 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade\n",
       "age         \n",
       "8     8738.0\n",
       "22    5914.5\n",
       "27    6655.0\n",
       "42    2169.0\n",
       "45    4395.0\n",
       "...      ...\n",
       "9952  2387.0\n",
       "9973  2121.0\n",
       "9984   779.0\n",
       "9987   854.0\n",
       "9997  2554.0\n",
       "\n",
       "[974 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import ray\n",
    "# ray.init()\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dask.config.set(scheduler=ray_dask_get)\n",
    "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
    "\n",
    "# The Dask scheduler submits the underlying task graph to Ray.\n",
    "d_arr.mean().compute(scheduler=ray_dask_get)\n",
    "\n",
    "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
    "# specify it on each compute call.\n",
    "\n",
    "df = dd.from_pandas(\n",
    "    pd.DataFrame(\n",
    "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
    "    npartitions=2)\n",
    "df.groupby([\"age\"]).mean().compute()\n",
    "\n",
    "# ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1639104458150
    }
   },
   "outputs": [],
   "source": [
    "# import dask.dataframe as dd\n",
    "\n",
    "# storage_options = {'account_name': 'azureopendatastorage'}\n",
    "# ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
    "# ddf.count().compute()\n",
    "#This still have error about parquet, need to fix, might be lib version conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1639106144831
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata Fetch Progress: 100%|██████████| 16/16 [00:08<00:00,  1.78it/s]\n",
      "Metadata Fetch Progress: 100%|██████████| 8/8 [00:00<00:00, 10.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98904376"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dask\n",
    "\n",
    "# import ray\n",
    "from ray.util.dask import ray_dask_get\n",
    "import dask\n",
    "import dask.array as da\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Model\n",
    "from adlfs import AzureBlobFileSystem\n",
    "account_key = ws.get_default_keyvault().get_secret(\"adls7-account-key\")\n",
    "account_name=\"adlsgen7\"\n",
    "abfs = AzureBlobFileSystem(account_name=\"adlsgen7\",account_key=account_key,  container_name=\"mltraining\")\n",
    "abfs2 = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
    "\n",
    "\n",
    "storage_options={'account_name': account_name, 'account_key': account_key}\n",
    "\n",
    "# ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year2008', storage_options=storage_options)\n",
    "\n",
    "data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs2)\n",
    "data2 = ray.data.read_parquet(\"az://mltraining/ISDWeatherDelta/year2008\", filesystem=abfs)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Ray Tune for distributed ML tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1639106657384
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 22:29:33,459\tWARNING function_runner.py:561 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.\n",
      "2021-12-10 22:29:33,475\tINFO logger.py:605 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2021-12-10 22:29:33,476\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-10 22:29:33 (running for 00:00:00.13)<br>Memory usage on this node: 4.1/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/53.05 GiB heap, 0.0/23.23 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-10_22-29-33<br>Number of trials: 1/1 (1 PENDING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_a61c4_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">6.14092e-10</td><td style=\"text-align: right;\"> 0.0582547</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 22:29:34,003\tERROR trial_runner.py:958 -- Trial train_mnist_a61c4_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 924, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 787, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/worker.py\", line 1715, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=207, ip=10.0.0.25)\n",
      "RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\n",
      "\u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=207, ip=10.0.0.25)\n",
      "  File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle.py\", line 679, in subimport\n",
      "    __import__(name)\n",
      "  File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
      "    from torchvision import models\n",
      "  File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/models/__init__.py\", line 12, in <module>\n",
      "    from . import detection\n",
      "  File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n",
      "    from .faster_rcnn import *\n",
      "  File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/models/detection/faster_rcnn.py\", line 7, in <module>\n",
      "    from torchvision.ops import misc as misc_nn_ops\n",
      "  File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/ops/__init__.py\", line 1, in <module>\n",
      "    from .boxes import nms, batched_nms, remove_small_boxes, clip_boxes_to_image, box_area, box_iou, generalized_box_iou\n",
      "  File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/ops/boxes.py\", line 45, in <module>\n",
      "    @torch.jit._script_if_tracing\n",
      "AttributeError: module 'torch.jit' has no attribute '_script_if_tracing'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_mnist_a61c4_00000:\n",
      "  trial_id: a61c4_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-10 22:29:34 (running for 00:00:00.51)<br>Memory usage on this node: 4.1/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/53.05 GiB heap, 0.0/23.23 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-10_22-29-33<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_a61c4_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">6.14092e-10</td><td style=\"text-align: right;\"> 0.0582547</td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mnist_a61c4_00000</td><td style=\"text-align: right;\">           1</td><td>/home/azureuser/ray_results/train_mnist_2021-12-10_22-29-33/train_mnist_a61c4_00000_0_lr=6.1409e-10,momentum=0.058255_2021-12-10_22-29-33/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m 2021-12-10 22:29:33,999\tERROR worker.py:431 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=207, ip=10.0.0.25)\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=207, ip=10.0.0.25)\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m   File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle.py\", line 679, in subimport\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m     __import__(name)\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m   File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/__init__.py\", line 6, in <module>\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m     from torchvision import models\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m   File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/models/__init__.py\", line 12, in <module>\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m     from . import detection\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m   File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m     from .faster_rcnn import *\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m   File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/models/detection/faster_rcnn.py\", line 7, in <module>\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m     from torchvision.ops import misc as misc_nn_ops\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m   File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/ops/__init__.py\", line 1, in <module>\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m     from .boxes import nms, batched_nms, remove_small_boxes, clip_boxes_to_image, box_area, box_iou, generalized_box_iou\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m   File \"/azureml-envs/azureml_f868bc5adb64a16ac9e789bb1315cb41/lib/python3.8/site-packages/torchvision/ops/boxes.py\", line 45, in <module>\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m     @torch.jit._script_if_tracing\n",
      "\u001b[2m\u001b[36m(TemporaryActor pid=207, ip=10.0.0.25)\u001b[0m AttributeError: module 'torch.jit' has no attribute '_script_if_tracing'\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_mnist_a61c4_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31183/956064152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_mnist_a61c4_00000])"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "# import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # In this example, we don't change the model architecture\n",
    "        # due to simplicity.\n",
    "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
    "        self.fc = nn.Linear(192, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
    "        x = x.view(-1, 192)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "# Change these values if you want the training to run quicker or slower.\n",
    "EPOCH_SIZE = 512\n",
    "TEST_SIZE = 256\n",
    "\n",
    "def train(model, optimizer, train_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # We set this just for the example to run quickly.\n",
    "        if batch_idx * len(data) > EPOCH_SIZE:\n",
    "            return\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def test(model, data_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            # We set this just for the example to run quickly.\n",
    "            if batch_idx * len(data) > TEST_SIZE:\n",
    "                break\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    return correct / total\n",
    "def train_mnist(config):\n",
    "    # Data Setup\n",
    "    mnist_transforms = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "    test_loader = DataLoader(\n",
    "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
    "        batch_size=64,\n",
    "        shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = ConvNet()\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
    "    for i in range(10):\n",
    "        train(model, optimizer, train_loader)\n",
    "        acc = test(model, test_loader)\n",
    "\n",
    "        # Send the current training result back to Tune\n",
    "        tune.report(mean_accuracy=acc)\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            # This saves the model to the trial directory\n",
    "            torch.save(model.state_dict(), \"./model.pth\")\n",
    "search_space = {\n",
    "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
    "    \"momentum\": tune.uniform(0.01, 0.09)\n",
    "}\n",
    "\n",
    "# Uncomment this to enable distributed execution\n",
    "# ray.shutdown()\n",
    "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
    "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
    "# Download the dataset first\n",
    "datasets.MNIST(\"~/data\", train=True, download=True)\n",
    "\n",
    "analysis = tune.run(train_mnist, config=search_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1639106681808
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 21:43:15,768\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-10 21:43:16 (running for 00:00:00.88)<br>Memory usage on this node: 4.0/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/24 CPUs, 0/0 GPUs, 0.0/53.06 GiB heap, 0.0/23.24 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-10_21-43-15<br>Number of trials: 10/10 (9 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_breast_cancer_2e77d_00000</td><td>RUNNING </td><td>10.0.0.26:23057</td><td style=\"text-align: right;\">0.0116743  </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.564379</td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.00371402 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.72637 </td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.000417622</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.830038</td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.0131403  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.854627</td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.00178065 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.944164</td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.0124743  </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.805848</td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.00551973 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.586203</td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.00997637 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.712431</td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00008</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.000510061</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.733943</td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00009</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">0.0695749  </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.935206</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_breast_cancer_2e77d_00007:\n",
      "  date: 2021-12-10_21-43-17\n",
      "  done: true\n",
      "  experiment_id: e46e5e5eecba438cb39b79b7d7950442\n",
      "  hostname: c2473fa89b9a40488624f53530886d6100000C\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.909091\n",
      "  node_ip: 10.0.0.25\n",
      "  pid: 195\n",
      "  time_since_restore: 0.10215330123901367\n",
      "  time_this_iter_s: 0.10215330123901367\n",
      "  time_total_s: 0.10215330123901367\n",
      "  timestamp: 1639172597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2e77d_00007\n",
      "  \n",
      "Result for train_breast_cancer_2e77d_00002:\n",
      "  date: 2021-12-10_21-43-17\n",
      "  done: true\n",
      "  experiment_id: a6d3135d2f364b7ab8b28612c3b5e35d\n",
      "  hostname: c2473fa89b9a40488624f53530886d6100000A\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.93007\n",
      "  node_ip: 10.0.0.20\n",
      "  pid: 210\n",
      "  time_since_restore: 0.09505844116210938\n",
      "  time_this_iter_s: 0.09505844116210938\n",
      "  time_total_s: 0.09505844116210938\n",
      "  timestamp: 1639172597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2e77d_00002\n",
      "  \n",
      "Result for train_breast_cancer_2e77d_00009:\n",
      "  date: 2021-12-10_21-43-17\n",
      "  done: true\n",
      "  experiment_id: 413f7f75f3364b189096a4a3d642c8bf\n",
      "  hostname: c2473fa89b9a40488624f53530886d61000000\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.902098\n",
      "  node_ip: 10.0.0.12\n",
      "  pid: 232\n",
      "  time_since_restore: 0.13996195793151855\n",
      "  time_this_iter_s: 0.13996195793151855\n",
      "  time_total_s: 0.13996195793151855\n",
      "  timestamp: 1639172597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2e77d_00009\n",
      "  \n",
      "Result for train_breast_cancer_2e77d_00006:\n",
      "  date: 2021-12-10_21-43-17\n",
      "  done: true\n",
      "  experiment_id: 8fc1ac0f01eb4b6bb4055b1363ad8fa0\n",
      "  hostname: c2473fa89b9a40488624f53530886d61000000\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.909091\n",
      "  node_ip: 10.0.0.12\n",
      "  pid: 230\n",
      "  time_since_restore: 0.15450239181518555\n",
      "  time_this_iter_s: 0.15450239181518555\n",
      "  time_total_s: 0.15450239181518555\n",
      "  timestamp: 1639172597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2e77d_00006\n",
      "  \n",
      "Result for train_breast_cancer_2e77d_00008:\n",
      "  date: 2021-12-10_21-43-17\n",
      "  done: true\n",
      "  experiment_id: 06f19853161c45c2b874c7a8739cc02b\n",
      "  hostname: c2473fa89b9a40488624f53530886d61000002\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.916084\n",
      "  node_ip: 10.0.0.18\n",
      "  pid: 197\n",
      "  time_since_restore: 0.1386566162109375\n",
      "  time_this_iter_s: 0.1386566162109375\n",
      "  time_total_s: 0.1386566162109375\n",
      "  timestamp: 1639172597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2e77d_00008\n",
      "  \n",
      "Result for train_breast_cancer_2e77d_00004:\n",
      "  date: 2021-12-10_21-43-17\n",
      "  done: true\n",
      "  experiment_id: b3d3a6f09dbc4195ba0840f1b39fdf7c\n",
      "  hostname: c2473fa89b9a40488624f53530886d61000001\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.909091\n",
      "  node_ip: 10.0.0.17\n",
      "  pid: 195\n",
      "  time_since_restore: 0.11961841583251953\n",
      "  time_this_iter_s: 0.11961841583251953\n",
      "  time_total_s: 0.11961841583251953\n",
      "  timestamp: 1639172597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2e77d_00004\n",
      "  \n",
      "Result for train_breast_cancer_2e77d_00003:\n",
      "  date: 2021-12-10_21-43-17\n",
      "  done: true\n",
      "  experiment_id: 903b09d210b748a38412acae9380c232\n",
      "  hostname: c2473fa89b9a40488624f53530886d61000002\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.93007\n",
      "  node_ip: 10.0.0.18\n",
      "  pid: 196\n",
      "  time_since_restore: 0.16823101043701172\n",
      "  time_this_iter_s: 0.16823101043701172\n",
      "  time_total_s: 0.16823101043701172\n",
      "  timestamp: 1639172597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2e77d_00003\n",
      "  \n",
      "Result for train_breast_cancer_2e77d_00000:\n",
      "  date: 2021-12-10_21-43-17\n",
      "  done: true\n",
      "  experiment_id: 41d68c1aa51b4e909c679301df93162b\n",
      "  hostname: janguy1\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.958042\n",
      "  node_ip: 10.0.0.26\n",
      "  pid: 23057\n",
      "  time_since_restore: 1.044778823852539\n",
      "  time_this_iter_s: 1.044778823852539\n",
      "  time_total_s: 1.044778823852539\n",
      "  timestamp: 1639172597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2e77d_00000\n",
      "  \n",
      "Result for train_breast_cancer_2e77d_00005:\n",
      "  date: 2021-12-10_21-43-17\n",
      "  done: true\n",
      "  experiment_id: bfd092802a5e47cbb28471006c323095\n",
      "  hostname: c2473fa89b9a40488624f53530886d61000001\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.923077\n",
      "  node_ip: 10.0.0.17\n",
      "  pid: 197\n",
      "  time_since_restore: 0.10450053215026855\n",
      "  time_this_iter_s: 0.10450053215026855\n",
      "  time_total_s: 0.10450053215026855\n",
      "  timestamp: 1639172597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2e77d_00005\n",
      "  \n",
      "Result for train_breast_cancer_2e77d_00001:\n",
      "  date: 2021-12-10_21-43-17\n",
      "  done: true\n",
      "  experiment_id: d76e344bfe554d5e9dc45990033ed88b\n",
      "  hostname: janguy1\n",
      "  iterations_since_restore: 1\n",
      "  mean_accuracy: 0.93007\n",
      "  node_ip: 10.0.0.26\n",
      "  pid: 23111\n",
      "  time_since_restore: 0.29124879837036133\n",
      "  time_this_iter_s: 0.29124879837036133\n",
      "  time_total_s: 0.29124879837036133\n",
      "  timestamp: 1639172597\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 2e77d_00001\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2021-12-10 21:43:18 (running for 00:00:02.23)<br>Memory usage on this node: 3.3/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/0 GPUs, 0.0/53.06 GiB heap, 0.0/23.24 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-10_21-43-15<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                     </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_breast_cancer_2e77d_00000</td><td>TERMINATED</td><td>10.0.0.26:23057</td><td style=\"text-align: right;\">0.0116743  </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.564379</td><td style=\"text-align: right;\">0.958042</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       1.04478  </td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00001</td><td>TERMINATED</td><td>10.0.0.26:23111</td><td style=\"text-align: right;\">0.00371402 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.72637 </td><td style=\"text-align: right;\">0.93007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.291249 </td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00002</td><td>TERMINATED</td><td>10.0.0.20:210  </td><td style=\"text-align: right;\">0.000417622</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.830038</td><td style=\"text-align: right;\">0.93007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.0950584</td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00003</td><td>TERMINATED</td><td>10.0.0.18:196  </td><td style=\"text-align: right;\">0.0131403  </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.854627</td><td style=\"text-align: right;\">0.93007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.168231 </td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00004</td><td>TERMINATED</td><td>10.0.0.17:195  </td><td style=\"text-align: right;\">0.00178065 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.944164</td><td style=\"text-align: right;\">0.909091</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.119618 </td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00005</td><td>TERMINATED</td><td>10.0.0.17:197  </td><td style=\"text-align: right;\">0.0124743  </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.805848</td><td style=\"text-align: right;\">0.923077</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.104501 </td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00006</td><td>TERMINATED</td><td>10.0.0.12:230  </td><td style=\"text-align: right;\">0.00551973 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.586203</td><td style=\"text-align: right;\">0.909091</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.154502 </td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00007</td><td>TERMINATED</td><td>10.0.0.25:195  </td><td style=\"text-align: right;\">0.00997637 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.712431</td><td style=\"text-align: right;\">0.909091</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.102153 </td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00008</td><td>TERMINATED</td><td>10.0.0.18:197  </td><td style=\"text-align: right;\">0.000510061</td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.733943</td><td style=\"text-align: right;\">0.916084</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.138657 </td></tr>\n",
       "<tr><td>train_breast_cancer_2e77d_00009</td><td>TERMINATED</td><td>10.0.0.12:232  </td><td style=\"text-align: right;\">0.0695749  </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.935206</td><td style=\"text-align: right;\">0.902098</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">       0.139962 </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 21:43:18,123\tINFO tune.py:626 -- Total run time: 2.36 seconds (2.21 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    " import sklearn.datasets\n",
    " import sklearn.metrics\n",
    " from sklearn.model_selection import train_test_split\n",
    " import xgboost as xgb\n",
    "\n",
    " from ray import tune\n",
    "\n",
    "\n",
    " def train_breast_cancer(config):\n",
    "     # Load dataset\n",
    "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "     # Split into train and test set\n",
    "     train_x, test_x, train_y, test_y = train_test_split(\n",
    "         data, labels, test_size=0.25)\n",
    "     # Build input matrices for XGBoost\n",
    "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
    "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
    "     # Train the classifier\n",
    "     results = {}\n",
    "     xgb.train(\n",
    "         config,\n",
    "         train_set,\n",
    "         evals=[(test_set, \"eval\")],\n",
    "         evals_result=results,\n",
    "         verbose_eval=False)\n",
    "     # Return prediction accuracy\n",
    "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
    "     tune.report(mean_accuracy=accuracy, done=True)\n",
    "\n",
    "\n",
    " config = {\n",
    "     \"objective\": \"binary:logistic\",\n",
    "     \"eval_metric\": [\"logloss\", \"error\"],\n",
    "     \"max_depth\": tune.randint(1, 9),\n",
    "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
    "     \"subsample\": tune.uniform(0.5, 1.0),\n",
    "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
    " }\n",
    " analysis = tune.run(\n",
    "     train_breast_cancer,\n",
    "     resources_per_trial={\"cpu\": 1},\n",
    "     config=config,\n",
    "     num_samples=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Spark on Ray (#todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "# import raydp\n",
    "# import os\n",
    "# ray.shutdown()\n",
    "# ray.init()\n",
    "# os.environ[\"PYSPARK_PYTHON\"]=\"/anaconda/envs/azureml_py38/bin/python3\"\n",
    "\n",
    "# # ray.init(address ='ray://10.0.0.11:6379')\n",
    "# spark = raydp.init_spark(\n",
    "#   app_name = \"example\",\n",
    "#   num_executors = 2,\n",
    "#   executor_cores = 1,\n",
    "#   executor_memory = \"1gb\"\n",
    "# )\n",
    "\n",
    "# # data =spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://ojsales-simulatedcontainer@azureopendatastorage.blob.core.windows.net/oj_sales_data/Store10*.csv\")\n",
    "\n",
    "\n",
    "# # # normal data processesing with Spark\n",
    "# # df = spark.createDataFrame([('look',), ('spark',), ('tutorial',), ('spark',), ('look', ), ('python', )], ['word'])\n",
    "# # df.show()\n",
    "# # word_count = df.groupBy('word').count()\n",
    "# # word_count.show()\n",
    "# import pandas as pd\n",
    "\n",
    "# from pyspark.sql.functions import col, pandas_udf\n",
    "# from pyspark.sql.types import LongType\n",
    "\n",
    "# # Declare the function and create the UDF\n",
    "# def multiply_func(a: pd.Series, b: pd.Series) -> pd.Series:\n",
    "#     return a * b\n",
    "\n",
    "# multiply = pandas_udf(multiply_func, returnType=LongType())\n",
    "\n",
    "# # The function for a pandas_udf should be able to execute with local Pandas data\n",
    "# x = pd.Series([1, 2, 3])\n",
    "# print(multiply_func(x, x))\n",
    "# # 0    1\n",
    "# # 1    4\n",
    "# # 2    9\n",
    "# # dtype: int64\n",
    "\n",
    "# # Create a Spark DataFrame, 'spark' is an existing SparkSession\n",
    "# df = spark.createDataFrame(pd.DataFrame(x, columns=[\"x\"]))\n",
    "\n",
    "# # Execute function as a Spark vectorized UDF\n",
    "# df.select(multiply(col(\"x\"), col(\"x\"))).show()\n",
    "# # +-------------------+\n",
    "# # |multiply_func(x, x)|\n",
    "# # +-------------------+\n",
    "# # |                  1|\n",
    "# # |                  4|\n",
    "# # |                  9|\n",
    "# # +-------------------+\n",
    "\n",
    "\n",
    "# # stop the spark cluster\n",
    "# raydp.stop_spark()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Ray on Job Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# base_conda_dep =['adlfs>=2021.10.0','pytorch','matplotlib','torchvision','pip']\n",
    "# base_pip_dep = ['sklearn','xgboost','lightgbm','ray[default]==1.9.0', 'xgboost_ray', 'dask','pyarrow>=6.0.1', 'azureml-mlflow']\n",
    "compute_cluster = 'worker-cpu-v3'\n",
    "maxnode =5\n",
    "vm_size='STANDARD_DS3_V2'\n",
    "vnet='rayvnet'\n",
    "subnet='default'\n",
    "exp ='ray_on_aml_job'\n",
    "ws_detail = ws.get_details()\n",
    "ws_rg = ws_detail['id'].split(\"/\")[4]\n",
    "vnet_rg=None\n",
    "try:\n",
    "    ray_cluster = ComputeTarget(workspace=ws, name=compute_cluster)\n",
    "\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    if vnet_rg is None:\n",
    "        vnet_rg = ws_rg\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                        min_nodes=0, max_nodes=maxnode,\n",
    "                                                        vnet_resourcegroup_name=vnet_rg,\n",
    "                                                        vnet_name=vnet,\n",
    "                                                        subnet_name=subnet)\n",
    "    ray_cluster = ComputeTarget.create(ws, compute_cluster, compute_config)\n",
    "\n",
    "    ray_cluster.wait_for_completion(show_output=True)\n",
    "\n",
    "\n",
    "# python_version = [\"python=\"+platform.python_version()]\n",
    "\n",
    "\n",
    "\n",
    "# conda_packages = python_version+base_conda_dep\n",
    "# pip_packages = base_pip_dep \n",
    "\n",
    "# conda_dep = CondaDependencies()\n",
    "\n",
    "# rayEnv = Environment(name=\"rayEnv\")\n",
    "rayEnv = Environment.get(ws, \"rayEnv\", version=18)\n",
    "# for conda_package in conda_packages:\n",
    "#     conda_dep.add_conda_package(conda_package)\n",
    "\n",
    "# for pip_package in pip_packages:\n",
    "#     conda_dep.add_pip_package(pip_package)\n",
    "\n",
    "# # Adds dependencies to PythonSection of myenv\n",
    "# rayEnv.python.conda_dependencies=conda_dep\n",
    "\n",
    "src = ScriptRunConfig(source_directory='job',\n",
    "                script='aml_job.py',\n",
    "                environment=rayEnv,\n",
    "                compute_target=ray_cluster,\n",
    "                distributed_job_config=PyTorchConfiguration(node_count=maxnode),\n",
    "                    # arguments = [\"--master_ip\",master_ip]\n",
    "                )\n",
    "run = Experiment(ws, exp).submit(src)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cac4749ce6e64bfd07fafd5bf9c175e86cc05b1d81ce0d05824a22ecc489c963"
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
