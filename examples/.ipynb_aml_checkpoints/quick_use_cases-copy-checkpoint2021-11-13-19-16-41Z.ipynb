{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Testing for Interactive use case"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install --upgrade ray-on-aml"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "# from azureml.widgets import RunDetails\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core.runconfig import PyTorchConfiguration\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "import platform\n",
        "import sys\n",
        "# sys.path.append(\"../\") # go to parent dir\n",
        "import importlib\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1639422777853
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#You can pre-provision \"worker-cpu-v3\" in the same vnet with your compute instance\n",
        "from ray_on_aml.core import Ray_On_AML\n",
        "ws = Workspace.from_config()\n",
        "ray_on_aml =Ray_On_AML(ws=ws, compute_cluster =\"dask-inter-cpu-3\", maxnode=2)\n",
        "_, ray = ray_on_aml.getRay()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "rank returned is  None\nrank returned is  None\nazureml_py38\nFound existing cluster, use it.\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\nWaiting: Cluster status is in  Queued\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-13 19:13:20,460\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n2021-12-13 19:13:36,266\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 10.1.0.5:6379\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1639179738843
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ray.cluster_resources()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "{'CPU': 12.0,\n 'memory': 26859820648.0,\n 'object_store_memory': 12016739941.0,\n 'node:10.1.0.7': 1.0,\n 'node:10.1.0.8': 1.0,\n 'node:10.1.0.5': 1.0}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1639179758561
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ray_on_aml.shutdown()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1639106683762
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing with Dask on Ray"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import ray\n",
        "# ray.init()\n",
        "from ray.util.dask import ray_dask_get\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "dask.config.set(scheduler=ray_dask_get)\n",
        "d_arr = da.from_array(np.random.randint(0, 1000, size=(256, 256)))\n",
        "\n",
        "# The Dask scheduler submits the underlying task graph to Ray.\n",
        "d_arr.mean().compute(scheduler=ray_dask_get)\n",
        "\n",
        "# Set the scheduler to ray_dask_get in your config so you don't have to\n",
        "# specify it on each compute call.\n",
        "\n",
        "df = dd.from_pandas(\n",
        "    pd.DataFrame(\n",
        "        np.random.randint(0, 10000, size=(1024, 2)), columns=[\"age\", \"grade\"]),\n",
        "    npartitions=2)\n",
        "df.groupby([\"age\"]).mean().compute()\n",
        "\n",
        "# ray.shutdown()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1639179775998
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import dask.dataframe as dd\n",
        "\n",
        "# storage_options = {'account_name': 'azureopendatastorage'}\n",
        "# ddf = dd.read_parquet('az://nyctlc/green/puYear=2019/puMonth=*/*.parquet', storage_options=storage_options)\n",
        "# ddf.count().compute()\n",
        "#This still have error about parquet, need to fix, might be lib version conflict"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1639104458150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dask\n",
        "\n",
        "# import ray\n",
        "from ray.util.dask import ray_dask_get\n",
        "import dask\n",
        "import dask.array as da\n",
        "import dask.dataframe as dd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import dask\n",
        "import dask.dataframe as dd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "from azureml.core import Workspace, Dataset, Model\n",
        "from adlfs import AzureBlobFileSystem\n",
        "# account_key = ws.get_default_keyvault().get_secret(\"adls7-account-key\")\n",
        "# account_name=\"adlsgen7\"\n",
        "# abfs = AzureBlobFileSystem(account_name=\"adlsgen7\",account_key=account_key,  container_name=\"mltraining\")\n",
        "abfs2 = AzureBlobFileSystem(account_name=\"azureopendatastorage\",  container_name=\"isdweatherdatacontainer\")\n",
        "\n",
        "\n",
        "# storage_options={'account_name': account_name, 'account_key': account_key}\n",
        "\n",
        "# ddf = dd.read_parquet('az://mltraining/ISDWeatherDelta/year2008', storage_options=storage_options)\n",
        "\n",
        "data = ray.data.read_parquet(\"az://isdweatherdatacontainer/ISDWeather/year=2009\", filesystem=abfs2)\n",
        "# data2 = ray.data.read_parquet(\"az://mltraining/ISDWeatherDelta/year2008\", filesystem=abfs)\n",
        "data.count()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1639179854644
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Ray Tune for distributed ML tunning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "# import ray\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # In this example, we don't change the model architecture\n",
        "        # due to simplicity.\n",
        "        self.conv1 = nn.Conv2d(1, 3, kernel_size=3)\n",
        "        self.fc = nn.Linear(192, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 3))\n",
        "        x = x.view(-1, 192)\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "# Change these values if you want the training to run quicker or slower.\n",
        "EPOCH_SIZE = 512\n",
        "TEST_SIZE = 256\n",
        "\n",
        "def train(model, optimizer, train_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # We set this just for the example to run quickly.\n",
        "        if batch_idx * len(data) > EPOCH_SIZE:\n",
        "            return\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test(model, data_loader):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            # We set this just for the example to run quickly.\n",
        "            if batch_idx * len(data) > TEST_SIZE:\n",
        "                break\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "    return correct / total\n",
        "def train_mnist(config):\n",
        "    # Data Setup\n",
        "    mnist_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.1307, ), (0.3081, ))])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        datasets.MNIST(\"~/data\", train=True, download=True, transform=mnist_transforms),\n",
        "        batch_size=64,\n",
        "        shuffle=True)\n",
        "    test_loader = DataLoader(\n",
        "        datasets.MNIST(\"~/data\", train=False, transform=mnist_transforms),\n",
        "        batch_size=64,\n",
        "        shuffle=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ConvNet()\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"])\n",
        "    for i in range(10):\n",
        "        train(model, optimizer, train_loader)\n",
        "        acc = test(model, test_loader)\n",
        "\n",
        "        # Send the current training result back to Tune\n",
        "        tune.report(mean_accuracy=acc)\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            # This saves the model to the trial directory\n",
        "            torch.save(model.state_dict(), \"./model.pth\")\n",
        "search_space = {\n",
        "    \"lr\": tune.sample_from(lambda spec: 10**(-10 * np.random.rand())),\n",
        "    \"momentum\": tune.uniform(0.01, 0.09)\n",
        "}\n",
        "\n",
        "# Uncomment this to enable distributed execution\n",
        "# ray.shutdown()\n",
        "# ray.init(address=\"auto\",ignore_reinit_error=True)\n",
        "# ray.init(address =f'ray://{headnode_private_ip}:10001',allow_multiple=True,ignore_reinit_error=True )\n",
        "# Download the dataset first\n",
        "datasets.MNIST(\"~/data\", train=True, download=True)\n",
        "\n",
        "analysis = tune.run(train_mnist, config=search_space)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-11 00:30:21,715\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "== Status ==<br>Current time: 2021-12-11 00:30:21 (running for 00:00:00.12)<br>Memory usage on this node: 3.4/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/25.02 GiB heap, 0.0/11.19 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-11_00-30-21<br>Number of trials: 1/1 (1 PENDING)<br><table>\n<thead>\n<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th></tr>\n</thead>\n<tbody>\n<tr><td>train_mnist_864dd_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000459906</td><td style=\"text-align: right;\"> 0.0787864</td></tr>\n</tbody>\n</table><br><br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-11 00:30:22,696\tERROR trial_runner.py:958 -- Trial train_mnist_864dd_00000: Error processing event.\nTraceback (most recent call last):\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/tune/trial_runner.py\", line 924, in _process_trial\n    results = self.trial_executor.fetch_result(trial)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\", line 787, in fetch_result\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n    return func(*args, **kwargs)\n  File \"/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/worker.py\", line 1715, in get\n    raise value\nray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=186, ip=10.1.0.8)\nRuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n\n\u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=186, ip=10.1.0.8)\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle.py\", line 679, in subimport\n    __import__(name)\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/__init__.py\", line 6, in <module>\n    from torchvision import models\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/__init__.py\", line 12, in <module>\n    from . import detection\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n    from .faster_rcnn import *\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/detection/faster_rcnn.py\", line 7, in <module>\n    from torchvision.ops import misc as misc_nn_ops\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/ops/__init__.py\", line 1, in <module>\n    from .boxes import nms, batched_nms, remove_small_boxes, clip_boxes_to_image, box_area, box_iou, generalized_box_iou\n  File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/ops/boxes.py\", line 45, in <module>\n    @torch.jit._script_if_tracing\nAttributeError: module 'torch.jit' has no attribute '_script_if_tracing'\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Result for train_mnist_864dd_00000:\n  trial_id: 864dd_00000\n  \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "== Status ==<br>Current time: 2021-12-11 00:30:22 (running for 00:00:00.98)<br>Memory usage on this node: 3.4/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/25.02 GiB heap, 0.0/11.19 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_mnist_2021-12-11_00-30-21<br>Number of trials: 1/1 (1 ERROR)<br><table>\n<thead>\n<tr><th>Trial name             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  momentum</th></tr>\n</thead>\n<tbody>\n<tr><td>train_mnist_864dd_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.000459906</td><td style=\"text-align: right;\"> 0.0787864</td></tr>\n</tbody>\n</table><br>Number of errored trials: 1<br><table>\n<thead>\n<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                         </th></tr>\n</thead>\n<tbody>\n<tr><td>train_mnist_864dd_00000</td><td style=\"text-align: right;\">           1</td><td>/home/azureuser/ray_results/train_mnist_2021-12-11_00-30-21/train_mnist_864dd_00000_0_lr=0.00045991,momentum=0.078786_2021-12-11_00-30-21/error.txt</td></tr>\n</tbody>\n</table><br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m 2021-12-11 00:30:22,679\tERROR worker.py:431 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=186, ip=10.1.0.8)\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m RuntimeError: The actor with name ImplicitFunc failed to import on the worker. This may be because needed library dependencies are not installed in the worker environment:\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m \n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m \u001b[36mray::ImplicitFunc.__init__()\u001b[39m (pid=186, ip=10.1.0.8)\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/ray/cloudpickle/cloudpickle.py\", line 679, in subimport\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m     __import__(name)\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/__init__.py\", line 6, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m     from torchvision import models\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/__init__.py\", line 12, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m     from . import detection\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m     from .faster_rcnn import *\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/models/detection/faster_rcnn.py\", line 7, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m     from torchvision.ops import misc as misc_nn_ops\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/ops/__init__.py\", line 1, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m     from .boxes import nms, batched_nms, remove_small_boxes, clip_boxes_to_image, box_area, box_iou, generalized_box_iou\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m   File \"/azureml-envs/azureml_9f40ebd6c5e1a42ea1a7e894680858b1/lib/python3.8/site-packages/torchvision/ops/boxes.py\", line 45, in <module>\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m     @torch.jit._script_if_tracing\n\u001b[2m\u001b[36m(TemporaryActor pid=186, ip=10.1.0.8)\u001b[0m AttributeError: module 'torch.jit' has no attribute '_script_if_tracing'\n"
        },
        {
          "output_type": "error",
          "ename": "TuneError",
          "evalue": "('Trials did not complete', [train_mnist_864dd_00000])",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_18879/956064152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"~/data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_mnist_864dd_00000])"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1639106657384
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install ipywidgets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        " import sklearn.datasets\n",
        " import sklearn.metrics\n",
        " from sklearn.model_selection import train_test_split\n",
        " import xgboost as xgb\n",
        "\n",
        " from ray import tune\n",
        "\n",
        "\n",
        " def train_breast_cancer(config):\n",
        "     # Load dataset\n",
        "     data, labels = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "     # Split into train and test set\n",
        "     train_x, test_x, train_y, test_y = train_test_split(\n",
        "         data, labels, test_size=0.25)\n",
        "     # Build input matrices for XGBoost\n",
        "     train_set = xgb.DMatrix(train_x, label=train_y)\n",
        "     test_set = xgb.DMatrix(test_x, label=test_y)\n",
        "     # Train the classifier\n",
        "     results = {}\n",
        "     xgb.train(\n",
        "         config,\n",
        "         train_set,\n",
        "         evals=[(test_set, \"eval\")],\n",
        "         evals_result=results,\n",
        "         verbose_eval=False)\n",
        "     # Return prediction accuracy\n",
        "     accuracy = 1. - results[\"eval\"][\"error\"][-1]\n",
        "     tune.report(mean_accuracy=accuracy, done=True)\n",
        "\n",
        "\n",
        " config = {\n",
        "     \"objective\": \"binary:logistic\",\n",
        "     \"eval_metric\": [\"logloss\", \"error\"],\n",
        "     \"max_depth\": tune.randint(1, 9),\n",
        "     \"min_child_weight\": tune.choice([1, 2, 3]),\n",
        "     \"subsample\": tune.uniform(0.5, 1.0),\n",
        "     \"eta\": tune.loguniform(1e-4, 1e-1)\n",
        " }\n",
        " analysis = tune.run(\n",
        "     train_breast_cancer,\n",
        "     resources_per_trial={\"cpu\": 1},\n",
        "     config=config,\n",
        "     num_samples=10)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-11 00:31:23,995\tWARNING callback.py:114 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "== Status ==<br>Current time: 2021-12-11 00:31:24 (running for 00:00:00.17)<br>Memory usage on this node: 3.5/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/25.02 GiB heap, 0.0/11.19 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-11_00-31-23<br>Number of trials: 10/10 (10 PENDING)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_ab850_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.000753868</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.789591</td></tr>\n<tr><td>train_breast_cancer_ab850_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00127206 </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.710987</td></tr>\n<tr><td>train_breast_cancer_ab850_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0469156  </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.65677 </td></tr>\n<tr><td>train_breast_cancer_ab850_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00175772 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.942523</td></tr>\n<tr><td>train_breast_cancer_ab850_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00841455 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.820798</td></tr>\n<tr><td>train_breast_cancer_ab850_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00474375 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.67028 </td></tr>\n<tr><td>train_breast_cancer_ab850_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00100369 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.557439</td></tr>\n<tr><td>train_breast_cancer_ab850_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0886247  </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.817153</td></tr>\n<tr><td>train_breast_cancer_ab850_00008</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0083008  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.797411</td></tr>\n<tr><td>train_breast_cancer_ab850_00009</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.00657158 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.786222</td></tr>\n</tbody>\n</table><br><br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Result for train_breast_cancer_ab850_00006:\n  date: 2021-12-11_00-31-26\n  done: true\n  experiment_id: 607f63e072014d71ae7f73bd0fc22db3\n  hostname: 4682a9e6f1694a15a0b2b82d005b79f6000003\n  iterations_since_restore: 1\n  mean_accuracy: 0.979021\n  node_ip: 10.1.0.8\n  pid: 248\n  time_since_restore: 0.1728968620300293\n  time_this_iter_s: 0.1728968620300293\n  time_total_s: 0.1728968620300293\n  timestamp: 1639182686\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: ab850_00006\n  \nResult for train_breast_cancer_ab850_00003:\n  date: 2021-12-11_00-31-26\n  done: true\n  experiment_id: c58f2a4526e34ffe8c9e14c91d7f4d6c\n  hostname: 4682a9e6f1694a15a0b2b82d005b79f6000002\n  iterations_since_restore: 1\n  mean_accuracy: 0.965035\n  node_ip: 10.1.0.7\n  pid: 213\n  time_since_restore: 0.24258041381835938\n  time_this_iter_s: 0.24258041381835938\n  time_total_s: 0.24258041381835938\n  timestamp: 1639182686\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: ab850_00003\n  \nResult for train_breast_cancer_ab850_00001:\n  date: 2021-12-11_00-31-26\n  done: true\n  experiment_id: 31ce856e7c164847882d6cc68d0e1419\n  hostname: 4682a9e6f1694a15a0b2b82d005b79f6000002\n  iterations_since_restore: 1\n  mean_accuracy: 0.958042\n  node_ip: 10.1.0.7\n  pid: 214\n  time_since_restore: 0.2967870235443115\n  time_this_iter_s: 0.2967870235443115\n  time_total_s: 0.2967870235443115\n  timestamp: 1639182686\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: ab850_00001\n  \nResult for train_breast_cancer_ab850_00002:\n  date: 2021-12-11_00-31-26\n  done: true\n  experiment_id: 62512f006543460cbede4af538c49fb2\n  hostname: 4682a9e6f1694a15a0b2b82d005b79f6000002\n  iterations_since_restore: 1\n  mean_accuracy: 0.93007\n  node_ip: 10.1.0.7\n  pid: 212\n  time_since_restore: 0.3019380569458008\n  time_this_iter_s: 0.3019380569458008\n  time_total_s: 0.3019380569458008\n  timestamp: 1639182686\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: ab850_00002\n  \nResult for train_breast_cancer_ab850_00007:\n  date: 2021-12-11_00-31-26\n  done: true\n  experiment_id: 3cfb20a24e5240dabc8a988ab7c063e5\n  hostname: 4682a9e6f1694a15a0b2b82d005b79f6000003\n  iterations_since_restore: 1\n  mean_accuracy: 0.944056\n  node_ip: 10.1.0.8\n  pid: 247\n  time_since_restore: 0.26726293563842773\n  time_this_iter_s: 0.26726293563842773\n  time_total_s: 0.26726293563842773\n  timestamp: 1639182686\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: ab850_00007\n  \nResult for train_breast_cancer_ab850_00004:\n  date: 2021-12-11_00-31-26\n  done: true\n  experiment_id: d21c49cdd899473589c6d958a147edc8\n  hostname: 4682a9e6f1694a15a0b2b82d005b79f6000003\n  iterations_since_restore: 1\n  mean_accuracy: 0.916084\n  node_ip: 10.1.0.8\n  pid: 249\n  time_since_restore: 0.2890925407409668\n  time_this_iter_s: 0.2890925407409668\n  time_total_s: 0.2890925407409668\n  timestamp: 1639182686\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: ab850_00004\n  \nResult for train_breast_cancer_ab850_00000:\n  date: 2021-12-11_00-31-27\n  done: true\n  experiment_id: 96950274a78c4f7e9e7626c1f3517ba8\n  hostname: hyssh1\n  iterations_since_restore: 1\n  mean_accuracy: 0.951049\n  node_ip: 10.1.0.5\n  pid: 19154\n  time_since_restore: 1.0391948223114014\n  time_this_iter_s: 1.0391948223114014\n  time_total_s: 1.0391948223114014\n  timestamp: 1639182687\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: ab850_00000\n  \nResult for train_breast_cancer_ab850_00005:\n  date: 2021-12-11_00-31-27\n  done: true\n  experiment_id: f549e016c9644aecab082fe91e7294bc\n  hostname: hyssh1\n  iterations_since_restore: 1\n  mean_accuracy: 0.923077\n  node_ip: 10.1.0.5\n  pid: 19264\n  time_since_restore: 0.4921693801879883\n  time_this_iter_s: 0.4921693801879883\n  time_total_s: 0.4921693801879883\n  timestamp: 1639182687\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: ab850_00005\n  \nResult for train_breast_cancer_ab850_00008:\n  date: 2021-12-11_00-31-27\n  done: true\n  experiment_id: ef04ee7000004e27b42c8c1ebc45e24b\n  hostname: hyssh1\n  iterations_since_restore: 1\n  mean_accuracy: 0.944056\n  node_ip: 10.1.0.5\n  pid: 19265\n  time_since_restore: 0.5741965770721436\n  time_this_iter_s: 0.5741965770721436\n  time_total_s: 0.5741965770721436\n  timestamp: 1639182687\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: ab850_00008\n  \nResult for train_breast_cancer_ab850_00009:\n  date: 2021-12-11_00-31-27\n  done: true\n  experiment_id: eb064f01b11641c783c7d552febdd5e0\n  hostname: hyssh1\n  iterations_since_restore: 1\n  mean_accuracy: 0.923077\n  node_ip: 10.1.0.5\n  pid: 19263\n  time_since_restore: 0.43230390548706055\n  time_this_iter_s: 0.43230390548706055\n  time_total_s: 0.43230390548706055\n  timestamp: 1639182687\n  timesteps_since_restore: 0\n  training_iteration: 1\n  trial_id: ab850_00009\n  \n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": "== Status ==<br>Current time: 2021-12-11 00:31:27 (running for 00:00:03.74)<br>Memory usage on this node: 3.4/13.7 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/25.02 GiB heap, 0.0/11.19 GiB objects<br>Result logdir: /home/azureuser/ray_results/train_breast_cancer_2021-12-11_00-31-23<br>Number of trials: 10/10 (10 TERMINATED)<br><table>\n<thead>\n<tr><th>Trial name                     </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">        eta</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n</thead>\n<tbody>\n<tr><td>train_breast_cancer_ab850_00000</td><td>TERMINATED</td><td>10.1.0.5:19154</td><td style=\"text-align: right;\">0.000753868</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.789591</td><td style=\"text-align: right;\">0.951049</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        1.03919 </td></tr>\n<tr><td>train_breast_cancer_ab850_00001</td><td>TERMINATED</td><td>10.1.0.7:214  </td><td style=\"text-align: right;\">0.00127206 </td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.710987</td><td style=\"text-align: right;\">0.958042</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.296787</td></tr>\n<tr><td>train_breast_cancer_ab850_00002</td><td>TERMINATED</td><td>10.1.0.7:212  </td><td style=\"text-align: right;\">0.0469156  </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.65677 </td><td style=\"text-align: right;\">0.93007 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.301938</td></tr>\n<tr><td>train_breast_cancer_ab850_00003</td><td>TERMINATED</td><td>10.1.0.7:213  </td><td style=\"text-align: right;\">0.00175772 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">   0.942523</td><td style=\"text-align: right;\">0.965035</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.24258 </td></tr>\n<tr><td>train_breast_cancer_ab850_00004</td><td>TERMINATED</td><td>10.1.0.8:249  </td><td style=\"text-align: right;\">0.00841455 </td><td style=\"text-align: right;\">          1</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.820798</td><td style=\"text-align: right;\">0.916084</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.289093</td></tr>\n<tr><td>train_breast_cancer_ab850_00005</td><td>TERMINATED</td><td>10.1.0.5:19264</td><td style=\"text-align: right;\">0.00474375 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.67028 </td><td style=\"text-align: right;\">0.923077</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.492169</td></tr>\n<tr><td>train_breast_cancer_ab850_00006</td><td>TERMINATED</td><td>10.1.0.8:248  </td><td style=\"text-align: right;\">0.00100369 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.557439</td><td style=\"text-align: right;\">0.979021</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.172897</td></tr>\n<tr><td>train_breast_cancer_ab850_00007</td><td>TERMINATED</td><td>10.1.0.8:247  </td><td style=\"text-align: right;\">0.0886247  </td><td style=\"text-align: right;\">          2</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.817153</td><td style=\"text-align: right;\">0.944056</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.267263</td></tr>\n<tr><td>train_breast_cancer_ab850_00008</td><td>TERMINATED</td><td>10.1.0.5:19265</td><td style=\"text-align: right;\">0.0083008  </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">   0.797411</td><td style=\"text-align: right;\">0.944056</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.574197</td></tr>\n<tr><td>train_breast_cancer_ab850_00009</td><td>TERMINATED</td><td>10.1.0.5:19263</td><td style=\"text-align: right;\">0.00657158 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">   0.786222</td><td style=\"text-align: right;\">0.923077</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.432304</td></tr>\n</tbody>\n</table><br><br>",
            "text/plain": "<IPython.core.display.HTML object>"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2021-12-11 00:31:27,853\tINFO tune.py:626 -- Total run time: 3.87 seconds (3.72 seconds for the tuning loop).\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1639181553874
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing Spark on Ray (#todo)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# import ray\n",
        "# import raydp\n",
        "# import os\n",
        "# ray.shutdown()\n",
        "# ray.init()\n",
        "# os.environ[\"PYSPARK_PYTHON\"]=\"/anaconda/envs/azureml_py38/bin/python3\"\n",
        "\n",
        "# # ray.init(address ='ray://10.0.0.11:6379')\n",
        "# spark = raydp.init_spark(\n",
        "#   app_name = \"example\",\n",
        "#   num_executors = 2,\n",
        "#   executor_cores = 1,\n",
        "#   executor_memory = \"1gb\"\n",
        "# )\n",
        "\n",
        "# # data =spark.read.format(\"csv\").option(\"header\", True).load(\"wasbs://ojsales-simulatedcontainer@azureopendatastorage.blob.core.windows.net/oj_sales_data/Store10*.csv\")\n",
        "\n",
        "\n",
        "# # # normal data processesing with Spark\n",
        "# # df = spark.createDataFrame([('look',), ('spark',), ('tutorial',), ('spark',), ('look', ), ('python', )], ['word'])\n",
        "# # df.show()\n",
        "# # word_count = df.groupBy('word').count()\n",
        "# # word_count.show()\n",
        "# import pandas as pd\n",
        "\n",
        "# from pyspark.sql.functions import col, pandas_udf\n",
        "# from pyspark.sql.types import LongType\n",
        "\n",
        "# # Declare the function and create the UDF\n",
        "# def multiply_func(a: pd.Series, b: pd.Series) -> pd.Series:\n",
        "#     return a * b\n",
        "\n",
        "# multiply = pandas_udf(multiply_func, returnType=LongType())\n",
        "\n",
        "# # The function for a pandas_udf should be able to execute with local Pandas data\n",
        "# x = pd.Series([1, 2, 3])\n",
        "# print(multiply_func(x, x))\n",
        "# # 0    1\n",
        "# # 1    4\n",
        "# # 2    9\n",
        "# # dtype: int64\n",
        "\n",
        "# # Create a Spark DataFrame, 'spark' is an existing SparkSession\n",
        "# df = spark.createDataFrame(pd.DataFrame(x, columns=[\"x\"]))\n",
        "\n",
        "# # Execute function as a Spark vectorized UDF\n",
        "# df.select(multiply(col(\"x\"), col(\"x\"))).show()\n",
        "# # +-------------------+\n",
        "# # |multiply_func(x, x)|\n",
        "# # +-------------------+\n",
        "# # |                  1|\n",
        "# # |                  4|\n",
        "# # |                  9|\n",
        "# # +-------------------+\n",
        "\n",
        "\n",
        "# # stop the spark cluster\n",
        "# raydp.stop_spark()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Ray on Job Cluster"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# base_conda_dep =['adlfs>=2021.10.0','pytorch','matplotlib','torchvision','pip']\n",
        "# base_pip_dep = ['sklearn','xgboost','lightgbm','ray[default]==1.9.0', 'xgboost_ray', 'dask','pyarrow>=6.0.1', 'azureml-mlflow']\n",
        "compute_cluster = 'worker-cpu-v3'\n",
        "maxnode =5\n",
        "vm_size='STANDARD_DS3_V2'\n",
        "vnet='rayvnet'\n",
        "subnet='default'\n",
        "exp ='ray_on_aml_job'\n",
        "ws_detail = ws.get_details()\n",
        "ws_rg = ws_detail['id'].split(\"/\")[4]\n",
        "vnet_rg=None\n",
        "try:\n",
        "    ray_cluster = ComputeTarget(workspace=ws, name=compute_cluster)\n",
        "\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    if vnet_rg is None:\n",
        "        vnet_rg = ws_rg\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
        "                                                        min_nodes=0, max_nodes=maxnode,\n",
        "                                                        vnet_resourcegroup_name=vnet_rg,\n",
        "                                                        vnet_name=vnet,\n",
        "                                                        subnet_name=subnet)\n",
        "    ray_cluster = ComputeTarget.create(ws, compute_cluster, compute_config)\n",
        "\n",
        "    ray_cluster.wait_for_completion(show_output=True)\n",
        "\n",
        "\n",
        "# python_version = [\"python=\"+platform.python_version()]\n",
        "\n",
        "\n",
        "\n",
        "# conda_packages = python_version+base_conda_dep\n",
        "# pip_packages = base_pip_dep \n",
        "\n",
        "# conda_dep = CondaDependencies()\n",
        "\n",
        "# rayEnv = Environment(name=\"rayEnv\")\n",
        "rayEnv = Environment.get(ws, \"rayEnv\", version=18)\n",
        "# for conda_package in conda_packages:\n",
        "#     conda_dep.add_conda_package(conda_package)\n",
        "\n",
        "# for pip_package in pip_packages:\n",
        "#     conda_dep.add_pip_package(pip_package)\n",
        "\n",
        "# # Adds dependencies to PythonSection of myenv\n",
        "# rayEnv.python.conda_dependencies=conda_dep\n",
        "\n",
        "src = ScriptRunConfig(source_directory='job',\n",
        "                script='aml_job.py',\n",
        "                environment=rayEnv,\n",
        "                compute_target=ray_cluster,\n",
        "                distributed_job_config=PyTorchConfiguration(node_count=maxnode),\n",
        "                    # arguments = [\"--master_ip\",master_ip]\n",
        "                )\n",
        "run = Experiment(ws, exp).submit(src)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "InProgress..\nFailedProvisioning operation finished, operation \"Failed\"\n"
        },
        {
          "output_type": "error",
          "ename": "ComputeTargetException",
          "evalue": "ComputeTargetException:\n\tMessage: Compute object provisioning polling reached non-successful terminal state, current provisioning state: Failed\nProvisioning operation error:\n{'code': 'BadRequest', 'message': '{\"id\":\"https://westus2.api.azureml.ms/batchai/subscriptions/89da9f33-fd31-4ece-861e-5fab7af4dc11/providers/Microsoft.BatchAI/locations/westus2/operationresults/54fa6b50-5028-46c7-a409-88dd46d8c8b8\",\"name\":\"54fa6b50-5028-46c7-a409-88dd46d8c8b8\",\"status\":\"Failed\",\"startTime\":\"2021-12-11T00:31:36.954Z\",\"endTime\":\"2021-12-11T00:31:39.076Z\",\"error\":{\"code\":\"VNetNotFound\",\"message\":\"The specified subnet id /subscriptions/89da9f33-fd31-4ece-861e-5fab7af4dc11/resourceGroups/mtcs-dev-aml-rg/providers/Microsoft.Network/virtualNetworks/rayvnet/subnets/default is not found\"}}'}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Compute object provisioning polling reached non-successful terminal state, current provisioning state: Failed\\nProvisioning operation error:\\n{'code': 'BadRequest', 'message': '{\\\"id\\\":\\\"https://westus2.api.azureml.ms/batchai/subscriptions/89da9f33-fd31-4ece-861e-5fab7af4dc11/providers/Microsoft.BatchAI/locations/westus2/operationresults/54fa6b50-5028-46c7-a409-88dd46d8c8b8\\\",\\\"name\\\":\\\"54fa6b50-5028-46c7-a409-88dd46d8c8b8\\\",\\\"status\\\":\\\"Failed\\\",\\\"startTime\\\":\\\"2021-12-11T00:31:36.954Z\\\",\\\"endTime\\\":\\\"2021-12-11T00:31:39.076Z\\\",\\\"error\\\":{\\\"code\\\":\\\"VNetNotFound\\\",\\\"message\\\":\\\"The specified subnet id /subscriptions/89da9f33-fd31-4ece-861e-5fab7af4dc11/resourceGroups/mtcs-dev-aml-rg/providers/Microsoft.Network/virtualNetworks/rayvnet/subnets/default is not found\\\"}}'}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mComputeTargetException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_18879/1963052339.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mray_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputeTarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, workspace, name)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 raise ComputeTargetException('ComputeTargetNotFound: Compute Target with name {} not found in '\n\u001b[0m\u001b[1;32m     91\u001b[0m                                              'provided workspace'.format(name))\n",
            "\u001b[0;31mComputeTargetException\u001b[0m: ComputeTargetException:\n\tMessage: ComputeTargetNotFound: Compute Target with name worker-cpu-v3 not found in provided workspace\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"ComputeTargetNotFound: Compute Target with name worker-cpu-v3 not found in provided workspace\"\n    }\n}",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mComputeTargetException\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_18879/1963052339.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mray_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputeTarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_cluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mray_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/compute/amlcompute.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, min_node_count, timeout_in_minutes, is_delete_operation)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;31m# For all LROs poll MLC's operation status endpoint first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_operation_endpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             super(AmlCompute, self).wait_for_completion(show_output=show_output,\n\u001b[0m\u001b[1;32m    375\u001b[0m                                                         is_delete_operation=is_delete_operation)\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_delete_operation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, is_delete_operation)\u001b[0m\n\u001b[1;32m    584\u001b[0m                                              'Current state is {}'.format(self.provisioning_state))\n\u001b[1;32m    585\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/compute/compute.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, is_delete_operation)\u001b[0m\n\u001b[1;32m    574\u001b[0m                     \u001b[0merror_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m                 raise ComputeTargetException('Compute object provisioning polling reached non-successful terminal '\n\u001b[0m\u001b[1;32m    577\u001b[0m                                              \u001b[0;34m'state, current provisioning state: {}\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m                                              \u001b[0;34m'Provisioning operation error:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mComputeTargetException\u001b[0m: ComputeTargetException:\n\tMessage: Compute object provisioning polling reached non-successful terminal state, current provisioning state: Failed\nProvisioning operation error:\n{'code': 'BadRequest', 'message': '{\"id\":\"https://westus2.api.azureml.ms/batchai/subscriptions/89da9f33-fd31-4ece-861e-5fab7af4dc11/providers/Microsoft.BatchAI/locations/westus2/operationresults/54fa6b50-5028-46c7-a409-88dd46d8c8b8\",\"name\":\"54fa6b50-5028-46c7-a409-88dd46d8c8b8\",\"status\":\"Failed\",\"startTime\":\"2021-12-11T00:31:36.954Z\",\"endTime\":\"2021-12-11T00:31:39.076Z\",\"error\":{\"code\":\"VNetNotFound\",\"message\":\"The specified subnet id /subscriptions/89da9f33-fd31-4ece-861e-5fab7af4dc11/resourceGroups/mtcs-dev-aml-rg/providers/Microsoft.Network/virtualNetworks/rayvnet/subnets/default is not found\"}}'}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Compute object provisioning polling reached non-successful terminal state, current provisioning state: Failed\\nProvisioning operation error:\\n{'code': 'BadRequest', 'message': '{\\\"id\\\":\\\"https://westus2.api.azureml.ms/batchai/subscriptions/89da9f33-fd31-4ece-861e-5fab7af4dc11/providers/Microsoft.BatchAI/locations/westus2/operationresults/54fa6b50-5028-46c7-a409-88dd46d8c8b8\\\",\\\"name\\\":\\\"54fa6b50-5028-46c7-a409-88dd46d8c8b8\\\",\\\"status\\\":\\\"Failed\\\",\\\"startTime\\\":\\\"2021-12-11T00:31:36.954Z\\\",\\\"endTime\\\":\\\"2021-12-11T00:31:39.076Z\\\",\\\"error\\\":{\\\"code\\\":\\\"VNetNotFound\\\",\\\"message\\\":\\\"The specified subnet id /subscriptions/89da9f33-fd31-4ece-861e-5fab7af4dc11/resourceGroups/mtcs-dev-aml-rg/providers/Microsoft.Network/virtualNetworks/rayvnet/subnets/default is not found\\\"}}'}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "cac4749ce6e64bfd07fafd5bf9c175e86cc05b1d81ce0d05824a22ecc489c963"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}